{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b167c316-79c8-437a-b28c-0ac1d221c178",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "\t•\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "    \n",
    "\t•\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "    \n",
    "\t•\tИсключим стоп-слова с помощью stop_words='english'.\n",
    "    \n",
    "\t•\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88bfbb94-1843-432a-b703-2da0f67b864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb869a83-e431-4d31-b920-81213dcbd774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('combine_df.pkl', 'rb') as f:\n",
    "    combine_df = pickle.load(f)\n",
    "    \n",
    "combine_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f41a2df-fcc5-4b09-8cec-e6175e9dfb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_df=0.9, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b94f662-f556-40e4-865f-22bee15f8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_stemmed = combine_df['tweet_stemmed'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4dffe62e-afce-46b8-a24e-67a491d8b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_stemmed_tweet = count_vectorizer.fit_transform(tweet_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9783ada-939e-4a93-87fe-86b8551da857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Olga/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual  ad  adapt  ...  \\\n",
       "0    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "1    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "2    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "\n",
       "   year  yesterday  yo  yoga  york  young  youth  youtub  yr  yummi  \n",
       "0     0          0   0     0     0      0      0       0   0      0  \n",
       "1     0          0   0     0     0      0      0       0   0      0  \n",
       "2     0          0   0     0     0      0      0       0   0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bow_stemmed_tweet.toarray(), columns = feature_names).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1709bcd9-7db9-446f-83a1-e63600e2df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_lemmatized = combine_df['tweet_lemmatized'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9b265b0-d284-4071-b780-e35bbab68a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_lemmatized_tweet = count_vectorizer.fit_transform(tweet_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6fa29cd-588c-4e89-a616-072c39fb82fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual  ad  adapt  ...  \\\n",
       "0    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "1    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "2    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "\n",
       "   year  yesterday  yo  yoga  york  young  youth  youtub  yr  yummi  \n",
       "0     0          0   0     0     0      0      0       0   0      0  \n",
       "1     0          0   0     0     0      0      0       0   0      0  \n",
       "2     0          0   0     0     0      0      0       0   0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bow_lemmatized_tweet.toarray(), columns = feature_names).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fce66b-9309-443e-839e-1c413d242e75",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "\t•\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "    \n",
    "\t•\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "    \n",
    "\t•\tИсключим стоп-слова с помощью stop_words='english'.\n",
    "    \n",
    "\t•\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50993444-69a8-4212-8b63-7e57564a568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e9ff90b-f0e3-462b-811d-ac04259a6384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Olga/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual   ad  adapt  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "\n",
       "   year  yesterday   yo  yoga  york  young  youth  youtub   yr  yummi  \n",
       "0   0.0        0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0        0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0        0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tfidf_tweet_stemmed = tfidf_vectorizer.fit_transform(tweet_stemmed)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bow_tfidf_tweet_stemmed.toarray(), columns = tfidf_feature_names).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c2e54c3-4068-4aef-903b-8cb73bdb93f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual   ad  adapt  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "\n",
       "   year  yesterday   yo  yoga  york  young  youth  youtub   yr  yummi  \n",
       "0   0.0        0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0        0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0        0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tfidf_tweet_lemmatized = tfidf_vectorizer.fit_transform(tweet_lemmatized)\n",
    "pd.DataFrame(bow_tfidf_tweet_lemmatized.toarray(), columns = tfidf_feature_names).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ad1aa-1073-40a0-9a63-96f88a060d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89bd89-9e04-499e-a799-3bd6c3b54565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faaf8cb2-ceb9-4cad-8586-f1a29152bbaa",
   "metadata": {},
   "source": [
    "3. Натренируем gensim.models.Word2Vec модель на наших данных.\n",
    "\n",
    "\t•\tТренировать будем на токенизированных твитах combine_df['tweet_token']\n",
    "    \n",
    "\t•\tУстановим следующие параметры: size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34.\n",
    "    \n",
    "\t•\tИспользуем функцию train() с параметром total_examples равным длине combine_df['tweet_token'], количество epochs установим 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7747f136-cada-4836-996d-21ba75b475cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Word2Vec in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: joblib in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from Word2Vec) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from Word2Vec) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Users/Olga/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05348b33-32a3-474b-872f-9185cea883d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "data_tweet_token = combine_df['tweet_token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9dfbd947-8c21-4744-b08b-bdb4921dc11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8989046, 11616500)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = Word2Vec(data_tweet_token, vector_size=200, window=5, min_count=2, sg=1, hs=0, negative=10, seed=34)\n",
    "\n",
    "model_w2v.train(data_tweet_token, total_examples=len(data_tweet_token), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78f710-a518-40d0-abd0-7daf6a4fd3bb",
   "metadata": {},
   "source": [
    "4. Давайте немного потестируем нашу модель Word2Vec и посмотрим, как она работает. Мы зададим слово positive = \"dinner\", и модель вытащит из корпуса наиболее похожие слова c помощью функции most_similar. То же самое попробуем со словом \"trump\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7daffaa9-112b-4e0c-b438-22d7513b10dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bolognese', 0.543958842754364),\n",
       " ('bihdaydinner', 0.5348308086395264),\n",
       " ('cookout', 0.5301646590232849),\n",
       " ('spaghetti', 0.5297001004219055),\n",
       " ('lastnight', 0.5202850699424744),\n",
       " ('burritos', 0.5127542018890381),\n",
       " ('hamburger', 0.5086919069290161),\n",
       " ('tacotuesday', 0.5061419010162354),\n",
       " ('tummys', 0.5038057565689087),\n",
       " ('shawarma', 0.5026416778564453)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive=['dinner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e416932-ab2e-49d1-a167-448a01027229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald', 0.5652064085006714),\n",
       " ('suppoer', 0.5310891270637512),\n",
       " ('dumptrump', 0.5072934031486511),\n",
       " ('melo', 0.506415605545044),\n",
       " ('unfit', 0.5052813291549683),\n",
       " ('potus', 0.5034103393554688),\n",
       " ('cuck', 0.5002031922340393),\n",
       " ('fuhered', 0.49987703561782837),\n",
       " ('conman', 0.49885204434394836),\n",
       " ('unfavorability', 0.4971436858177185)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive=['trump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad439f-1a0a-4bdd-ad19-f4dfeff2bc5c",
   "metadata": {},
   "source": [
    "5. Из приведенных выше примеров мы видим, что наша модель word2vec хорошо справляется с поиском наиболее похожих слов для данного слова. Но как она это делает? Она изучила векторы для каждого уникального слова наших данных и использует косинусное сходство, чтобы найти наиболее похожие векторы (слова).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d30b18da-92ba-4bfc-91c4-01aabc3e27a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.53921765e-01, -1.50882328e+00,  1.23223193e-01,  2.03804940e-01,\n",
       "       -2.02758014e-01,  3.20326537e-01,  1.28303230e-01, -4.08637375e-02,\n",
       "       -1.40873445e-02, -1.26715809e-01, -2.39821017e-01, -4.68562663e-01,\n",
       "       -8.55437398e-01,  4.19450223e-01, -4.84234571e-01,  7.06048787e-01,\n",
       "        5.31541944e-01,  5.29132783e-01,  9.32122409e-01, -5.00904858e-01,\n",
       "       -2.01845244e-01,  2.33033478e-01, -5.18460035e-01,  3.41544211e-01,\n",
       "       -3.46907020e-01,  2.36726984e-01, -3.88577700e-01, -2.14445293e-01,\n",
       "        1.31052300e-01,  4.35426444e-01,  4.49210346e-01, -1.36421397e-01,\n",
       "       -6.21884227e-01,  2.56906480e-01, -3.58356088e-01,  1.54572353e-01,\n",
       "        2.48437479e-01, -5.00212073e-01,  1.77097976e-01,  4.90734011e-01,\n",
       "        9.22248065e-01,  3.93360257e-01, -1.00136886e-03,  5.64731240e-01,\n",
       "       -5.48365176e-01,  4.46165174e-01,  3.99055511e-01, -3.18298519e-01,\n",
       "       -6.59377933e-01, -7.08211362e-02, -9.05507356e-02,  1.44647509e-01,\n",
       "        6.81352377e-01, -2.43234605e-01,  5.91738410e-02,  1.75104454e-01,\n",
       "        4.63499606e-01, -2.38131970e-01, -1.93504155e-01, -5.09023190e-01,\n",
       "       -6.17357373e-01, -2.38679022e-01, -3.32826898e-02, -3.16281766e-01,\n",
       "        4.93904859e-01,  3.47820938e-01, -1.86073244e-01,  9.70448554e-02,\n",
       "       -7.09059760e-02, -6.56424046e-01,  1.79131880e-01, -2.33961523e-01,\n",
       "        1.04595497e-01,  8.87515321e-02,  1.41847804e-01, -1.05135632e+00,\n",
       "       -6.83070004e-01,  6.13620505e-02, -1.59875676e-01,  2.60639358e-02,\n",
       "       -3.22823256e-01, -7.81593174e-02, -1.96961850e-01,  1.04089931e-01,\n",
       "        4.64023978e-01,  2.99236804e-01, -8.03258196e-02, -9.03498381e-02,\n",
       "       -3.11827689e-01,  2.55141288e-01, -2.11763129e-01,  3.60266119e-01,\n",
       "       -3.76391977e-01,  5.59213459e-01,  7.95900598e-02, -4.06667769e-01,\n",
       "       -5.94771683e-01,  7.98809826e-01,  6.64072454e-01,  5.43868482e-01,\n",
       "        6.18314683e-01, -7.33755708e-01,  3.57215852e-02, -5.30806959e-01,\n",
       "       -2.18823835e-01,  1.96123645e-01,  2.33011112e-01, -6.57134473e-01,\n",
       "       -9.11405236e-02, -4.97877210e-01,  2.39005938e-01, -7.50545561e-01,\n",
       "       -8.27648640e-02, -4.45997626e-01,  6.67330861e-01, -7.05043152e-02,\n",
       "       -2.61305124e-01,  8.92798424e-01,  5.03440797e-01,  6.14396274e-01,\n",
       "        4.30527806e-01,  6.32079840e-02, -8.90745446e-02,  2.62493402e-01,\n",
       "       -3.19827385e-02,  2.27799313e-03, -1.20420083e-01,  5.95448501e-02,\n",
       "       -1.04527555e-01,  4.04254019e-01, -1.68637231e-01, -6.84325159e-01,\n",
       "        2.86786526e-01,  5.80232561e-01, -9.50586870e-02,  2.47257531e-01,\n",
       "       -3.23647112e-01, -1.06581002e-01,  1.65191829e-01,  2.71287024e-01,\n",
       "        3.14103186e-01,  3.12602639e-01,  5.77097118e-01,  1.19385147e+00,\n",
       "       -3.95733118e-02, -1.78794220e-01,  2.42534190e-01, -6.24276400e-01,\n",
       "        7.08889812e-02,  8.41110349e-02,  6.41956806e-01, -5.56001127e-01,\n",
       "       -7.59087861e-01,  5.77377342e-02, -4.11112100e-01, -1.06143010e+00,\n",
       "       -1.13914847e-01, -4.71892536e-01,  1.03521037e+00,  5.61630011e-01,\n",
       "        3.81893069e-01,  1.13205008e-01,  1.10162783e+00,  6.59321202e-03,\n",
       "       -1.35078147e-01,  1.15291653e-02, -1.55254290e-01,  2.92403042e-01,\n",
       "       -3.79534721e-01, -5.97039938e-01,  2.55405337e-01,  3.22344571e-01,\n",
       "        6.97462499e-01, -4.10749644e-01, -9.13182795e-01, -2.03526691e-01,\n",
       "        1.82858169e-01, -3.55444789e-01, -7.80672371e-01,  1.51241884e-01,\n",
       "       -4.87850964e-01,  1.30404547e-01,  3.48208606e-01, -1.84718892e-01,\n",
       "        5.51530182e-01,  5.31516969e-01, -1.03395201e-01, -3.11955847e-02,\n",
       "        2.27950811e-01, -1.38491318e-01,  4.38861817e-01, -6.72755539e-02,\n",
       "        5.40125072e-02,  4.87752378e-01, -4.77231166e-04,  3.46979022e-01,\n",
       "        7.09723011e-02, -5.24790227e-01,  4.17136997e-01, -1.41683921e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv['food']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba610e62-faa2-450b-9ff3-17151135d965",
   "metadata": {},
   "source": [
    "6. Поскольку наши данные содержат твиты, а не только слова, нам придется придумать способ использовать векторы слов из модели word2vec для создания векторного представления всего твита. Существует простое решение этой проблемы, мы можем просто взять среднее значение всех векторов слов, присутствующих в твите. Длина результирующего вектора будет одинаковой, то есть 200. Мы повторим тот же процесс для всех твитов в наших данных и получим их векторы. Теперь у нас есть 200 функций word2vec для наших данных.\n",
    "Необходимо создать вектор для каждого твита, взяв среднее значение векторов слов, присутствующих в твите. В цикле сделать:  vec += model_w2v[word].reshape((1, size))\n",
    "и поделить финальный вектор на количество слов в твите.\n",
    "На выходе должен получиться wordvec_df.shape = (49159, 200).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcbfd77f-9184-4de2-82e1-f604ad3f0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets2vec(tweets_list, size=200):\n",
    "    n_words = len(tweets_list)\n",
    "    vec = np.zeros((1, size))\n",
    "    if n_words == 0:\n",
    "        return vec\n",
    "    for word in tweets_list:\n",
    "        try:\n",
    "            vec += model_w2v.wv[word].reshape((1, size))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return vec / n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d8a59115-c480-4eb4-a840-58d185b18088",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df = combine_df['tweet_token'].apply(tweets2vec)\n",
    "wordvec_df = np.concatenate(wordvec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3d73561-60dd-411f-93cf-b283fcad4d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 200)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "77e1bff5-b6db-46c5-b807-d9f3fd5f385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordvec_df.pkl', 'wb') as f:\n",
    "    pickle.dump(wordvec_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599465d-9c2e-4ca7-9c67-bb24e167b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
