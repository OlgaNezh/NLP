{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcde1f0-1367-415b-8c06-b87dbe46920a",
   "metadata": {},
   "source": [
    "## Урок 5. Part-of-Speech разметка, NER, извлечение отношений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f6e61-bb12-4d94-9c7f-a19f031cd59b",
   "metadata": {},
   "source": [
    "### Тема “POS-tagger и NER”\n",
    "\n",
    "### Задание 1. Написать теггер на данных с русским языком\n",
    "проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации\n",
    "написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
    "сравнить все реализованные методы сделать выводы\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de344f51-6bf3-459c-abfe-22bb38df0b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyconll in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e3d39a-c6d1-4284-a00d-a694f79cb8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipymarkup in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: intervaltree>=3 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from ipymarkup) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipymarkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbac5cae-6a49-466b-954e-57fafee85681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: corus in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install corus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6cce2e-a43d-4a80-9efb-52ebfac7b3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (0.3.6)\n",
      "Requirement already satisfied: tqdm>=2.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from sklearn_crfsuite) (4.63.0)\n",
      "Requirement already satisfied: six in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from sklearn_crfsuite) (1.16.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from sklearn_crfsuite) (0.9.8)\n",
      "Requirement already satisfied: tabulate in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from sklearn_crfsuite) (0.8.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4ef3d4-bcd6-4ea5-9d6b-9776fa6b2ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (3.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (4.63.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (8.1.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (1.1.1)\n",
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    3.4.0                         \n",
      "Location         /Users/Olga/opt/anaconda3/lib/python3.9/site-packages/spacy\n",
      "Platform         macOS-10.13.6-x86_64-i386-64bit\n",
      "Python version   3.9.7                         \n",
      "Pipelines        ru_core_news_sm (3.4.0)       \n",
      "\n",
      "Collecting ru-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.4.0/ru_core_news_sm-3.4.0-py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: pymorphy2>=0.9 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from ru-core-news-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from ru-core-news-sm==3.4.0) (3.4.0)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.7.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.4.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.9.1)\n",
      "Requirement already satisfied: setuptools in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (58.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.63.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n",
      "Requirement already satisfied: slovnet in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (0.5.0)\n",
      "Requirement already satisfied: razdel in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from slovnet) (0.5.0)\n",
      "Requirement already satisfied: numpy in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from slovnet) (1.21.5)\n",
      "Requirement already satisfied: navec in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from slovnet) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "#nltk.download() \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pyconll\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "import corus\n",
    "!pip install -U spacy\n",
    "!python -m spacy info\n",
    "!python -m spacy download ru_core_news_sm\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import ru_core_news_sm\n",
    "!pip install slovnet\n",
    "from navec import Navec\n",
    "from slovnet import NER\n",
    "from ipymarkup import show_span_ascii_markup as show_markup\n",
    "from razdel import tokenize\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d1ee2b-78ec-4b47-9297-06d179c5685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = pyconll.load_from_file('ru_syntagrus-ud-train-a.conllu')\n",
    "full_test = pyconll.load_from_file('ru_syntagrus-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b41e58e-ae7a-40e1-92ed-b98200b99de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анкета NOUN\n",
      ". PUNCT\n",
      "\n",
      "Начальник NOUN\n",
      "областного ADJ\n",
      "управления NOUN\n",
      "связи NOUN\n",
      "Семен PROPN\n",
      "Еремеевич PROPN\n",
      "был AUX\n",
      "человек NOUN\n",
      "простой ADJ\n",
      ", PUNCT\n",
      "приходил VERB\n",
      "на ADP\n",
      "работу NOUN\n",
      "всегда ADV\n",
      "вовремя ADV\n",
      ", PUNCT\n",
      "здоровался VERB\n",
      "с ADP\n",
      "секретаршей NOUN\n",
      "за ADP\n",
      "руку NOUN\n",
      "и CCONJ\n",
      "иногда ADV\n",
      "даже PART\n",
      "писал VERB\n",
      "в ADP\n",
      "стенгазету NOUN\n",
      "заметки NOUN\n",
      "под ADP\n",
      "псевдонимом NOUN\n",
      "\" PUNCT\n",
      "Муха NOUN\n",
      "\" PUNCT\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in full_train[:2]:\n",
    "    for token in sent:\n",
    "        print(token.form, token.upos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c73c62-1a5b-4650-a550-07c426b3a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata_train = []\n",
    "for sent in full_train[:]:\n",
    "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_sent_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_sent_test.append([token.form for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e67980aa-a774-4890-887d-2c3bef6fbdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая длина предложения 194\n",
      "Наибольшая длина токена 31\n"
     ]
    }
   ],
   "source": [
    "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
    "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
    "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
    "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc19819-5b22-43c2-8585-abf43f295197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24516, 8906, 8906)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdata_train), len(fdata_test), len(fdata_sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a1f306-f66b-4635-b48c-3221798d0f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Анкета', 'NOUN'), ('.', 'PUNCT')],\n",
       " [('Начальник', 'NOUN'),\n",
       "  ('областного', 'ADJ'),\n",
       "  ('управления', 'NOUN'),\n",
       "  ('связи', 'NOUN'),\n",
       "  ('Семен', 'PROPN'),\n",
       "  ('Еремеевич', 'PROPN'),\n",
       "  ('был', 'AUX'),\n",
       "  ('человек', 'NOUN'),\n",
       "  ('простой', 'ADJ'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('приходил', 'VERB'),\n",
       "  ('на', 'ADP'),\n",
       "  ('работу', 'NOUN'),\n",
       "  ('всегда', 'ADV'),\n",
       "  ('вовремя', 'ADV'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('здоровался', 'VERB'),\n",
       "  ('с', 'ADP'),\n",
       "  ('секретаршей', 'NOUN'),\n",
       "  ('за', 'ADP'),\n",
       "  ('руку', 'NOUN'),\n",
       "  ('и', 'CCONJ'),\n",
       "  ('иногда', 'ADV'),\n",
       "  ('даже', 'PART'),\n",
       "  ('писал', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('стенгазету', 'NOUN'),\n",
       "  ('заметки', 'NOUN'),\n",
       "  ('под', 'ADP'),\n",
       "  ('псевдонимом', 'NOUN'),\n",
       "  ('\"', 'PUNCT'),\n",
       "  ('Муха', 'NOUN'),\n",
       "  ('\"', 'PUNCT'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('В', 'ADP'),\n",
       "  ('приемной', 'NOUN'),\n",
       "  ('его', 'PRON'),\n",
       "  ('с', 'ADP'),\n",
       "  ('утра', 'NOUN'),\n",
       "  ('ожидали', 'VERB'),\n",
       "  ('посетители', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('-', 'PUNCT'),\n",
       "  ('кое-кто', 'PRON'),\n",
       "  ('с', 'ADP'),\n",
       "  ('важными', 'ADJ'),\n",
       "  ('делами', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('а', 'CCONJ'),\n",
       "  ('кое-кто', 'PRON'),\n",
       "  ('и', 'PART'),\n",
       "  ('с', 'ADP'),\n",
       "  ('такими', 'DET'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('которые', 'PRON'),\n",
       "  ('легко', 'ADV'),\n",
       "  ('можно', 'ADV'),\n",
       "  ('было', 'AUX'),\n",
       "  ('решить', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('нижестоящих', 'ADJ'),\n",
       "  ('инстанциях', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('не', 'PART'),\n",
       "  ('затрудняя', 'VERB'),\n",
       "  ('Семена', 'PROPN'),\n",
       "  ('Еремеевича', 'PROPN'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('Однако', 'ADV'),\n",
       "  ('стиль', 'NOUN'),\n",
       "  ('работы', 'NOUN'),\n",
       "  ('Семена', 'PROPN'),\n",
       "  ('Еремеевича', 'PROPN'),\n",
       "  ('заключался', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('том', 'PRON'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('чтобы', 'SCONJ'),\n",
       "  ('принимать', 'VERB'),\n",
       "  ('всех', 'DET'),\n",
       "  ('желающих', 'VERB'),\n",
       "  ('и', 'CCONJ'),\n",
       "  ('лично', 'ADV'),\n",
       "  ('вникать', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('дело', 'NOUN'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('Приемная', 'NOUN'),\n",
       "  ('была', 'AUX'),\n",
       "  ('обставлена', 'VERB'),\n",
       "  ('просто', 'ADV'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('но', 'CCONJ'),\n",
       "  ('по-деловому', 'ADV'),\n",
       "  ('.', 'PUNCT')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c04657-e9f2-481e-9f88-18d96a2de319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823732013802982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unigram_tagger = UnigramTagger(fdata_train)\n",
    "accuracy_U = unigram_tagger.evaluate(fdata_test)\n",
    "display(accuracy_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a4bd1e8-b3cd-4854-b9d1-f1ed26d62e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6093886320724006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigram_tagger = BigramTagger(fdata_train)\n",
    "accuracy_B = bigram_tagger.evaluate(fdata_test)\n",
    "display(accuracy_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10afceef-e22c-4ae3-bb3e-4995d3a7457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1778631421316492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trigram_tagger = TrigramTagger(fdata_train)\n",
    "accuracy_T = trigram_tagger.evaluate(fdata_test)\n",
    "display(accuracy_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f37bfc8-a317-4bad-ae70-dab373021814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8275343446838986, 0.8273650628296113, 0.1750309264926102, 0.827905462595221]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1 = [UnigramTagger, BigramTagger]\n",
    "\n",
    "list_2 = [UnigramTagger, TrigramTagger]\n",
    "\n",
    "list_3 = [BigramTagger, TrigramTagger]\n",
    "\n",
    "list_4 = [UnigramTagger, BigramTagger, TrigramTagger]\n",
    "\n",
    "accuracy_N = []\n",
    "\n",
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "for list_N in [list_1, list_2, list_3, list_4]:\n",
    "    backoff = DefaultTagger('NN') \n",
    "    tag = backoff_tagger(fdata_train,  \n",
    "                         list_N,  \n",
    "                         backoff = backoff) \n",
    "\n",
    "    accuracy_N.append(tag.evaluate(fdata_test))\n",
    "\n",
    "accuracy_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3304c251-2fa4-4cac-8e56-1cc3300c92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd2e7848-647e-4d1a-9d55-c9420207eb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tagger</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UnigramTagger+BigramTagger+TrigramTagger</td>\n",
       "      <td>0.827905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unigram + Bigram</td>\n",
       "      <td>0.827534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnigramTagger + TrigramTagger</td>\n",
       "      <td>0.827365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unigram</td>\n",
       "      <td>0.823732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bigram</td>\n",
       "      <td>0.609389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trigram</td>\n",
       "      <td>0.177863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BigramTagger + TrigramTagger</td>\n",
       "      <td>0.175031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Tagger  Accuracy\n",
       "6  UnigramTagger+BigramTagger+TrigramTagger  0.827905\n",
       "3                          Unigram + Bigram  0.827534\n",
       "4             UnigramTagger + TrigramTagger  0.827365\n",
       "0                                   Unigram  0.823732\n",
       "1                                    Bigram  0.609389\n",
       "2                                   Trigram  0.177863\n",
       "5              BigramTagger + TrigramTagger  0.175031"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Tagger': ['Unigram', 'Bigram', 'Trigram', 'Unigram + Bigram', 'UnigramTagger + TrigramTagger', 'BigramTagger + TrigramTagger', 'UnigramTagger+BigramTagger+TrigramTagger'], 'Accuracy' : [accuracy_U, accuracy_B, accuracy_T] + accuracy_N})\n",
    "result.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b74aabf-eeb7-4b56-bcac-e99912f61d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = [] \n",
    "train_label = [] \n",
    "train_tok = []\n",
    "train_label = []\n",
    "for sent in fdata_train[:]:\n",
    "    for tok in sent:\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "        \n",
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in fdata_test[:]:\n",
    "    for tok in sent:\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b247a5ce-c1c1-4380-a577-071d7bd6ca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
       "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
       "       'VERB', 'X'], dtype='<U6')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(train_label)\n",
    "test_enc_labels = le.transform(test_label)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d17b3815-3dcf-4e06-9b73-ca5db84b0032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.92      0.91      0.92     11247\n",
      "         ADP       0.98      1.00      0.99     10255\n",
      "         ADV       0.92      0.90      0.91      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.88      0.75      0.81      2978\n",
      "        INTJ       0.33      0.36      0.35        11\n",
      "        NOUN       0.92      0.95      0.94     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.86      0.90      0.88      1436\n",
      "        PART       0.95      0.78      0.86      3762\n",
      "        PRON       0.83      0.89      0.86      5346\n",
      "       PROPN       0.79      0.59      0.67      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.91      0.86      2176\n",
      "         SYM       1.00      0.68      0.81        53\n",
      "        VERB       0.94      0.94      0.94     12617\n",
      "           X       0.47      0.16      0.24       105\n",
      "\n",
      "    accuracy                           0.93    115000\n",
      "   macro avg       0.85      0.82      0.82    115000\n",
      "weighted avg       0.93      0.93      0.93    115000\n",
      "\n",
      "TfidfVectorizer(analyzer='char', ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.91      0.91     11247\n",
      "         ADP       0.99      0.99      0.99     10255\n",
      "         ADV       0.92      0.86      0.89      5986\n",
      "         AUX       0.81      0.97      0.89      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.80      0.83      0.82      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.90      0.96      0.93     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.85      0.90      0.87      1436\n",
      "        PART       0.95      0.79      0.86      3762\n",
      "        PRON       0.87      0.84      0.86      5346\n",
      "       PROPN       0.80      0.52      0.63      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.91      0.86      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.93      0.93      0.93     12617\n",
      "           X       0.45      0.09      0.14       105\n",
      "\n",
      "    accuracy                           0.92    115000\n",
      "   macro avg       0.83      0.78      0.79    115000\n",
      "weighted avg       0.92      0.92      0.92    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.84      0.84     11247\n",
      "         ADP       0.97      0.98      0.98     10255\n",
      "         ADV       0.83      0.79      0.81      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.80      0.80      0.80      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.84      0.90      0.87     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.81      0.82      0.82      1436\n",
      "        PART       0.92      0.78      0.84      3762\n",
      "        PRON       0.84      0.86      0.85      5346\n",
      "       PROPN       0.72      0.45      0.55      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.88      0.84      0.86     12617\n",
      "           X       0.31      0.05      0.08       105\n",
      "\n",
      "    accuracy                           0.89    115000\n",
      "   macro avg       0.79      0.75      0.76    115000\n",
      "weighted avg       0.88      0.89      0.88    115000\n",
      "\n",
      "CountVectorizer(ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.95      0.40      0.57     11247\n",
      "         ADP       0.99      0.48      0.65     10255\n",
      "         ADV       0.96      0.78      0.86      5986\n",
      "         AUX       0.83      0.88      0.85      1058\n",
      "       CCONJ       0.90      0.20      0.33      4276\n",
      "         DET       0.77      0.78      0.77      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.98      0.68      0.80     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.88      0.51      0.65      1436\n",
      "        PART       0.97      0.75      0.84      3762\n",
      "        PRON       0.85      0.76      0.80      5346\n",
      "       PROPN       0.94      0.14      0.24      4315\n",
      "       PUNCT       0.37      1.00      0.54     21941\n",
      "       SCONJ       0.78      0.84      0.81      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.97      0.46      0.62     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.65    115000\n",
      "   macro avg       0.67      0.48      0.52    115000\n",
      "weighted avg       0.83      0.65      0.66    115000\n",
      "\n",
      "TfidfVectorizer(ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.95      0.44      0.60     11247\n",
      "         ADP       0.99      0.48      0.65     10255\n",
      "         ADV       0.96      0.78      0.86      5986\n",
      "         AUX       0.83      0.88      0.85      1058\n",
      "       CCONJ       0.89      0.20      0.33      4276\n",
      "         DET       0.90      0.64      0.75      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.98      0.68      0.80     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.89      0.55      0.68      1436\n",
      "        PART       0.97      0.75      0.84      3762\n",
      "        PRON       0.80      0.86      0.83      5346\n",
      "       PROPN       0.93      0.15      0.26      4315\n",
      "       PUNCT       0.38      1.00      0.55     21941\n",
      "       SCONJ       0.79      0.85      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.97      0.46      0.62     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.65    115000\n",
      "   macro avg       0.68      0.48      0.52    115000\n",
      "weighted avg       0.84      0.65      0.66    115000\n",
      "\n",
      "HashingVectorizer(n_features=1000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.43      0.21      0.28     11247\n",
      "         ADP       0.83      0.47      0.60     10255\n",
      "         ADV       0.59      0.63      0.61      5986\n",
      "         AUX       0.70      0.94      0.80      1058\n",
      "       CCONJ       0.84      0.18      0.30      4276\n",
      "         DET       0.49      0.55      0.52      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.25      0.53      0.34     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.41      0.43      0.42      1436\n",
      "        PART       0.86      0.76      0.81      3762\n",
      "        PRON       0.64      0.76      0.70      5346\n",
      "       PROPN       0.32      0.08      0.13      4315\n",
      "       PUNCT       0.00      0.00      0.00     21941\n",
      "       SCONJ       0.67      0.95      0.78      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.45      0.25      0.32     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.37    115000\n",
      "   macro avg       0.42      0.38      0.37    115000\n",
      "weighted avg       0.39      0.37      0.35    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.87      0.87     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.87      0.82      0.84      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.84      0.75      0.80      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.86      0.93      0.89     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.83      0.84      0.83      1436\n",
      "        PART       0.94      0.78      0.85      3762\n",
      "        PRON       0.83      0.89      0.85      5346\n",
      "       PROPN       0.74      0.41      0.53      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.89      0.88      0.89     12617\n",
      "           X       0.38      0.06      0.10       105\n",
      "\n",
      "    accuracy                           0.90    115000\n",
      "   macro avg       0.81      0.76      0.77    115000\n",
      "weighted avg       0.90      0.90      0.90    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.88      0.87     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.88      0.83      0.85      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.95      0.67      0.79      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.87      0.93      0.90     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.82      0.84      0.83      1436\n",
      "        PART       0.95      0.77      0.85      3762\n",
      "        PRON       0.79      0.93      0.86      5346\n",
      "       PROPN       0.78      0.39      0.52      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.79      0.88        53\n",
      "        VERB       0.88      0.90      0.89     12617\n",
      "           X       0.28      0.10      0.15       105\n",
      "\n",
      "    accuracy                           0.90    115000\n",
      "   macro avg       0.81      0.77      0.78    115000\n",
      "weighted avg       0.90      0.90      0.90    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.88      0.88     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.90      0.83      0.86      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.83      0.78      0.81      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.87      0.94      0.90     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.84      0.87      0.85      1436\n",
      "        PART       0.94      0.78      0.85      3762\n",
      "        PRON       0.83      0.86      0.85      5346\n",
      "       PROPN       0.76      0.41      0.54      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.89      0.90      0.89     12617\n",
      "           X       0.50      0.05      0.09       105\n",
      "\n",
      "    accuracy                           0.91    115000\n",
      "   macro avg       0.82      0.77      0.77    115000\n",
      "weighted avg       0.90      0.91      0.90    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=10000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.88      0.88     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.90      0.84      0.87      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.83      0.78      0.81      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.88      0.94      0.91     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.84      0.88      0.86      1436\n",
      "        PART       0.94      0.79      0.85      3762\n",
      "        PRON       0.82      0.87      0.85      5346\n",
      "       PROPN       0.78      0.42      0.54      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.82      0.86      0.84      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.90      0.90      0.90     12617\n",
      "           X       0.71      0.05      0.09       105\n",
      "\n",
      "    accuracy                           0.91    115000\n",
      "   macro avg       0.83      0.77      0.78    115000\n",
      "weighted avg       0.91      0.91      0.90    115000\n",
      "\n",
      "HashingVectorizer(n_features=2000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.50      0.26      0.34     11247\n",
      "         ADP       0.90      0.48      0.62     10255\n",
      "         ADV       0.68      0.69      0.68      5986\n",
      "         AUX       0.75      0.94      0.84      1058\n",
      "       CCONJ       0.89      0.18      0.31      4276\n",
      "         DET       0.67      0.53      0.59      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.61      0.58      0.59     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.53      0.47      0.50      1436\n",
      "        PART       0.91      0.76      0.83      3762\n",
      "        PRON       0.69      0.85      0.76      5346\n",
      "       PROPN       0.39      0.10      0.15      4315\n",
      "       PUNCT       0.48      1.00      0.65     21941\n",
      "       SCONJ       0.76      0.90      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.55      0.31      0.39     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.58    115000\n",
      "   macro avg       0.52      0.45      0.45    115000\n",
      "weighted avg       0.62      0.58      0.56    115000\n",
      "\n",
      "HashingVectorizer(n_features=3000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.55      0.30      0.39     11247\n",
      "         ADP       0.92      0.48      0.63     10255\n",
      "         ADV       0.77      0.71      0.74      5986\n",
      "         AUX       0.77      0.94      0.85      1058\n",
      "       CCONJ       0.93      0.18      0.30      4276\n",
      "         DET       0.71      0.57      0.63      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.65      0.60      0.62     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.61      0.49      0.54      1436\n",
      "        PART       0.90      0.78      0.84      3762\n",
      "        PRON       0.74      0.83      0.79      5346\n",
      "       PROPN       0.44      0.12      0.18      4315\n",
      "       PUNCT       0.47      1.00      0.64     21941\n",
      "       SCONJ       0.73      0.95      0.83      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.60      0.34      0.43     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.60    115000\n",
      "   macro avg       0.54      0.46      0.47    115000\n",
      "weighted avg       0.65      0.60      0.58    115000\n",
      "\n",
      "HashingVectorizer(n_features=5000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.63      0.33      0.44     11247\n",
      "         ADP       0.91      0.48      0.63     10255\n",
      "         ADV       0.82      0.72      0.77      5986\n",
      "         AUX       0.79      0.95      0.86      1058\n",
      "       CCONJ       0.92      0.19      0.31      4276\n",
      "         DET       0.69      0.70      0.70      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.70      0.62      0.65     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.66      0.48      0.55      1436\n",
      "        PART       0.91      0.76      0.83      3762\n",
      "        PRON       0.79      0.79      0.79      5346\n",
      "       PROPN       0.54      0.13      0.21      4315\n",
      "       PUNCT       0.45      1.00      0.62     21941\n",
      "       SCONJ       0.76      0.88      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.67      0.36      0.47     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.61    115000\n",
      "   macro avg       0.57      0.47      0.48    115000\n",
      "weighted avg       0.68      0.61      0.59    115000\n",
      "\n",
      "HashingVectorizer(n_features=10000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.72      0.36      0.48     11247\n",
      "         ADP       0.96      0.48      0.64     10255\n",
      "         ADV       0.88      0.75      0.81      5986\n",
      "         AUX       0.81      0.88      0.84      1058\n",
      "       CCONJ       0.88      0.20      0.33      4276\n",
      "         DET       0.72      0.75      0.74      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.77      0.64      0.70     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.74      0.58      0.65      1436\n",
      "        PART       0.96      0.75      0.84      3762\n",
      "        PRON       0.83      0.78      0.81      5346\n",
      "       PROPN       0.67      0.15      0.24      4315\n",
      "       PUNCT       0.42      1.00      0.59     21941\n",
      "       SCONJ       0.78      0.88      0.83      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.75      0.41      0.53     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.63    115000\n",
      "   macro avg       0.60      0.48      0.50    115000\n",
      "weighted avg       0.73      0.63      0.62    115000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizers = [CountVectorizer(ngram_range=(1, 3), analyzer='char'), \n",
    "               TfidfVectorizer(ngram_range=(1, 3), analyzer='char'), \n",
    "               HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=1000)] \n",
    "vectorizers_word = [CountVectorizer(ngram_range=(1, 3), analyzer='word'), \n",
    "               TfidfVectorizer(ngram_range=(1, 3), analyzer='word'), \n",
    "               HashingVectorizer(ngram_range=(1, 3), analyzer='word', n_features=1000)] \n",
    "n_features = [2000, 3000, 5000, 10000]\n",
    "vectorizers_hash = [HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=feat) for feat in n_features]\n",
    "vectorizers_hash_word = [HashingVectorizer(ngram_range=(1, 3), analyzer='word', n_features=feat) for feat in n_features]\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for vectorizer in vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word:\n",
    "    X_train = vectorizer.fit_transform(train_tok)\n",
    "    X_test = vectorizer.transform(test_tok[:115000])\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0, max_iter=100)\n",
    "    lr.fit(X_train, train_enc_labels)\n",
    "    pred = lr.predict(X_test)\n",
    "    f1 = f1_score(test_enc_labels[:115000], pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    acc = accuracy_score(test_enc_labels[:115000], pred)\n",
    "    accuracy_scores.append(acc)\n",
    "    \n",
    "    print(vectorizer)\n",
    "    print(classification_report(test_enc_labels[:115000], pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "927242ec-9954-4b7b-b5ad-4b7fac23fba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.927836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.921158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.903641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.901222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.897044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.895273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.882215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.662699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.656861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HashingVectorizer(n_features=10000, ngram_rang...</td>\n",
       "      <td>0.619406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HashingVectorizer(n_features=5000, ngram_range...</td>\n",
       "      <td>0.594828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HashingVectorizer(n_features=3000, ngram_range...</td>\n",
       "      <td>0.577165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HashingVectorizer(n_features=2000, ngram_range...</td>\n",
       "      <td>0.555762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HashingVectorizer(n_features=1000, ngram_range...</td>\n",
       "      <td>0.345039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Vectorizer  f1_score\n",
       "0   CountVectorizer(analyzer='char', ngram_range=(...  0.927836\n",
       "1   TfidfVectorizer(analyzer='char', ngram_range=(...  0.921158\n",
       "9   HashingVectorizer(analyzer='char', n_features=...  0.903641\n",
       "8   HashingVectorizer(analyzer='char', n_features=...  0.901222\n",
       "7   HashingVectorizer(analyzer='char', n_features=...  0.897044\n",
       "6   HashingVectorizer(analyzer='char', n_features=...  0.895273\n",
       "2   HashingVectorizer(analyzer='char', n_features=...  0.882215\n",
       "4                 TfidfVectorizer(ngram_range=(1, 3))  0.662699\n",
       "3                 CountVectorizer(ngram_range=(1, 3))  0.656861\n",
       "13  HashingVectorizer(n_features=10000, ngram_rang...  0.619406\n",
       "12  HashingVectorizer(n_features=5000, ngram_range...  0.594828\n",
       "11  HashingVectorizer(n_features=3000, ngram_range...  0.577165\n",
       "10  HashingVectorizer(n_features=2000, ngram_range...  0.555762\n",
       "5   HashingVectorizer(n_features=1000, ngram_range...  0.345039"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word,\n",
    "                            'f1_score': f1_scores})\n",
    "result_model.sort_values('f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bea321d7-edaf-4610-a025-0bfb42f1f12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.929513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.923583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.907417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.901357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.898939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.885157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.652983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.647391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HashingVectorizer(n_features=10000, ngram_rang...</td>\n",
       "      <td>0.628617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HashingVectorizer(n_features=5000, ngram_range...</td>\n",
       "      <td>0.612913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HashingVectorizer(n_features=3000, ngram_range...</td>\n",
       "      <td>0.601191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HashingVectorizer(n_features=2000, ngram_range...</td>\n",
       "      <td>0.584009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HashingVectorizer(n_features=1000, ngram_range...</td>\n",
       "      <td>0.365243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Vectorizer  Accuracy\n",
       "0   CountVectorizer(analyzer='char', ngram_range=(...  0.929513\n",
       "1   TfidfVectorizer(analyzer='char', ngram_range=(...  0.923583\n",
       "9   HashingVectorizer(analyzer='char', n_features=...  0.907417\n",
       "8   HashingVectorizer(analyzer='char', n_features=...  0.905000\n",
       "7   HashingVectorizer(analyzer='char', n_features=...  0.901357\n",
       "6   HashingVectorizer(analyzer='char', n_features=...  0.898939\n",
       "2   HashingVectorizer(analyzer='char', n_features=...  0.885157\n",
       "4                 TfidfVectorizer(ngram_range=(1, 3))  0.652983\n",
       "3                 CountVectorizer(ngram_range=(1, 3))  0.647391\n",
       "13  HashingVectorizer(n_features=10000, ngram_rang...  0.628617\n",
       "12  HashingVectorizer(n_features=5000, ngram_range...  0.612913\n",
       "11  HashingVectorizer(n_features=3000, ngram_range...  0.601191\n",
       "10  HashingVectorizer(n_features=2000, ngram_range...  0.584009\n",
       "5   HashingVectorizer(n_features=1000, ngram_range...  0.365243"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model_acc = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word,\n",
    "                            'Accuracy': accuracy_scores})\n",
    "result_model_acc.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcfdc558-3987-4231-9197-d188785ee824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tagger</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UnigramTagger+BigramTagger+TrigramTagger</td>\n",
       "      <td>0.827905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Tagger  Accuracy\n",
       "6  UnigramTagger+BigramTagger+TrigramTagger  0.827905"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values('Accuracy', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebf5d763-0455-4749-b76c-05f97e534bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.927836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Vectorizer  f1_score\n",
       "0  CountVectorizer(analyzer='char', ngram_range=(...  0.927836"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model.sort_values('f1_score', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a591ccd-da5d-49a4-bd43-25e0f05af132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.929513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Vectorizer  Accuracy\n",
       "0  CountVectorizer(analyzer='char', ngram_range=(...  0.929513"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model_acc.sort_values('Accuracy', ascending=False).head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476ba7b-7f47-46c2-a3bd-0d7aae1a31ad",
   "metadata": {},
   "source": [
    "### Задание 2. Проверить насколько хорошо работает NER\n",
    "данные брать из http://www.labinform.ru/pub/named_entities/\n",
    "проверить NER из nltk/spacy/deeppavlov\n",
    "написать свой нер попробовать разные подходы\n",
    "передаём в сетку токен и его соседей\n",
    "передаём в сетку только токен\n",
    "свой вариант\n",
    "сравнить ваши реализованные подходы на качество (вывести precision/recall/f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f9d9c29-b6bb-48dd-b0b5-8dd986e70796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1040.ann', '1047.txt', '289.txt', '504.txt', '517.ann', '271.ann', '262.txt', '276.txt', '20_11_12a.txt', '265.ann', '503.ann', '510.txt', '538.txt', '04_12_12f.ann', '259.ann', '28_11_12g.txt', '2039.ann', '2011.ann', '2002.txt', '2016.txt', '098.ann', '2005.ann', '060.txt', '073.ann', '067.ann', '074.txt', '048.txt', '114.txt', '107.ann', '113.ann', '100.txt', '128.txt', '1134.ann', '1127.txt', '1133.txt', '1120.ann', '1108.ann', '488.ann', '470.txt', 'last_42.txt', 'last_51.ann', '463.ann', 'turkmenija.ann', '305.ann', '316.txt', '302.txt', '311.ann', 'last_45.ann', '477.ann', '464.txt', 'last_56.txt', '339.ann', '458.txt', '459.txt', '338.ann', '310.ann', '303.txt', 'last_57.txt', '465.txt', 'shojgu4.txt', '476.ann', 'last_44.ann', '462.ann', 'last_50.ann', 'last_43.txt', 'shojgu3.ann', '471.txt', '317.txt', '304.ann', '489.ann', '1109.ann', '1121.ann', '1132.txt', '1126.txt', '1135.ann', '129.txt', '101.txt', '112.ann', '106.ann', '115.txt', 'Avtovaz.ann', '049.txt', '075.txt', '066.ann', '072.ann', '061.txt', '2004.ann', '099.ann', '2017.txt', '2003.txt', '2010.ann', '28_11_12a.ann', '2038.ann', '28_11_12f.txt', '258.ann', '539.txt', '04_12_12g.ann', '264.ann', '277.txt', '511.txt', '502.ann', '516.ann', '505.txt', '263.txt', '270.ann', '288.txt', '1046.txt', '1041.ann', '1044.txt', '1043.ann', '1050.txt', '299.ann', '500.ann', '513.txt', '20_11_12b.txt', '275.txt', '266.ann', '272.ann', '261.txt', '507.txt', '514.ann', '249.txt', '04_12_12b.txt', '528.ann', '2029.txt', '2015.txt', '2006.ann', '088.txt', '2012.ann', '2001.txt', '064.ann', '077.txt', 'blokhin.txt', '063.txt', '070.ann', '058.ann', '19_11_12h.ann', '110.ann', '103.txt', '117.txt', '104.ann', '533 (!).txt', '138.ann', '1130.txt', '1123.ann', '1137.ann', '1124.txt', '498.txt', '1118.txt', 'last_46.ann', '474.ann', 'shojgu6.txt', '467.txt', 'last_55.txt', '301.txt', '312.ann', '306.ann', '315.txt', '473.txt', 'shojgu1.ann', 'last_41.txt', 'last_52.ann', '460.ann', 'last_69.txt', '448.ann', '329.txt', '328.txt', '449.ann', 'last_68.txt', '314.txt', '307.ann', '461.ann', 'last_53.ann', 'last_40.txt', '472.txt', 'last_54.txt', '466.txt', '475.ann', 'last_47.ann', '313.ann', '300.txt', '1119.txt', '499.txt', '1125.txt', '1136.ann', '1122.ann', '1131.txt', '139.ann', '105.ann', '116.txt', '102.txt', '111.ann', '059.ann', '071.ann', '062.txt', '076.txt', '065.ann', '2013.ann', '089.txt', '2007.ann', '14_01_13i.txt', '2014.txt', '2028.txt', '04_12_12d.ann', '529.ann', '248.txt', '260.txt', '20_11_12d.ann', '273.ann', '515.ann', '506.txt', '512.txt', '501.ann', '267.ann', '20_11_12c.txt', '274.txt', '04_12_12h_corr.txt', '298.ann', '1042.ann', '1045.txt', '288.ann', '1041.txt', '1046.ann', '04_12_12g.txt', '539.ann', '258.txt', '270.txt', '263.ann', '505.ann', '516.txt', '502.txt', '511.ann', '277.ann', '264.txt', '2010.txt', '2003.ann', '099.txt', '2017.ann', '2004.txt', '28_11_12f.ann', '2038.txt', '28_11_12a.txt', '049.ann', '061.ann', '072.txt', '066.txt', '075.ann', 'Avtovaz.txt', '129.ann', '115.ann', '106.txt', '112.txt', '101.ann', '1109.txt', '489.txt', '1135.txt', '1126.ann', '1132.ann', '1121.txt', '338.txt', '459.ann', '304.txt', '317.ann', 'last_43.ann', 'shojgu3.txt', '471.ann', '462.txt', 'last_50.txt', 'shojgu4.ann', '476.txt', 'last_44.txt', 'last_57.ann', '465.ann', '303.ann', '310.txt', '464.ann', 'last_56.ann', 'last_45.txt', '477.txt', '311.txt', '302.ann', '316.ann', 'turkmenija.txt', '305.txt', 'last_51.txt', '463.txt', '470.ann', 'last_42.ann', '458.ann', '339.txt', '1120.txt', '1133.ann', '1127.ann', '1134.txt', '488.txt', '1108.txt', '100.ann', '113.txt', '107.txt', '114.ann', '128.ann', '074.ann', '067.txt', '073.txt', '060.ann', '048.ann', '2039.txt', '28_11_12g.ann', '2005.txt', '2016.ann', '098.txt', '2002.ann', '2011.txt', '510.ann', '503.txt', '265.txt', '276.ann', '20_11_12a.ann', '262.ann', '271.txt', '517.txt', '504.ann', '259.txt', '04_12_12f.txt', '538.ann', '1047.ann', '1040.txt', '289.ann', '298.txt', '04_12_12h_corr.ann', '1045.ann', '1042.txt', '248.ann', '529.txt', '04_12_12d.txt', '20_11_12c.ann', '274.ann', '267.txt', '501.txt', '512.ann', '506.ann', '515.txt', '20_11_12d.txt', '273.txt', '260.ann', '2014.ann', '089.ann', '2007.txt', '14_01_13i.ann', '2013.txt', '2028.ann', '059.txt', '065.txt', '076.ann', '062.ann', '071.txt', '139.txt', '111.txt', '102.ann', '116.ann', '105.txt', '499.ann', '1119.ann', '1131.ann', '1122.txt', '1136.txt', '1125.ann', 'last_68.ann', '449.txt', '328.ann', '300.ann', '313.txt', '475.txt', 'last_47.txt', 'last_54.ann', '466.ann', 'last_40.ann', '472.ann', '461.txt', 'last_53.txt', '307.txt', '314.ann', 'last_52.txt', '460.txt', '473.ann', 'shojgu1.txt', 'last_41.ann', '315.ann', '306.txt', '312.txt', '301.ann', '467.ann', 'last_55.ann', 'last_46.txt', '474.txt', 'shojgu6.ann', '329.ann', '448.txt', 'last_69.ann', '1124.ann', '1137.txt', '1123.txt', '1130.ann', '1118.ann', '498.ann', '104.txt', '117.ann', '103.ann', '110.txt', '138.txt', '533 (!).ann', '19_11_12h.txt', '070.txt', '063.ann', 'blokhin.ann', '077.ann', '064.txt', '058.txt', '2029.ann', '2001.ann', '2012.txt', '2006.txt', '088.ann', '2015.ann', '514.txt', '507.ann', '261.ann', '272.txt', '266.txt', '20_11_12b.ann', '275.ann', '513.ann', '500.txt', '528.txt', '249.ann', '04_12_12b.ann', '1050.ann', '1043.txt', '1044.ann', '299.txt', '1030.txt', '1023.ann', '1037.ann', '1024.txt', '1018.txt', '09_01_13e.txt', '201.txt', '212.ann', '574.ann', '567.txt', '560.ann', '206.ann', '215.txt', '548.ann', '229.txt', '2049.txt', '010.ann', '003.txt', '017.txt', '004.ann', '27_11_12e.txt', '03_12_12b.ann', '10_01_13a.txt', '038.ann', '188.txt', '611.txt', '602.ann', '164.ann', '177.txt', '163.txt', '170.ann', '616.ann', '21_11_12i.ann', '158.ann', 'kuleshov.ann', '22_11_12g.ann', '1144.txt', '1157.ann', '1143.ann', '1150.txt', '399.ann', '1178.txt', '375.txt', '366.ann', 'last_32.ann', '1194.ann', '400.ann', '413.txt', '1187.txt', 'last_21.txt', '1193.txt', '407.txt', 'last_35.txt', 'last_26.ann', '414.ann', '1180.ann', '372.ann', '361.txt', '349.txt', '428.ann', 'last_09.txt', 'last_08.txt', '429.ann', '348.txt', '1181.ann', '415.ann', 'last_27.ann', 'last_34.txt', '406.txt', '1192.txt', '360.txt', '373.ann', '367.ann', '374.txt', 'last_20.txt', '1186.txt', '412.txt', 'lenoblast.txt', '401.ann', '1195.ann', 'last_33.ann', '15_01_13b.ann', '09_01_13.txt', '398.ann', '1179.txt', '15_01_13e.txt', '1151.txt', '1142.ann', '22_11_12a.txt', '1156.ann', '1145.txt', '159.ann', '171.ann', '162.txt', '21_11_12h.ann', '617.ann', '610.txt', '176.txt', '165.ann', '189.txt', '039.ann', '03_12_12d.txt', '03_12_12c.ann', '005.ann', '016.txt', '25_12_12a.ann', '27_11_12d.txt', '27_11_12c.ann', '002.txt', '011.ann', '2048.txt', '228.txt', '549.ann', '561.ann', '572.txt', '214.txt', '207.ann', '213.ann', '200.txt', '575.ann', '09_01_13d.txt', '1019.txt', '599.txt', '09_01_13c.ann', '1025.txt', '1036.ann', '1022.ann', '1031.txt', '1034.ann', '1027.txt', '1033.txt', '1020.ann', '1008.ann', '09_01_13a.ann', '588.ann', '205.ann', '216.txt', '570.txt', '563.ann', '577.ann', '564.txt', '202.txt', '211.ann', '239.ann', '558.txt', '25_12_12c.ann', '014.txt', '007.ann', '013.ann', '25_12_12d.txt', '27_11_12a.ann', '028.txt', 'mvd2.ann', '03_12_12a.ann', '198.ann', 'rosobrnadzor.txt', '615.ann', '21_11_12j.ann', '30_11_12h.ann', '160.txt', '173.ann', '167.ann', '174.txt', '612.txt', '601.ann', '629.ann', '148.txt', '22_11_12c.txt', '1140.ann', '1153.txt', '1147.txt', '1154.ann', '22_11_12d.ann', '1168.ann', '389.txt', '371.ann', '362.txt', '1190.txt', '404.txt', 'last_36.txt', 'last_25.ann', '417.ann', '1183.ann', 'last_31.ann', '1197.ann', '403.ann', '410.txt', '1184.txt', 'last_22.txt', '376.txt', '365.ann', 'last_19.ann', '438.txt', '359.ann', '358.ann', '439.txt', 'last_18.ann', 'last_23.txt', '1185.txt', '411.txt', '402.ann', '1196.ann', '364.ann', '377.txt', '363.txt', '370.ann', '1182.ann', '416.ann', 'last_24.ann', 'last_37.txt', '405.txt', '1191.txt', '15_01_13f.txt', '1169.ann', '388.txt', '15_01_13a.ann', '1155.ann', '1146.txt', 'chirkunov.ann', '1152.txt', '1141.ann', '149.txt', '628.ann', '175.txt', '166.ann', '600.ann', '613.txt', '30_11_12i.ann', '614.ann', '172.ann', '161.txt', '199.ann', '03_12_12g.txt', '029.txt', '10_01_13d.ann', '598 (!).ann', '001.txt', '012.ann', '25_12_12e.txt', '006.ann', '559.txt', '238.ann', '565.txt', '576.ann', '210.ann', '203.txt', '217.txt', '204.ann', '562.ann', '571.txt', '589.ann', '1009.ann', '1021.ann', '1032.txt', '1026.txt', '1035.ann', '09_01_13c.txt', '599.ann', '09_01_13d.ann', '1019.ann', '1031.ann', '1022.txt', '1036.txt', '1025.ann', '549.txt', '228.ann', '575.txt', '200.ann', '213.txt', '207.txt', '214.ann', '572.ann', '561.txt', '2048.ann', '03_12_12c.txt', '03_12_12d.ann', '039.txt', '011.txt', '002.ann', '27_11_12c.txt', '25_12_12a.txt', '27_11_12d.ann', '016.ann', '005.txt', '189.ann', '159.txt', '165.txt', '176.ann', '610.ann', '21_11_12h.txt', '617.txt', '162.ann', '171.txt', '1179.ann', '15_01_13e.ann', '09_01_13.ann', '398.txt', '15_01_13b.txt', '1145.ann', '1156.txt', '22_11_12a.ann', '1142.txt', '1151.ann', '348.ann', '429.txt', 'last_08.ann', 'lenoblast.ann', '1195.txt', '401.txt', 'last_33.txt', 'last_20.ann', '412.ann', '1186.ann', '374.ann', '367.txt', '373.txt', '360.ann', 'last_34.ann', '1192.ann', '406.ann', '415.txt', '1181.txt', 'last_27.txt', '361.ann', '372.txt', 'last_26.txt', '1180.txt', '414.txt', '407.ann', '1193.ann', 'last_35.ann', '1187.ann', '413.ann', 'last_21.ann', 'last_32.txt', '400.txt', '1194.txt', '366.txt', '375.ann', 'last_09.ann', '428.txt', '349.ann', '1150.ann', '1143.txt', '1157.txt', '1144.ann', '22_11_12g.txt', 'kuleshov.txt', '1178.ann', '399.txt', '616.txt', '21_11_12i.txt', '170.txt', '163.ann', '177.ann', '164.txt', '602.txt', '611.ann', '158.txt', '188.ann', '27_11_12e.ann', '004.txt', '017.ann', '003.ann', '010.txt', '038.txt', '10_01_13a.ann', '03_12_12b.txt', '2049.ann', '215.ann', '206.txt', '560.txt', '567.ann', '574.txt', '212.txt', '201.ann', '229.ann', '548.txt', '1024.ann', '1037.txt', '1023.txt', '1030.ann', '1018.ann', '09_01_13e.ann', '1009.txt', '589.txt', '1035.txt', '1026.ann', '1032.ann', '1021.txt', '238.txt', '559.ann', '571.ann', '562.txt', '204.txt', '217.ann', '203.ann', '210.txt', '576.txt', '565.ann', '598 (!).txt', '029.ann', '10_01_13d.txt', '03_12_12g.ann', '006.txt', '25_12_12e.ann', '012.txt', '001.ann', '199.txt', '628.txt', '149.ann', '161.ann', '172.txt', '614.txt', '30_11_12i.txt', '613.ann', '600.txt', '166.txt', '175.ann', '15_01_13a.txt', '388.ann', '1169.txt', '15_01_13f.ann', '1141.txt', '1152.ann', 'chirkunov.txt', '1146.ann', '1155.txt', 'last_18.txt', '439.ann', '358.txt', 'last_37.ann', '1191.ann', '405.ann', '416.txt', '1182.txt', 'last_24.txt', '370.txt', '363.ann', '377.ann', '364.txt', '1196.txt', '402.txt', 'last_23.ann', '411.ann', '1185.ann', '365.txt', '376.ann', '1184.ann', '410.ann', 'last_22.ann', 'last_31.txt', '403.txt', '1197.txt', 'last_25.txt', '1183.txt', '417.txt', '404.ann', '1190.ann', 'last_36.ann', '362.ann', '371.txt', '359.txt', '438.ann', 'last_19.txt', '22_11_12d.txt', '1154.txt', '1147.ann', '1153.ann', '1140.txt', '22_11_12c.ann', '389.ann', '1168.txt', '601.txt', '612.ann', '174.ann', '167.txt', '173.txt', '160.ann', '30_11_12h.txt', '615.txt', '21_11_12j.txt', '148.ann', '629.txt', 'rosobrnadzor.ann', '198.txt', '25_12_12d.ann', '27_11_12a.txt', '013.txt', '007.txt', '014.ann', '25_12_12c.txt', '03_12_12a.txt', 'mvd2.txt', '028.ann', '211.txt', '202.ann', '564.ann', '577.txt', '563.txt', '570.ann', '216.ann', '205.txt', '558.ann', '239.txt', '1020.txt', '1033.ann', '1027.ann', '1034.txt', '09_01_13a.txt', '588.txt', '1008.txt', '596.ann', '1002.ann', '1011.txt', '585.txt', '591.txt', '1005.txt', '1016.ann', '582.ann', '1039.txt', '233.ann', '220.txt', '546.txt', '541.ann', '552.txt', '234.txt', '227.ann', '569.ann', '208.txt', '1200.ann', '2040.txt', '2047.ann', '022.txt', '031.ann', '025.ann', '036.txt', 'uchitel.txt', '019.ann', '186.ann', '195.txt', '181.txt', '192.ann', '623.ann', '630.txt', '156.txt', '145.ann', '151.ann', '142.txt', '624.txt', 'si_tzjanpin.txt', '30_11_12b.ann', '179.ann', '618.txt', '397.txt', '384.ann', '1176.ann', '1165.txt', '1171.txt', '1162.ann', '390.ann', '383.txt', '22_11_12i.txt', '29_11_12a.txt', '1159.txt', '347.ann', '354.txt', '432.txt', 'last_13.ann', '421.ann', '435.ann', '426.txt', 'last_14.txt', '340.txt', '353.ann', '368.txt', '1189.ann', 'last_28.txt', '409.ann', '408.ann', 'last_29.txt', '369.txt', '1188.ann', 'last_15.txt', '427.txt', '434.ann', 'last_06.ann', '352.ann', '341.txt', '355.txt', '346.ann', '420.ann', 'last_12.ann', 'last_01.txt', 'sobjanin2.ann', '433.txt', '22_11_12h.txt', '1158.txt', '1163.ann', '1170.txt', '382.txt', '391.ann', '385.ann', '396.txt', '1164.txt', '1177.ann', '619.txt', '178.ann', '143.txt', '150.ann', '625.txt', '631.txt', '622.ann', '144.ann', '157.txt', '193.ann', '180.txt', '194.txt', '187.ann', '018.ann', '27_11_12j.ann', '037.txt', '10_01_13i.txt', '030.ann', '023.txt', '2046.ann', '2041.txt', '209.txt', '568.ann', '553.txt', 'chaves.txt', '540.ann', '226.ann', '235.txt', '221.txt', '232.ann', '554.ann', '547.txt', '1038.txt', '583.ann', '1017.ann', '1004.txt', '590.txt', '1010.txt', '1003.ann', '597.ann', '592.txt', '1006.txt', '09_01_13h.ann', '1015.ann', '581.ann', '595.ann', '1001.ann', '1012.txt', '586.txt', 'last_07_new.ann', '1029.ann', '237.txt', '224.ann', 'kamchatka.txt', '542.ann', '551.txt', '545.txt', '556.ann', '230.ann', '223.txt', '218.ann', '579.txt', 'last_30_new.txt', '2044.ann', '2050.ann', '2043.txt', '03_12_12h.ann', '026.ann', '035.txt', '021.txt', '032.ann', '009.txt', '182.txt', '191.ann', '185.ann', '196.txt', '627.txt', '152.ann', '141.txt', '155.txt', '146.ann', '620.ann', '633.txt', '169.txt', '21_11_12c.ann', '393.ann', 'artjakov.txt', '380.txt', '1172.txt', '1161.ann', '1175.ann', '1166.txt', '394.txt', '387.ann', '1149.ann', '22_11_12j.txt', '29_11_12b.txt', '343.txt', '350.ann', 'last_04.ann', '436.ann', '425.txt', 'last_17.txt', '431.txt', 'last_03.txt', 'last_10.ann', '422.ann', '344.ann', '357.txt', '419.txt', 'last_38.ann', '1199.txt', '378.ann', '1198.txt', '379.ann', 'last_39.ann', '418.txt', '423.ann', 'last_11.ann', 'last_02.txt', '430.txt', '356.txt', '345.ann', '351.ann', '342.txt', 'last_16.txt', '424.txt', '437.ann', 'last_05.ann', '1148.ann', '04_03_13a_sorokin.ann', '1167.txt', '1174.ann', '386.ann', '395.txt', 'maykl dzhekson.txt', '381.txt', '392.ann', '1160.ann', '1173.txt', '168.txt', '147.ann', '154.txt', '632.txt', '621.ann', '626.txt', '140.txt', '153.ann', '197.txt', '184.ann', '190.ann', '183.txt', '008.txt', '033.ann', '020.txt', '034.txt', '027.ann', '2042.txt', '2045.ann', '04_02_13a_abdulatipov.txt', '578.txt', '584 (!).txt', '219.ann', '557.ann', '544.txt', '222.txt', '231.ann', '225.ann', '236.txt', '550.txt', '543.ann', '1028.ann', '587.txt', '1013.txt', '1000.ann', '594.ann', '1014.ann', '09_01_13i.ann', '1007.txt', '593.txt', '1038.ann', '597.txt', '1003.txt', '1010.ann', '590.ann', '1004.ann', '1017.txt', '583.txt', '568.txt', '209.ann', '547.ann', '554.txt', '232.txt', '221.ann', '235.ann', '226.txt', '540.txt', '553.ann', 'chaves.ann', '2041.ann', '2046.txt', '27_11_12j.txt', '018.txt', '023.ann', '030.txt', '10_01_13i.ann', '037.ann', '187.txt', '194.ann', '180.ann', '193.txt', '178.txt', '619.ann', '157.ann', '144.txt', '622.txt', '631.ann', '625.ann', '150.txt', '143.ann', '1158.ann', '22_11_12h.ann', '1177.txt', '1164.ann', '396.ann', '385.txt', '391.txt', '382.ann', '1170.ann', '1163.txt', '1188.txt', '369.ann', 'last_29.ann', '408.txt', 'last_01.ann', 'sobjanin2.txt', '433.ann', '420.txt', 'last_12.txt', '346.txt', '355.ann', '341.ann', '352.txt', '434.txt', 'last_06.txt', 'last_15.ann', '427.ann', '353.txt', '340.ann', '426.ann', 'last_14.ann', '435.txt', 'last_13.txt', '421.txt', '432.ann', '354.ann', '347.txt', '409.txt', 'last_28.ann', '1189.txt', '368.ann', '383.ann', '390.txt', '1162.txt', '1171.ann', '1165.ann', '1176.txt', '384.txt', '397.ann', '1159.ann', '29_11_12a.ann', '22_11_12i.ann', 'si_tzjanpin.ann', '624.ann', '142.ann', '151.txt', '145.txt', '156.ann', '630.ann', '623.txt', '618.ann', '179.txt', '30_11_12b.txt', '192.txt', '181.ann', '195.ann', '186.txt', 'uchitel.ann', '036.ann', '025.txt', '031.txt', '022.ann', '019.txt', '1200.txt', '2047.txt', '2040.ann', '227.txt', '234.ann', '552.ann', '541.txt', '546.ann', '220.ann', '233.txt', '208.ann', '569.txt', '582.txt', '1016.txt', '1005.ann', '591.ann', '585.ann', '1011.ann', '1002.txt', '596.txt', '1039.ann', '1028.txt', '593.ann', '1007.ann', '1014.txt', '09_01_13i.txt', '594.txt', '1000.txt', '1013.ann', '587.ann', '219.txt', '584 (!).ann', '578.ann', '543.txt', '550.ann', '236.ann', '225.txt', '231.txt', '222.ann', '544.ann', '557.txt', '2045.txt', '2042.ann', '04_02_13a_abdulatipov.ann', '008.ann', '027.txt', '034.ann', '020.ann', '033.txt', '183.ann', '190.txt', '184.txt', '197.ann', '168.ann', '153.txt', '140.ann', '626.ann', '621.txt', '632.ann', '154.ann', '147.txt', '1148.txt', '1173.ann', '1160.txt', '392.txt', '381.ann', '395.ann', 'maykl dzhekson.ann', '386.txt', '1174.txt', '04_03_13a_sorokin.txt', '1167.ann', '418.ann', 'last_39.txt', '379.txt', '1198.ann', '437.txt', 'last_05.txt', 'last_16.ann', '424.ann', '342.ann', '351.txt', '345.txt', '356.ann', 'last_02.ann', '430.ann', '423.txt', 'last_11.txt', '357.ann', '344.txt', 'last_10.txt', '422.txt', '431.ann', 'last_03.ann', '425.ann', 'last_17.ann', 'last_04.txt', '436.txt', '350.txt', '343.ann', '378.txt', '1199.ann', 'last_38.txt', '419.ann', '387.txt', '394.ann', '1166.ann', '1175.txt', '1161.txt', '1172.ann', 'artjakov.ann', '380.ann', '393.txt', '29_11_12b.ann', '22_11_12j.ann', '1149.txt', '633.ann', '620.txt', '146.txt', '155.ann', '141.ann', '152.txt', '627.ann', '21_11_12c.txt', '169.ann', '196.ann', '185.txt', '191.txt', '182.ann', '032.txt', '021.ann', '035.ann', '026.txt', '03_12_12h.txt', '009.ann', '2043.ann', '2050.txt', '2044.txt', 'last_30_new.ann', '223.ann', '230.txt', '556.txt', '545.ann', '551.ann', 'kamchatka.ann', '542.txt', '224.txt', '237.ann', '579.ann', '218.txt', '586.ann', '1012.ann', 'last_07_new.txt', '1001.txt', '595.txt', '09_01_13h.txt', '581.txt', '1015.txt', '1006.ann', '592.ann', '1029.txt', '293.ann', '280.txt', '294.txt', '287.ann', '1049.ann', '536.ann', '525.txt', '243.txt', '250.ann', '244.ann', '257.txt', '531.txt', '522.ann', '519.txt', '278.ann', '082.txt', '091.ann', '085.ann', '2018.ann', '096.txt', '2023.txt', '2030.ann', '23_11_12a.ann', '28_11_12i.ann', '23_11_12f.txt', '2024.ann', '2037.txt', '015 (!).ann', '052.ann', '041.txt', '055.txt', '046.ann', '069.txt', '126.ann', '135.txt', '121.txt', '132.ann', '109.txt', '1106.txt', '492.txt', '481.ann', '1115.ann', '1101.ann', '495.ann', '486.txt', '1112.txt', 'last_70.ann', '442.ann', '451.txt', 'last_63.txt', '337.txt', '324.ann', '330.ann', '323.txt', '445.txt', 'last_64.ann', '318.ann', '26_11_12c.txt', 'last_58.ann', '479.txt', '26_11_12b.txt', '478.txt', 'last_59.ann', '26_11_12e.ann', '319.ann', '322.txt', '331.ann', '457.ann', 'last_65.ann', '444.txt', 'last_62.txt', '450.txt', '443.ann', 'last_71.ann', '325.ann', '336.txt', '1128.ann', '1113.txt', '487.txt', '494.ann', '1100.ann', '1114.ann', '480.ann', '493.txt', '1107.txt', '108.txt', '133.ann', '120.txt', '134.txt', '127.ann', '19_11_12d.txt', '068.txt', '047.ann', '054.txt', '040.txt', '053.ann', 'semenenko.ann', '2036.txt', '2025.ann', '2031.ann', '2022.txt', '28_11_12h.ann', '097.txt', '2019.ann', '084.ann', '090.ann', '083.txt', '14_01_13c.txt', '279.ann', '518.txt', '20_11_12i.txt', '256.txt', '245.ann', '523.ann', '530.txt', '524.txt', '537.ann', '251.ann', '242.txt', '1048.ann', '286.ann', '295.txt', '281.txt', '292.ann', '297.txt', '284.ann', 'abdulatipov.txt', '290.ann', '283.txt', '532.txt', '521.ann', '247.ann', '254.txt', '240.txt', '253.ann', '535.ann', '526.txt', '268.txt', '509.ann', '2008.txt', '086.ann', '095.txt', 'ryadovoy chelah.txt', '081.txt', '092.ann', '2027.ann', '2034.txt', '23_11_12e.txt', '23_11_12b.ann', '28_11_12j.ann', '2020.txt', '056.txt', '045.ann', '051.ann', '042.txt', '079.ann', 'mvd.txt', '122.txt', '131.ann', '125.ann', '136.txt', '119.ann', '1102.ann', '496.ann', '485.txt', '1111.txt', '1105.txt', '491.txt', '482.ann', '1116.ann', '1139.txt', '446.txt', 'last_74.txt', 'last_67.ann', '455.ann', '333.ann', '320.txt', '334.txt', '327.ann', 'last_73.ann', '441.ann', '452.txt', 'last_60.txt', '469.ann', 'last_48.txt', '308.txt', '309.txt', '26_11_12f.ann', 'last_49.txt', '468.ann', '326.ann', '335.txt', 'last_61.txt', '453.txt', '440.ann', 'last_72.ann', '11_01_13e.txt', '454.ann', 'last_66.ann', 'last_75.txt', '11_01_13b.ann', '447.txt', '321.txt', '332.ann', '1138.txt', '1117.ann', '483.ann', '490.txt', '1104.txt', '555 (!).txt', '1110.txt', '484.txt', '497.ann', '1103.ann', '118.ann', 'klinton.txt', '137.txt', '124.ann', '130.ann', '123.txt', '078.ann', '043.txt', '050.ann', '044.ann', '057.txt', '23_11_12c.ann', '2032.ann', '2021.txt', '2035.txt', '2026.ann', '23_11_12d.txt', '093.ann', '080.txt', '094.txt', '087.ann', '14_01_13g.ann', '2009.txt', '508.ann', '269.txt', '252.ann', '241.txt', '527.txt', '534.ann', '520.ann', '255.txt', '246.ann', '282.txt', '291.ann', '285.ann', '296.txt', '1048.txt', '292.txt', '281.ann', '295.ann', '286.txt', '20_11_12i.ann', '518.ann', '279.txt', '242.ann', '251.txt', '537.txt', '524.ann', '530.ann', '523.txt', '245.txt', '256.ann', '28_11_12h.txt', '2022.ann', '2031.txt', '2025.txt', '2036.ann', '083.ann', '14_01_13c.ann', '090.txt', '084.txt', '097.ann', '2019.txt', '068.ann', '053.txt', 'semenenko.txt', '040.ann', '054.ann', '047.txt', '19_11_12d.ann', '108.ann', '127.txt', '134.ann', '120.ann', '133.txt', '1128.txt', '1107.ann', '493.ann', '480.txt', '1114.txt', '1100.txt', '494.txt', '487.ann', '1113.ann', '26_11_12e.txt', '319.txt', 'last_59.txt', '478.ann', '26_11_12b.ann', '336.ann', '325.txt', '443.txt', 'last_71.txt', 'last_62.ann', '450.ann', '444.ann', '457.txt', 'last_65.txt', '331.txt', '322.ann', 'last_64.txt', '445.ann', '323.ann', '330.txt', '324.txt', '337.ann', '451.ann', 'last_63.ann', 'last_70.txt', '442.txt', '479.ann', 'last_58.txt', '26_11_12c.ann', '318.txt', '1112.ann', '486.ann', '495.txt', '1101.txt', '1115.txt', '481.txt', '492.ann', '1106.ann', '132.txt', '121.ann', '135.ann', '126.txt', '109.ann', '046.txt', '055.ann', '041.ann', '052.txt', '069.ann', '2018.txt', '096.ann', '085.txt', '091.txt', '082.ann', '2037.ann', '015 (!).txt', '2024.txt', '23_11_12f.ann', '28_11_12i.txt', '23_11_12a.txt', '2030.txt', '2023.ann', '522.txt', '531.ann', '257.ann', '244.txt', '250.txt', '243.ann', '525.ann', '536.txt', '278.txt', '519.ann', '287.txt', '294.ann', '280.ann', '293.txt', '1049.txt', '296.ann', '285.txt', '291.txt', '282.ann', '269.ann', '508.txt', '246.txt', '255.ann', '520.txt', '534.txt', '527.ann', '241.ann', '252.txt', '23_11_12d.ann', '2026.txt', '2035.ann', '2021.ann', '2032.txt', '23_11_12c.txt', '087.txt', '14_01_13g.txt', '2009.ann', '094.ann', '080.ann', '093.txt', '078.txt', '057.ann', '044.txt', '050.txt', '043.ann', '118.txt', 'klinton.ann', '123.ann', '130.txt', '124.txt', '137.ann', '1138.ann', '1103.txt', '497.txt', '484.ann', '1110.ann', '1104.ann', '490.ann', '555 (!).ann', '483.txt', '1117.txt', '468.txt', 'last_49.ann', '26_11_12f.txt', '309.ann', '332.txt', '321.ann', 'last_75.ann', '11_01_13b.txt', '447.ann', '454.txt', 'last_66.txt', '440.txt', 'last_72.txt', '11_01_13e.ann', 'last_61.ann', '453.ann', '335.ann', '326.txt', '452.ann', 'last_60.ann', 'last_73.txt', '441.txt', '327.txt', '334.ann', '320.ann', '333.txt', 'last_67.txt', '455.txt', '446.ann', 'last_74.ann', '308.ann', 'last_48.ann', '469.txt', '1116.txt', '482.txt', '491.ann', '1105.ann', '1111.ann', '485.ann', '496.txt', '1102.txt', '1139.ann', '136.ann', '125.txt', '131.txt', '122.ann', '119.txt', 'mvd.ann', '042.ann', '051.txt', '045.txt', '056.ann', '079.txt', '092.txt', '081.ann', 'ryadovoy chelah.ann', '095.ann', '2008.ann', '086.txt', '2020.ann', '28_11_12j.txt', '23_11_12b.txt', '23_11_12e.ann', '2034.ann', '2027.txt', '526.ann', '535.txt', '253.txt', '240.ann', '254.ann', '247.txt', '521.txt', '532.ann', '509.txt', '268.ann', '283.ann', '290.txt', '284.txt', 'abdulatipov.ann', '297.ann']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"collection3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfa2dfbb-c259-464a-9359-412397445c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1047.txt', '289.txt', '504.txt', '262.txt', '276.txt', '20_11_12a.txt', '510.txt', '538.txt', '28_11_12g.txt', '2002.txt', '2016.txt', '060.txt', '074.txt', '048.txt', '114.txt', '100.txt', '128.txt', '1127.txt', '1133.txt', '470.txt', 'last_42.txt', '316.txt', '302.txt', '464.txt', 'last_56.txt', '458.txt', '459.txt', '303.txt', 'last_57.txt', '465.txt', 'shojgu4.txt', 'last_43.txt', '471.txt', '317.txt', '1132.txt', '1126.txt', '129.txt', '101.txt', '115.txt', '049.txt', '075.txt', '061.txt', '2017.txt', '2003.txt', '28_11_12f.txt', '539.txt', '277.txt', '511.txt', '505.txt', '263.txt', '288.txt', '1046.txt', '1044.txt', '1050.txt', '513.txt', '20_11_12b.txt', '275.txt', '261.txt', '507.txt', '249.txt', '04_12_12b.txt', '2029.txt', '2015.txt', '088.txt', '2001.txt', '077.txt', 'blokhin.txt', '063.txt', '103.txt', '117.txt', '533 (!).txt', '1130.txt', '1124.txt', '498.txt', '1118.txt', 'shojgu6.txt', '467.txt', 'last_55.txt', '301.txt', '315.txt', '473.txt', 'last_41.txt', 'last_69.txt', '329.txt', '328.txt', 'last_68.txt', '314.txt', 'last_40.txt', '472.txt', 'last_54.txt', '466.txt', '300.txt', '1119.txt', '499.txt', '1125.txt', '1131.txt', '116.txt', '102.txt', '062.txt', '076.txt', '089.txt', '14_01_13i.txt', '2014.txt', '2028.txt', '248.txt', '260.txt', '506.txt', '512.txt', '20_11_12c.txt', '274.txt', '04_12_12h_corr.txt', '1045.txt', '1041.txt', '04_12_12g.txt', '258.txt', '270.txt', '516.txt', '502.txt', '264.txt', '2010.txt', '099.txt', '2004.txt', '2038.txt', '28_11_12a.txt', '072.txt', '066.txt', 'Avtovaz.txt', '106.txt', '112.txt', '1109.txt', '489.txt', '1135.txt', '1121.txt', '338.txt', '304.txt', 'shojgu3.txt', '462.txt', 'last_50.txt', '476.txt', 'last_44.txt', '310.txt', 'last_45.txt', '477.txt', '311.txt', 'turkmenija.txt', '305.txt', 'last_51.txt', '463.txt', '339.txt', '1120.txt', '1134.txt', '488.txt', '1108.txt', '113.txt', '107.txt', '067.txt', '073.txt', '2039.txt', '2005.txt', '098.txt', '2011.txt', '503.txt', '265.txt', '271.txt', '517.txt', '259.txt', '04_12_12f.txt', '1040.txt', '298.txt', '1042.txt', '529.txt', '04_12_12d.txt', '267.txt', '501.txt', '515.txt', '20_11_12d.txt', '273.txt', '2007.txt', '2013.txt', '059.txt', '065.txt', '071.txt', '139.txt', '111.txt', '105.txt', '1122.txt', '1136.txt', '449.txt', '313.txt', '475.txt', 'last_47.txt', '461.txt', 'last_53.txt', '307.txt', 'last_52.txt', '460.txt', 'shojgu1.txt', '306.txt', '312.txt', 'last_46.txt', '474.txt', '448.txt', '1137.txt', '1123.txt', '104.txt', '110.txt', '138.txt', '19_11_12h.txt', '070.txt', '064.txt', '058.txt', '2012.txt', '2006.txt', '514.txt', '272.txt', '266.txt', '500.txt', '528.txt', '1043.txt', '299.txt', '1030.txt', '1024.txt', '1018.txt', '09_01_13e.txt', '201.txt', '567.txt', '215.txt', '229.txt', '2049.txt', '003.txt', '017.txt', '27_11_12e.txt', '10_01_13a.txt', '188.txt', '611.txt', '177.txt', '163.txt', '1144.txt', '1150.txt', '1178.txt', '375.txt', '413.txt', '1187.txt', 'last_21.txt', '1193.txt', '407.txt', 'last_35.txt', '361.txt', '349.txt', 'last_09.txt', 'last_08.txt', '348.txt', 'last_34.txt', '406.txt', '1192.txt', '360.txt', '374.txt', 'last_20.txt', '1186.txt', '412.txt', 'lenoblast.txt', '09_01_13.txt', '1179.txt', '15_01_13e.txt', '1151.txt', '22_11_12a.txt', '1145.txt', '162.txt', '610.txt', '176.txt', '189.txt', '03_12_12d.txt', '016.txt', '27_11_12d.txt', '002.txt', '2048.txt', '228.txt', '572.txt', '214.txt', '200.txt', '09_01_13d.txt', '1019.txt', '599.txt', '1025.txt', '1031.txt', '1027.txt', '1033.txt', '216.txt', '570.txt', '564.txt', '202.txt', '558.txt', '014.txt', '25_12_12d.txt', '028.txt', 'rosobrnadzor.txt', '160.txt', '174.txt', '612.txt', '148.txt', '22_11_12c.txt', '1153.txt', '1147.txt', '389.txt', '362.txt', '1190.txt', '404.txt', 'last_36.txt', '410.txt', '1184.txt', 'last_22.txt', '376.txt', '438.txt', '439.txt', 'last_23.txt', '1185.txt', '411.txt', '377.txt', '363.txt', 'last_37.txt', '405.txt', '1191.txt', '15_01_13f.txt', '388.txt', '1146.txt', '1152.txt', '149.txt', '175.txt', '613.txt', '161.txt', '03_12_12g.txt', '029.txt', '001.txt', '25_12_12e.txt', '559.txt', '565.txt', '203.txt', '217.txt', '571.txt', '1032.txt', '1026.txt', '09_01_13c.txt', '1022.txt', '1036.txt', '549.txt', '575.txt', '213.txt', '207.txt', '561.txt', '03_12_12c.txt', '039.txt', '011.txt', '27_11_12c.txt', '25_12_12a.txt', '005.txt', '159.txt', '165.txt', '21_11_12h.txt', '617.txt', '171.txt', '398.txt', '15_01_13b.txt', '1156.txt', '1142.txt', '429.txt', '1195.txt', '401.txt', 'last_33.txt', '367.txt', '373.txt', '415.txt', '1181.txt', 'last_27.txt', '372.txt', 'last_26.txt', '1180.txt', '414.txt', 'last_32.txt', '400.txt', '1194.txt', '366.txt', '428.txt', '1143.txt', '1157.txt', '22_11_12g.txt', 'kuleshov.txt', '399.txt', '616.txt', '21_11_12i.txt', '170.txt', '164.txt', '602.txt', '158.txt', '004.txt', '010.txt', '038.txt', '03_12_12b.txt', '206.txt', '560.txt', '574.txt', '212.txt', '548.txt', '1037.txt', '1023.txt', '1009.txt', '589.txt', '1035.txt', '1021.txt', '238.txt', '562.txt', '204.txt', '210.txt', '576.txt', '598 (!).txt', '10_01_13d.txt', '006.txt', '012.txt', '199.txt', '628.txt', '172.txt', '614.txt', '30_11_12i.txt', '600.txt', '166.txt', '15_01_13a.txt', '1169.txt', '1141.txt', 'chirkunov.txt', '1155.txt', 'last_18.txt', '358.txt', '416.txt', '1182.txt', 'last_24.txt', '370.txt', '364.txt', '1196.txt', '402.txt', '365.txt', 'last_31.txt', '403.txt', '1197.txt', 'last_25.txt', '1183.txt', '417.txt', '371.txt', '359.txt', 'last_19.txt', '22_11_12d.txt', '1154.txt', '1140.txt', '1168.txt', '601.txt', '167.txt', '173.txt', '30_11_12h.txt', '615.txt', '21_11_12j.txt', '629.txt', '198.txt', '27_11_12a.txt', '013.txt', '007.txt', '25_12_12c.txt', '03_12_12a.txt', 'mvd2.txt', '211.txt', '577.txt', '563.txt', '205.txt', '239.txt', '1020.txt', '1034.txt', '09_01_13a.txt', '588.txt', '1008.txt', '1011.txt', '585.txt', '591.txt', '1005.txt', '1039.txt', '220.txt', '546.txt', '552.txt', '234.txt', '208.txt', '2040.txt', '022.txt', '036.txt', 'uchitel.txt', '195.txt', '181.txt', '630.txt', '156.txt', '142.txt', '624.txt', 'si_tzjanpin.txt', '618.txt', '397.txt', '1165.txt', '1171.txt', '383.txt', '22_11_12i.txt', '29_11_12a.txt', '1159.txt', '354.txt', '432.txt', '426.txt', 'last_14.txt', '340.txt', '368.txt', 'last_28.txt', 'last_29.txt', '369.txt', 'last_15.txt', '427.txt', '341.txt', '355.txt', 'last_01.txt', '433.txt', '22_11_12h.txt', '1158.txt', '1170.txt', '382.txt', '396.txt', '1164.txt', '619.txt', '143.txt', '625.txt', '631.txt', '157.txt', '180.txt', '194.txt', '037.txt', '10_01_13i.txt', '023.txt', '2041.txt', '209.txt', '553.txt', 'chaves.txt', '235.txt', '221.txt', '547.txt', '1038.txt', '1004.txt', '590.txt', '1010.txt', '592.txt', '1006.txt', '1012.txt', '586.txt', '237.txt', 'kamchatka.txt', '551.txt', '545.txt', '223.txt', '579.txt', 'last_30_new.txt', '2043.txt', '035.txt', '021.txt', '009.txt', '182.txt', '196.txt', '627.txt', '141.txt', '155.txt', '633.txt', '169.txt', 'artjakov.txt', '380.txt', '1172.txt', '1166.txt', '394.txt', '22_11_12j.txt', '29_11_12b.txt', '343.txt', '425.txt', 'last_17.txt', '431.txt', 'last_03.txt', '357.txt', '419.txt', '1199.txt', '1198.txt', '418.txt', 'last_02.txt', '430.txt', '356.txt', '342.txt', 'last_16.txt', '424.txt', '1167.txt', '395.txt', 'maykl dzhekson.txt', '381.txt', '1173.txt', '168.txt', '154.txt', '632.txt', '626.txt', '140.txt', '197.txt', '183.txt', '008.txt', '020.txt', '034.txt', '2042.txt', '04_02_13a_abdulatipov.txt', '578.txt', '584 (!).txt', '544.txt', '222.txt', '236.txt', '550.txt', '587.txt', '1013.txt', '1007.txt', '593.txt', '597.txt', '1003.txt', '1017.txt', '583.txt', '568.txt', '554.txt', '232.txt', '226.txt', '540.txt', '2046.txt', '27_11_12j.txt', '018.txt', '030.txt', '187.txt', '193.txt', '178.txt', '144.txt', '622.txt', '150.txt', '1177.txt', '385.txt', '391.txt', '1163.txt', '1188.txt', '408.txt', 'sobjanin2.txt', '420.txt', 'last_12.txt', '346.txt', '352.txt', '434.txt', 'last_06.txt', '353.txt', '435.txt', 'last_13.txt', '421.txt', '347.txt', '409.txt', '1189.txt', '390.txt', '1162.txt', '1176.txt', '384.txt', '151.txt', '145.txt', '623.txt', '179.txt', '30_11_12b.txt', '192.txt', '186.txt', '025.txt', '031.txt', '019.txt', '1200.txt', '2047.txt', '227.txt', '541.txt', '233.txt', '569.txt', '582.txt', '1016.txt', '1002.txt', '596.txt', '1028.txt', '1014.txt', '09_01_13i.txt', '594.txt', '1000.txt', '219.txt', '543.txt', '225.txt', '231.txt', '557.txt', '2045.txt', '027.txt', '033.txt', '190.txt', '184.txt', '153.txt', '621.txt', '147.txt', '1148.txt', '1160.txt', '392.txt', '386.txt', '1174.txt', '04_03_13a_sorokin.txt', 'last_39.txt', '379.txt', '437.txt', 'last_05.txt', '351.txt', '345.txt', '423.txt', 'last_11.txt', '344.txt', 'last_10.txt', '422.txt', 'last_04.txt', '436.txt', '350.txt', '378.txt', 'last_38.txt', '387.txt', '1175.txt', '1161.txt', '393.txt', '1149.txt', '620.txt', '146.txt', '152.txt', '21_11_12c.txt', '185.txt', '191.txt', '032.txt', '026.txt', '03_12_12h.txt', '2050.txt', '2044.txt', '230.txt', '556.txt', '542.txt', '224.txt', '218.txt', 'last_07_new.txt', '1001.txt', '595.txt', '09_01_13h.txt', '581.txt', '1015.txt', '1029.txt', '280.txt', '294.txt', '525.txt', '243.txt', '257.txt', '531.txt', '519.txt', '082.txt', '096.txt', '2023.txt', '23_11_12f.txt', '2037.txt', '041.txt', '055.txt', '069.txt', '135.txt', '121.txt', '109.txt', '1106.txt', '492.txt', '486.txt', '1112.txt', '451.txt', 'last_63.txt', '337.txt', '323.txt', '445.txt', '26_11_12c.txt', '479.txt', '26_11_12b.txt', '478.txt', '322.txt', '444.txt', 'last_62.txt', '450.txt', '336.txt', '1113.txt', '487.txt', '493.txt', '1107.txt', '108.txt', '120.txt', '134.txt', '19_11_12d.txt', '068.txt', '054.txt', '040.txt', '2036.txt', '2022.txt', '097.txt', '083.txt', '14_01_13c.txt', '518.txt', '20_11_12i.txt', '256.txt', '530.txt', '524.txt', '242.txt', '295.txt', '281.txt', '297.txt', 'abdulatipov.txt', '283.txt', '532.txt', '254.txt', '240.txt', '526.txt', '268.txt', '2008.txt', '095.txt', 'ryadovoy chelah.txt', '081.txt', '2034.txt', '23_11_12e.txt', '2020.txt', '056.txt', '042.txt', 'mvd.txt', '122.txt', '136.txt', '485.txt', '1111.txt', '1105.txt', '491.txt', '1139.txt', '446.txt', 'last_74.txt', '320.txt', '334.txt', '452.txt', 'last_60.txt', 'last_48.txt', '308.txt', '309.txt', 'last_49.txt', '335.txt', 'last_61.txt', '453.txt', '11_01_13e.txt', 'last_75.txt', '447.txt', '321.txt', '1138.txt', '490.txt', '1104.txt', '555 (!).txt', '1110.txt', '484.txt', 'klinton.txt', '137.txt', '123.txt', '043.txt', '057.txt', '2021.txt', '2035.txt', '23_11_12d.txt', '080.txt', '094.txt', '2009.txt', '269.txt', '241.txt', '527.txt', '255.txt', '282.txt', '296.txt', '1048.txt', '292.txt', '286.txt', '279.txt', '251.txt', '537.txt', '523.txt', '245.txt', '28_11_12h.txt', '2031.txt', '2025.txt', '090.txt', '084.txt', '2019.txt', '053.txt', 'semenenko.txt', '047.txt', '127.txt', '133.txt', '1128.txt', '480.txt', '1114.txt', '1100.txt', '494.txt', '26_11_12e.txt', '319.txt', 'last_59.txt', '325.txt', '443.txt', 'last_71.txt', '457.txt', 'last_65.txt', '331.txt', 'last_64.txt', '330.txt', '324.txt', 'last_70.txt', '442.txt', 'last_58.txt', '318.txt', '495.txt', '1101.txt', '1115.txt', '481.txt', '132.txt', '126.txt', '046.txt', '052.txt', '2018.txt', '085.txt', '091.txt', '015 (!).txt', '2024.txt', '28_11_12i.txt', '23_11_12a.txt', '2030.txt', '522.txt', '244.txt', '250.txt', '536.txt', '278.txt', '287.txt', '293.txt', '1049.txt', '285.txt', '291.txt', '508.txt', '246.txt', '520.txt', '534.txt', '252.txt', '2026.txt', '2032.txt', '23_11_12c.txt', '087.txt', '14_01_13g.txt', '093.txt', '078.txt', '044.txt', '050.txt', '118.txt', '130.txt', '124.txt', '1103.txt', '497.txt', '483.txt', '1117.txt', '468.txt', '26_11_12f.txt', '332.txt', '11_01_13b.txt', '454.txt', 'last_66.txt', '440.txt', 'last_72.txt', '326.txt', 'last_73.txt', '441.txt', '327.txt', '333.txt', 'last_67.txt', '455.txt', '469.txt', '1116.txt', '482.txt', '496.txt', '1102.txt', '125.txt', '131.txt', '119.txt', '051.txt', '045.txt', '079.txt', '092.txt', '086.txt', '28_11_12j.txt', '23_11_12b.txt', '2027.txt', '535.txt', '253.txt', '247.txt', '521.txt', '509.txt', '290.txt', '284.txt']\n"
     ]
    }
   ],
   "source": [
    "fileDir = r\"collection3\"\n",
    "fileExt = r\".txt\"\n",
    "documents_txt = [_ for _ in os.listdir(fileDir) if _.endswith(fileExt)]\n",
    "print(documents_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e99218a-c563-4585-ac09-46350103c2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Жириновский предлагает обменять с США Сноудена...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Д.Медведев назначил ряд глав региональных МВД\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>СМИ: В.Суркову надоело работать в администраци...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Д.Медведев освободил от должности еще 10 генер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Д.Медведев уволил командира московского ОМОНа\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Д.Медведев снял с работы руководителей МВД в 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Французскую версию Huffington Post возглавила ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Глава швейцарского Центробанка ушел в отставку...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>СМИ: Д.Медведев уволил генерала МВД, который п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Бывший председатель Банка России сменит Кудрин...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Жириновский предлагает обменять с США Сноудена...\n",
       "1    Д.Медведев назначил ряд глав региональных МВД\\...\n",
       "2    СМИ: В.Суркову надоело работать в администраци...\n",
       "3    Д.Медведев освободил от должности еще 10 генер...\n",
       "4    Д.Медведев уволил командира московского ОМОНа\\...\n",
       "..                                                 ...\n",
       "995  Д.Медведев снял с работы руководителей МВД в 8...\n",
       "996  Французскую версию Huffington Post возглавила ...\n",
       "997  Глава швейцарского Центробанка ушел в отставку...\n",
       "998  СМИ: Д.Медведев уволил генерала МВД, который п...\n",
       "999  Бывший председатель Банка России сменит Кудрин...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = []\n",
    "for file in documents_txt:\n",
    "    doc = open('collection3/' + file, encoding='utf-8')\n",
    "    text = doc.read()\n",
    "    text_list.append(text)\n",
    "    \n",
    "data_text = pd.DataFrame({'text': text_list })\n",
    "data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59ecf162-b0a4-4385-b0e3-ba289a1e0253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Olga/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Olga/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c11e81-9e39-4dee-9016-f29b5aebfe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Жириновский', 'JJ'),\n",
       " ('предлагает', 'NNP'),\n",
       " ('обменять', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('Сноудена', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('Бута', 'NNP'),\n",
       " ('Лидер', 'NNP'),\n",
       " ('ЛДПР', 'NNP'),\n",
       " ('Владимир', 'NNP'),\n",
       " ('Жириновский', 'NNP'),\n",
       " ('предложил', 'NNP'),\n",
       " ('обменять', 'NNP'),\n",
       " ('бывшего', 'NNP'),\n",
       " ('сотрудника', 'NNP'),\n",
       " ('ЦРУ', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('Эдварда', 'NNP'),\n",
       " ('Сноудена', 'NNP'),\n",
       " (',', ','),\n",
       " ('который', 'NNP'),\n",
       " ('прибыл', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Москву', 'NNP'),\n",
       " (',', ','),\n",
       " ('на', 'NNP'),\n",
       " ('осужденного', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Америке', 'NNP'),\n",
       " ('бизнесмена', 'NNP'),\n",
       " ('Виктора', 'NNP'),\n",
       " ('Бута', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('Сноудена', 'JJ'),\n",
       " ('ни', 'NN'),\n",
       " ('в', 'NNP'),\n",
       " ('коем', 'NNP'),\n",
       " ('случае', 'NNP'),\n",
       " ('не', 'NNP'),\n",
       " ('высылать', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " (',', ','),\n",
       " ('а', 'NNP'),\n",
       " ('обменять', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('Виктора', 'NNP'),\n",
       " ('Бута', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('Константина', 'NNP'),\n",
       " ('Ярошенко', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('В', 'VB'),\n",
       " ('идеале', 'JJ'),\n",
       " ('—', 'NNP'),\n",
       " ('добавить', 'NNP'),\n",
       " ('генерала', 'NNP'),\n",
       " ('Олега', 'NNP'),\n",
       " ('Калугина', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('—', 'NNP'),\n",
       " ('написал', 'NNP'),\n",
       " ('он', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('своем', 'NNP'),\n",
       " ('микроблоге', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Twitter', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Сноуден', 'NN'),\n",
       " (',', ','),\n",
       " ('работавший', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('компанию', 'NNP'),\n",
       " ('Booz', 'NNP'),\n",
       " ('Allen', 'NNP'),\n",
       " ('Hamilton', 'NNP'),\n",
       " ('—', 'NNP'),\n",
       " ('подрядчика', 'NNP'),\n",
       " ('Центрального', 'NNP'),\n",
       " ('разведывательного', 'NNP'),\n",
       " ('управления', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " (',', ','),\n",
       " ('в', 'NNP'),\n",
       " ('начале', 'NNP'),\n",
       " ('июня', 'NNP'),\n",
       " ('распространил', 'NNP'),\n",
       " ('секретный', 'NNP'),\n",
       " ('ордер', 'NNP'),\n",
       " ('суда', 'NNP'),\n",
       " (',', ','),\n",
       " ('по', 'NNP'),\n",
       " ('которому', 'NNP'),\n",
       " ('спецслужбы', 'NNP'),\n",
       " ('получили', 'NNP'),\n",
       " ('доступ', 'NNP'),\n",
       " ('ко', 'NNP'),\n",
       " ('всем', 'NNP'),\n",
       " ('звонкам', 'NNP'),\n",
       " ('крупнейшего', 'NNP'),\n",
       " ('сотового', 'NNP'),\n",
       " ('оператора', 'NNP'),\n",
       " ('Verizon', 'NNP'),\n",
       " (',', ','),\n",
       " ('а', 'NNP'),\n",
       " ('также', 'NNP'),\n",
       " ('данные', 'NNP'),\n",
       " ('о', 'NNP'),\n",
       " ('сверхсекретной', 'NNP'),\n",
       " ('программе', 'NNP'),\n",
       " ('агентства', 'NNP'),\n",
       " ('национальной', 'NNP'),\n",
       " ('безопасности', 'NNP'),\n",
       " ('PRISM', 'NNP'),\n",
       " (',', ','),\n",
       " ('позволяющей', 'NNP'),\n",
       " ('отслеживать', 'NNP'),\n",
       " ('электронные', 'NNP'),\n",
       " ('коммуникации', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('крупнейших', 'NNP'),\n",
       " ('сайтах', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('В', 'VB'),\n",
       " ('воскресенье', 'JJ'),\n",
       " ('стало', 'NNP'),\n",
       " ('известно', 'NNP'),\n",
       " (',', ','),\n",
       " ('что', 'NNP'),\n",
       " ('Сноуден', 'NNP'),\n",
       " ('прибыл', 'NNP'),\n",
       " ('из', 'NNP'),\n",
       " ('Гонконга', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Москву', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('запросил', 'NNP'),\n",
       " ('убежища', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Эквадоре', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Что', 'VB'),\n",
       " ('ждет', 'JJ'),\n",
       " ('Эдварда', 'NNP'),\n",
       " ('Сноудена', 'NNP'),\n",
       " ('Эдвард', 'NNP'),\n",
       " ('Сноуден', 'NNP'),\n",
       " (',', ','),\n",
       " ('наверное', 'NNP'),\n",
       " (',', ','),\n",
       " ('не', 'NNP'),\n",
       " ('знал', 'NNP'),\n",
       " ('только', 'NNP'),\n",
       " ('одного', 'NN'),\n",
       " (':', ':'),\n",
       " ('что', 'JJ'),\n",
       " ('отныне', 'NNP'),\n",
       " ('от', 'NNP'),\n",
       " ('него', 'NNP'),\n",
       " ('ничего', 'NNP'),\n",
       " ('уже', 'NNP'),\n",
       " ('не', 'NNP'),\n",
       " ('будет', 'NNP'),\n",
       " ('зависеть', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Москва-Гавана-Каракас', 'JJ'),\n",
       " ('–', 'JJ'),\n",
       " ('в', 'NN'),\n",
       " ('новой', 'NNP'),\n",
       " ('траектории', 'NNP'),\n",
       " ('жизни', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('В', 'VB'),\n",
       " ('плотном', 'JJ'),\n",
       " ('кольце', 'NNP'),\n",
       " ('новых', 'NNP'),\n",
       " ('друзей', 'NNP'),\n",
       " (',', ','),\n",
       " ('которым', 'NNP'),\n",
       " ('нужно', 'NNP'),\n",
       " ('быстро', 'NNP'),\n",
       " ('вытащить', 'NNP'),\n",
       " ('из', 'NNP'),\n",
       " ('тебя', 'NNP'),\n",
       " ('то', 'NNP'),\n",
       " (',', ','),\n",
       " ('что', 'NNP'),\n",
       " ('еще', 'NNP'),\n",
       " ('не', 'NNP'),\n",
       " ('сказал', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('А', 'NN'),\n",
       " ('может', 'NN'),\n",
       " (',', ','),\n",
       " ('говорить', 'NNP'),\n",
       " ('больше', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('нечего', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Когда', 'VB'),\n",
       " ('и', 'JJ'),\n",
       " ('они', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('этом', 'NNP'),\n",
       " ('убедятся', 'NNP'),\n",
       " (',', ','),\n",
       " ('как', 'NNP'),\n",
       " ('раз', 'NNP'),\n",
       " ('объявят', 'NNP'),\n",
       " ('посадку', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Каракасе', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Добро', 'VB'),\n",
       " ('пожаловать', 'JJ'),\n",
       " ('в', 'NNP'),\n",
       " ('третий', 'NNP'),\n",
       " ('мир', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Потому', 'VB'),\n",
       " ('что', 'JJ'),\n",
       " ('если', 'NNP'),\n",
       " ('тебе', 'NNP'),\n",
       " ('нет', 'NNP'),\n",
       " ('место', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('первом', 'NNP'),\n",
       " (',', ','),\n",
       " ('не', 'NNP'),\n",
       " ('станет', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('тобой', 'NNP'),\n",
       " ('надолго', 'NNP'),\n",
       " ('связываться', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('второй', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Подробнее', 'VB'),\n",
       " ('>', 'JJ'),\n",
       " ('>', 'NN')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = data_text.text[0]\n",
    "\n",
    "nltk.pos_tag(nltk.word_tokenize(document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93d0af51-504a-4c42-89de-24c3b710de48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/Olga/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/Olga/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "755da9f6-7925-4e71-a910-f07291b776d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Hamilton', 'PERSON'),\n",
       " ('Америке', 'PERSON'),\n",
       " ('Виктора Бута', 'PERSON'),\n",
       " ('Москву', 'PERSON'),\n",
       " ('Сноуден', 'PERSON'),\n",
       " ('Эдварда Сноудена', 'PERSON'),\n",
       " ('Эдварда Сноудена Эдвард Сноуден', 'PERSON')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da2678ec-dfc0-4b39-be75-43a38e4bb123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>LOC 0 6</th>\n",
       "      <th>Россия</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 50 53</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>LOC 57 63</td>\n",
       "      <td>Грузию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 87 93</td>\n",
       "      <td>МОСКВА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T5</td>\n",
       "      <td>ORG 103 114</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 116 122</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T7</td>\n",
       "      <td>LOC 141 144</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 161 168</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 301 307</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T10</td>\n",
       "      <td>PER 308 324</td>\n",
       "      <td>Григорий Карасин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T11</td>\n",
       "      <td>LOC 383 386</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T12</td>\n",
       "      <td>PER 387 402</td>\n",
       "      <td>Дэниэлом Фридом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 505 517</td>\n",
       "      <td>Южной Осетии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T14</td>\n",
       "      <td>LOC 703 709</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 723 730</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T16</td>\n",
       "      <td>LOC 815 825</td>\n",
       "      <td>Вашингтона</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T17</td>\n",
       "      <td>ORG 838 841</td>\n",
       "      <td>МИД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 842 848</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T1      LOC 0 6            Россия\n",
       "0    T2    LOC 50 53               США\n",
       "1    T3    LOC 57 63            Грузию\n",
       "2    T4    LOC 87 93            МОСКВА\n",
       "3    T5  ORG 103 114       РИА Новости\n",
       "4    T6  LOC 116 122            Россия\n",
       "5    T7  LOC 141 144               США\n",
       "6    T8  LOC 161 168           Тбилиси\n",
       "7    T9  LOC 301 307            России\n",
       "8   T10  PER 308 324  Григорий Карасин\n",
       "9   T11  LOC 383 386               США\n",
       "10  T12  PER 387 402   Дэниэлом Фридом\n",
       "11  T13  LOC 505 517      Южной Осетии\n",
       "12  T14  LOC 703 709            Россия\n",
       "13  T15  LOC 723 730           Тбилиси\n",
       "14  T16  LOC 815 825        Вашингтона\n",
       "15  T17  ORG 838 841               МИД\n",
       "16  T18  LOC 842 848            России"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('collection3/001.ann', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47e8f21d-269d-481f-b198-ec33fdb3b9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Жириновский\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " предлагает обменять с \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Сноудена\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " на \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Бута\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</br></br>Лидер \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ЛДПР\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Владимир Жириновский\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " предложил обменять бывшего сотрудника \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ЦРУ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Эдварда Сноудена\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", который прибыл в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Москву\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", на осужденного в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Америке\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " бизнесмена \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Виктора Бута\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br>&quot;\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Сноудена\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " ни в коем случае не высылать в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", а обменять на \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Виктора Бута\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " и \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Константина Ярошенко\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". В идеале — добавить генерала \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Олега Калугина\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       "&quot;, — написал он в своем микроблоге в \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</br></br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Сноуден\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", работавший на компанию \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Booz Allen Hamilton\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " — подрядчика \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Центрального разведывательного управления\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", в начале июня распространил секретный ордер суда, по которому спецслужбы получили доступ ко всем звонкам крупнейшего сотового оператора \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Verizon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", а также данные о сверхсекретной программе агентства национальной безопасности PRISM, позволяющей отслеживать электронные коммуникации на крупнейших сайтах. В воскресенье стало известно, что \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Сноуден\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " прибыл из \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Гонконга\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Москву\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " и запросил убежища в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Эквадоре\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</br></br>Что ждет \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Эдварда Сноудена\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       "</br></br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Эдвард Сноуден\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", наверное, не знал только одного: что отныне от него ничего уже не будет зависеть. \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Москва-Гавана-Каракас\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " – в новой траектории жизни. В плотном кольце новых друзей, которым нужно быстро вытащить из тебя то, что еще не сказал. А может, говорить больше и нечего. Когда и они в этом убедятся, как раз объявят посадку в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Каракасе\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Добро пожаловать в третий мир. Потому что если тебе нет место в первом, не станет с тобой надолго связываться и второй. Подробнее &gt;&gt;</br></br></br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = ru_core_news_sm.load()\n",
    "ny_bb = data_text.text[0]\n",
    "article = nlp(ny_bb)\n",
    "displacy.render(article, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1181fe97-9e0b-4eea-9248-d5a1779e0dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Жириновский PROPN nsubj\n",
      "предлагает VERB ROOT\n",
      "обменять VERB xcomp\n",
      "с ADP case\n",
      "США PROPN obl\n",
      "Сноудена PROPN obj\n",
      "на ADP case\n",
      "Бута PROPN obl\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Лидер NOUN nsubj\n",
      "ЛДПР PROPN nmod\n",
      "Владимир PROPN appos\n",
      "Жириновский PROPN flat:name\n",
      "предложил VERB parataxis\n",
      "обменять VERB xcomp\n",
      "бывшего ADJ amod\n",
      "сотрудника NOUN obj\n",
      "ЦРУ PROPN nmod\n",
      "США PROPN nmod\n",
      "Эдварда PROPN appos\n",
      "Сноудена PROPN flat:name\n",
      ", PUNCT punct\n",
      "который PRON nsubj\n",
      "прибыл VERB acl:relcl\n",
      "в ADP case\n",
      "Москву PROPN obl\n",
      ", PUNCT punct\n",
      "на ADP case\n",
      "осужденного NOUN acl\n",
      "в ADP case\n",
      "Америке PROPN obl\n",
      "бизнесмена NOUN appos\n",
      "Виктора PROPN appos\n",
      "Бута PROPN flat:name\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "\" PUNCT punct\n",
      "Сноудена NOUN obj\n",
      "ни PART advmod\n",
      "в ADP fixed\n",
      "коем DET fixed\n",
      "случае NOUN fixed\n",
      "не PART advmod\n",
      "высылать VERB ROOT\n",
      "в ADP case\n",
      "США PROPN obl\n",
      ", PUNCT punct\n",
      "а CCONJ cc\n",
      "обменять VERB conj\n",
      "на ADP case\n",
      "Виктора PROPN obl\n",
      "Бута PROPN flat:name\n",
      "и CCONJ cc\n",
      "Константина PROPN conj\n",
      "Ярошенко PROPN flat:name\n",
      ". PUNCT punct\n",
      "В ADP case\n",
      "идеале NOUN ROOT\n",
      "— PUNCT punct\n",
      "добавить VERB parataxis\n",
      "генерала NOUN obj\n",
      "Олега PROPN appos\n",
      "Калугина PROPN flat:name\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "— PUNCT punct\n",
      "написал VERB parataxis\n",
      "он PRON nsubj\n",
      "в ADP case\n",
      "своем DET det\n",
      "микроблоге NOUN obl\n",
      "в ADP case\n",
      "Twitter PROPN nmod\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Сноуден PROPN nsubj\n",
      ", PUNCT punct\n",
      "работавший VERB acl\n",
      "на ADP case\n",
      "компанию NOUN obl\n",
      "Booz X appos\n",
      "Allen X flat:foreign\n",
      "Hamilton X flat:foreign\n",
      "— PUNCT punct\n",
      "подрядчика NOUN appos\n",
      "Центрального ADJ amod\n",
      "разведывательного ADJ amod\n",
      "управления NOUN nmod\n",
      "США PROPN nmod\n",
      ", PUNCT punct\n",
      "в ADP case\n",
      "начале NOUN obl\n",
      "июня NOUN nmod\n",
      "распространил VERB ROOT\n",
      "секретный ADJ amod\n",
      "ордер NOUN obj\n",
      "суда NOUN nmod\n",
      ", PUNCT punct\n",
      "по ADP case\n",
      "которому PRON obl\n",
      "спецслужбы NOUN nsubj\n",
      "получили VERB acl:relcl\n",
      "доступ NOUN obj\n",
      "ко ADP case\n",
      "всем DET det\n",
      "звонкам NOUN nmod\n",
      "крупнейшего ADJ amod\n",
      "сотового ADJ amod\n",
      "оператора NOUN nmod\n",
      "Verizon PROPN appos\n",
      ", PUNCT punct\n",
      "а CCONJ cc\n",
      "также ADV fixed\n",
      "данные NOUN conj\n",
      "о ADP case\n",
      "сверхсекретной ADJ amod\n",
      "программе NOUN nmod\n",
      "агентства NOUN nmod\n",
      "национальной ADJ amod\n",
      "безопасности NOUN nmod\n",
      "PRISM PROPN appos\n",
      ", PUNCT punct\n",
      "позволяющей VERB acl\n",
      "отслеживать VERB xcomp\n",
      "электронные ADJ amod\n",
      "коммуникации NOUN obj\n",
      "на ADP case\n",
      "крупнейших ADJ amod\n",
      "сайтах NOUN obl\n",
      ". PUNCT punct\n",
      "В ADP case\n",
      "воскресенье NOUN obl\n",
      "стало VERB ROOT\n",
      "известно ADJ xcomp\n",
      ", PUNCT punct\n",
      "что SCONJ mark\n",
      "Сноуден PROPN nsubj\n",
      "прибыл VERB ccomp\n",
      "из ADP case\n",
      "Гонконга PROPN obl\n",
      "в ADP case\n",
      "Москву PROPN obl\n",
      "и CCONJ cc\n",
      "запросил VERB conj\n",
      "убежища NOUN obj\n",
      "в ADP case\n",
      "Эквадоре PROPN obl\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Что PRON obj\n",
      "ждет VERB ccomp\n",
      "Эдварда PROPN nsubj\n",
      "Сноудена PROPN flat:name\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Эдвард PROPN nsubj\n",
      "Сноуден PROPN flat:name\n",
      ", PUNCT punct\n",
      "наверное ADV parataxis\n",
      ", PUNCT punct\n",
      "не PART advmod\n",
      "знал VERB ROOT\n",
      "только PART advmod\n",
      "одного NUM obj\n",
      ": PUNCT punct\n",
      "что PRON nsubj\n",
      "отныне ADV advmod\n",
      "от ADP case\n",
      "него PRON obl\n",
      "ничего PRON nsubj\n",
      "уже ADV advmod\n",
      "не PART advmod\n",
      "будет AUX aux\n",
      "зависеть VERB parataxis\n",
      ". PUNCT punct\n",
      "Москва PROPN nsubj\n",
      "- PROPN nsubj\n",
      "Гавана PROPN nsubj\n",
      "- PROPN nsubj\n",
      "Каракас PROPN nsubj\n",
      "– PUNCT punct\n",
      "в ADP case\n",
      "новой ADJ amod\n",
      "траектории NOUN ROOT\n",
      "жизни NOUN nmod\n",
      ". PUNCT punct\n",
      "В ADP case\n",
      "плотном ADJ amod\n",
      "кольце NOUN ROOT\n",
      "новых ADJ amod\n",
      "друзей NOUN nmod\n",
      ", PUNCT punct\n",
      "которым PRON iobj\n",
      "нужно ADJ acl:relcl\n",
      "быстро ADV advmod\n",
      "вытащить VERB csubj\n",
      "из ADP case\n",
      "тебя PRON obl\n",
      "то PRON obj\n",
      ", PUNCT punct\n",
      "что SCONJ nsubj\n",
      "еще ADV advmod\n",
      "не PART advmod\n",
      "сказал VERB acl\n",
      ". PUNCT punct\n",
      "А CCONJ cc\n",
      "может VERB parataxis\n",
      ", PUNCT punct\n",
      "говорить VERB csubj\n",
      "больше ADV advmod\n",
      "и CCONJ cc\n",
      "нечего VERB ROOT\n",
      ". PUNCT punct\n",
      "Когда SCONJ mark\n",
      "и PART advmod\n",
      "они PRON nsubj\n",
      "в ADP case\n",
      "этом PRON obl\n",
      "убедятся VERB ROOT\n",
      ", PUNCT punct\n",
      "как ADV advmod\n",
      "раз NOUN fixed\n",
      "объявят VERB advcl\n",
      "посадку NOUN obj\n",
      "в ADP case\n",
      "Каракасе PROPN obl\n",
      ". PUNCT punct\n",
      "Добро NOUN ROOT\n",
      "пожаловать VERB nmod\n",
      "в ADP case\n",
      "третий ADJ amod\n",
      "мир NOUN obl\n",
      ". PUNCT punct\n",
      "Потому ADV mark\n",
      "что SCONJ fixed\n",
      "если SCONJ mark\n",
      "тебе PRON iobj\n",
      "нет VERB advcl\n",
      "место NOUN nsubj\n",
      "в ADP case\n",
      "первом ADJ nmod\n",
      ", PUNCT punct\n",
      "не PART advmod\n",
      "станет VERB ROOT\n",
      "с ADP case\n",
      "тобой PRON obl\n",
      "надолго ADV advmod\n",
      "связываться VERB xcomp\n",
      "и CCONJ cc\n",
      "второй ADJ conj\n",
      ". PUNCT punct\n",
      "Подробнее ADV ROOT\n",
      "> PUNCT punct\n",
      "> PUNCT punct\n",
      "\n",
      "\n",
      "\n",
      " SPACE dep\n"
     ]
    }
   ],
   "source": [
    "for token in article:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c38a13c8-cac8-4204-a156-0cf38d89ff19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>LOC 0 6</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 50 53</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>LOC 57 63</td>\n",
       "      <td>Грузию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 87 93</td>\n",
       "      <td>МОСКВА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>ORG 103 114</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 116 122</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>LOC 141 144</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 161 168</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 301 307</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T10</td>\n",
       "      <td>PER 308 324</td>\n",
       "      <td>Григорий Карасин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T11</td>\n",
       "      <td>LOC 383 386</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T12</td>\n",
       "      <td>PER 387 402</td>\n",
       "      <td>Дэниэлом Фридом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 505 517</td>\n",
       "      <td>Южной Осетии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>LOC 703 709</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 723 730</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T16</td>\n",
       "      <td>LOC 815 825</td>\n",
       "      <td>Вашингтона</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>ORG 838 841</td>\n",
       "      <td>МИД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 842 848</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1                 2\n",
       "0    T1      LOC 0 6            Россия\n",
       "1    T2    LOC 50 53               США\n",
       "2    T3    LOC 57 63            Грузию\n",
       "3    T4    LOC 87 93            МОСКВА\n",
       "4    T5  ORG 103 114       РИА Новости\n",
       "5    T6  LOC 116 122            Россия\n",
       "6    T7  LOC 141 144               США\n",
       "7    T8  LOC 161 168           Тбилиси\n",
       "8    T9  LOC 301 307            России\n",
       "9   T10  PER 308 324  Григорий Карасин\n",
       "10  T11  LOC 383 386               США\n",
       "11  T12  PER 387 402   Дэниэлом Фридом\n",
       "12  T13  LOC 505 517      Южной Осетии\n",
       "13  T14  LOC 703 709            Россия\n",
       "14  T15  LOC 723 730           Тбилиси\n",
       "15  T16  LOC 815 825        Вашингтона\n",
       "16  T17  ORG 838 841               МИД\n",
       "17  T18  LOC 842 848            России"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('collection3/001.ann', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "128a092e-78fb-4613-9667-0b7fb1756691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natasha in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: navec>=0.9.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: pymorphy2 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.9.1)\n",
      "Requirement already satisfied: razdel>=0.5.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: yargy>=0.14.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.15.0)\n",
      "Requirement already satisfied: slovnet>=0.3.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: intervaltree>=3 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: numpy in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from navec>=0.9.0->natasha) (1.21.5)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b89a1cf-d42b-44da-98b4-d6138d08a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: navec in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in /Users/Olga/opt/anaconda3/lib/python3.9/site-packages (from navec) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install navec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c0d3852-d1bd-4834-9cca-506c69683450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Жириновский предлагает обменять с США Сноудена на Бута\n",
      "                                  LOC PER─────    PER─\n",
      "Лидер ЛДПР Владимир Жириновский предложил обменять бывшего сотрудника \n",
      "      ORG─ PER─────────────────                                       \n",
      "ЦРУ США Эдварда Сноудена, который прибыл в Москву, на осужденного в \n",
      "ORG LOC PER─────────────                   LOC───                   \n",
      "Америке бизнесмена Виктора Бута.\n",
      "LOC────            PER───────── \n",
      "\"Сноудена ни в коем случае не высылать в США, а обменять на Виктора \n",
      " PER─────                                LOC                PER─────\n",
      "Бута и Константина Ярошенко. В идеале — добавить генерала Олега \n",
      "────   PER─────────────────                               PER───\n",
      "Калугина\", — написал он в своем микроблоге в Twitter.\n",
      "────────                                     ORG──── \n",
      "Сноуден, работавший на компанию Booz Allen Hamilton — подрядчика \n",
      "PER────                         ORG────────────────              \n",
      "Центрального разведывательного управления США, в начале июня \n",
      "ORG────────────────────────────────────── LOC                \n",
      "распространил секретный ордер суда, по которому спецслужбы получили \n",
      "доступ ко всем звонкам крупнейшего сотового оператора Verizon, а также\n",
      "                                                      ORG────         \n",
      " данные о сверхсекретной программе агентства национальной безопасности\n",
      " PRISM, позволяющей отслеживать электронные коммуникации на крупнейших\n",
      " сайтах. В воскресенье стало известно, что Сноуден прибыл из Гонконга \n",
      "                                           PER────           LOC───── \n",
      "в Москву и запросил убежища в Эквадоре.\n",
      "  LOC───                      LOC───── \n",
      "Что ждет Эдварда Сноудена\n",
      "         PER─────────────\n",
      "Эдвард Сноуден, наверное, не знал только одного: что отныне от него \n",
      "PER───────────                                                      \n",
      "ничего уже не будет зависеть. Москва-Гавана-Каракас – в новой \n",
      "траектории жизни. В плотном кольце новых друзей, которым нужно быстро \n",
      "вытащить из тебя то, что еще не сказал. А может, говорить больше и \n",
      "нечего. Когда и они в этом убедятся, как раз объявят посадку в \n",
      "Каракасе. Добро пожаловать в третий мир. Потому что если тебе нет \n",
      "LOC─────                                                          \n",
      "место в первом, не станет с тобой надолго связываться и второй. \n",
      "Подробнее >>\n"
     ]
    }
   ],
   "source": [
    "text = data_text.text[0]\n",
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "ner = NER.load('slovnet_ner_news_v1.tar')\n",
    "ner.navec(navec)\n",
    "\n",
    "markup = ner(text)\n",
    "show_markup(markup.text, markup.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "988ce1e9-47dd-477c-a8a1-d3f8e1c3643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1040.ann', '517.ann', '271.ann', '265.ann', '503.ann', '04_12_12f.ann', '259.ann', '2039.ann', '2011.ann', '098.ann', '2005.ann', '073.ann', '067.ann', '107.ann', '113.ann', '1134.ann', '1120.ann', '1108.ann', '488.ann', 'last_51.ann', '463.ann', 'turkmenija.ann', '305.ann', '311.ann', 'last_45.ann', '477.ann', '339.ann', '338.ann', '310.ann', '476.ann', 'last_44.ann', '462.ann', 'last_50.ann', 'shojgu3.ann', '304.ann', '489.ann', '1109.ann', '1121.ann', '1135.ann', '112.ann', '106.ann', 'Avtovaz.ann', '066.ann', '072.ann', '2004.ann', '099.ann', '2010.ann', '28_11_12a.ann', '2038.ann', '258.ann', '04_12_12g.ann', '264.ann', '502.ann', '516.ann', '270.ann', '1041.ann', '1043.ann', '299.ann', '500.ann', '266.ann', '272.ann', '514.ann', '528.ann', '2006.ann', '2012.ann', '064.ann', '070.ann', '058.ann', '19_11_12h.ann', '110.ann', '104.ann', '138.ann', '1123.ann', '1137.ann', 'last_46.ann', '474.ann', '312.ann', '306.ann', 'shojgu1.ann', 'last_52.ann', '460.ann', '448.ann', '449.ann', '307.ann', '461.ann', 'last_53.ann', '475.ann', 'last_47.ann', '313.ann', '1136.ann', '1122.ann', '139.ann', '105.ann', '111.ann', '059.ann', '071.ann', '065.ann', '2013.ann', '2007.ann', '04_12_12d.ann', '529.ann', '20_11_12d.ann', '273.ann', '515.ann', '501.ann', '267.ann', '298.ann', '1042.ann', '288.ann', '1046.ann', '539.ann', '263.ann', '505.ann', '511.ann', '277.ann', '2003.ann', '2017.ann', '28_11_12f.ann', '049.ann', '061.ann', '075.ann', '129.ann', '115.ann', '101.ann', '1126.ann', '1132.ann', '459.ann', '317.ann', 'last_43.ann', '471.ann', 'shojgu4.ann', 'last_57.ann', '465.ann', '303.ann', '464.ann', 'last_56.ann', '302.ann', '316.ann', '470.ann', 'last_42.ann', '458.ann', '1133.ann', '1127.ann', '100.ann', '114.ann', '128.ann', '074.ann', '060.ann', '048.ann', '28_11_12g.ann', '2016.ann', '2002.ann', '510.ann', '276.ann', '20_11_12a.ann', '262.ann', '504.ann', '538.ann', '1047.ann', '289.ann', '04_12_12h_corr.ann', '1045.ann', '248.ann', '20_11_12c.ann', '274.ann', '512.ann', '506.ann', '260.ann', '2014.ann', '089.ann', '14_01_13i.ann', '2028.ann', '076.ann', '062.ann', '102.ann', '116.ann', '499.ann', '1119.ann', '1131.ann', '1125.ann', 'last_68.ann', '328.ann', '300.ann', 'last_54.ann', '466.ann', 'last_40.ann', '472.ann', '314.ann', '473.ann', 'last_41.ann', '315.ann', '301.ann', '467.ann', 'last_55.ann', 'shojgu6.ann', '329.ann', 'last_69.ann', '1124.ann', '1130.ann', '1118.ann', '498.ann', '117.ann', '103.ann', '533 (!).ann', '063.ann', 'blokhin.ann', '077.ann', '2029.ann', '2001.ann', '088.ann', '2015.ann', '507.ann', '261.ann', '20_11_12b.ann', '275.ann', '513.ann', '249.ann', '04_12_12b.ann', '1050.ann', '1044.ann', '1023.ann', '1037.ann', '212.ann', '574.ann', '560.ann', '206.ann', '548.ann', '010.ann', '004.ann', '03_12_12b.ann', '038.ann', '602.ann', '164.ann', '170.ann', '616.ann', '21_11_12i.ann', '158.ann', 'kuleshov.ann', '22_11_12g.ann', '1157.ann', '1143.ann', '399.ann', '366.ann', 'last_32.ann', '1194.ann', '400.ann', 'last_26.ann', '414.ann', '1180.ann', '372.ann', '428.ann', '429.ann', '1181.ann', '415.ann', 'last_27.ann', '373.ann', '367.ann', '401.ann', '1195.ann', 'last_33.ann', '15_01_13b.ann', '398.ann', '1142.ann', '1156.ann', '159.ann', '171.ann', '21_11_12h.ann', '617.ann', '165.ann', '039.ann', '03_12_12c.ann', '005.ann', '25_12_12a.ann', '27_11_12c.ann', '011.ann', '549.ann', '561.ann', '207.ann', '213.ann', '575.ann', '09_01_13c.ann', '1036.ann', '1022.ann', '1034.ann', '1020.ann', '1008.ann', '09_01_13a.ann', '588.ann', '205.ann', '563.ann', '577.ann', '211.ann', '239.ann', '25_12_12c.ann', '007.ann', '013.ann', '27_11_12a.ann', 'mvd2.ann', '03_12_12a.ann', '198.ann', '615.ann', '21_11_12j.ann', '30_11_12h.ann', '173.ann', '167.ann', '601.ann', '629.ann', '1140.ann', '1154.ann', '22_11_12d.ann', '1168.ann', '371.ann', 'last_25.ann', '417.ann', '1183.ann', 'last_31.ann', '1197.ann', '403.ann', '365.ann', 'last_19.ann', '359.ann', '358.ann', 'last_18.ann', '402.ann', '1196.ann', '364.ann', '370.ann', '1182.ann', '416.ann', 'last_24.ann', '1169.ann', '15_01_13a.ann', '1155.ann', 'chirkunov.ann', '1141.ann', '628.ann', '166.ann', '600.ann', '30_11_12i.ann', '614.ann', '172.ann', '199.ann', '10_01_13d.ann', '598 (!).ann', '012.ann', '006.ann', '238.ann', '576.ann', '210.ann', '204.ann', '562.ann', '589.ann', '1009.ann', '1021.ann', '1035.ann', '599.ann', '09_01_13d.ann', '1019.ann', '1031.ann', '1025.ann', '228.ann', '200.ann', '214.ann', '572.ann', '2048.ann', '03_12_12d.ann', '002.ann', '27_11_12d.ann', '016.ann', '189.ann', '176.ann', '610.ann', '162.ann', '1179.ann', '15_01_13e.ann', '09_01_13.ann', '1145.ann', '22_11_12a.ann', '1151.ann', '348.ann', 'last_08.ann', 'lenoblast.ann', 'last_20.ann', '412.ann', '1186.ann', '374.ann', '360.ann', 'last_34.ann', '1192.ann', '406.ann', '361.ann', '407.ann', '1193.ann', 'last_35.ann', '1187.ann', '413.ann', 'last_21.ann', '375.ann', 'last_09.ann', '349.ann', '1150.ann', '1144.ann', '1178.ann', '163.ann', '177.ann', '611.ann', '188.ann', '27_11_12e.ann', '017.ann', '003.ann', '10_01_13a.ann', '2049.ann', '215.ann', '567.ann', '201.ann', '229.ann', '1024.ann', '1030.ann', '1018.ann', '09_01_13e.ann', '1026.ann', '1032.ann', '559.ann', '571.ann', '217.ann', '203.ann', '565.ann', '029.ann', '03_12_12g.ann', '25_12_12e.ann', '001.ann', '149.ann', '161.ann', '613.ann', '175.ann', '388.ann', '15_01_13f.ann', '1152.ann', '1146.ann', '439.ann', 'last_37.ann', '1191.ann', '405.ann', '363.ann', '377.ann', 'last_23.ann', '411.ann', '1185.ann', '376.ann', '1184.ann', '410.ann', 'last_22.ann', '404.ann', '1190.ann', 'last_36.ann', '362.ann', '438.ann', '1147.ann', '1153.ann', '22_11_12c.ann', '389.ann', '612.ann', '174.ann', '160.ann', '148.ann', 'rosobrnadzor.ann', '25_12_12d.ann', '014.ann', '028.ann', '202.ann', '564.ann', '570.ann', '216.ann', '558.ann', '1033.ann', '1027.ann', '596.ann', '1002.ann', '1016.ann', '582.ann', '233.ann', '541.ann', '227.ann', '569.ann', '1200.ann', '2047.ann', '031.ann', '025.ann', '019.ann', '186.ann', '192.ann', '623.ann', '145.ann', '151.ann', '30_11_12b.ann', '179.ann', '384.ann', '1176.ann', '1162.ann', '390.ann', '347.ann', 'last_13.ann', '421.ann', '435.ann', '353.ann', '1189.ann', '409.ann', '408.ann', '1188.ann', '434.ann', 'last_06.ann', '352.ann', '346.ann', '420.ann', 'last_12.ann', 'sobjanin2.ann', '1163.ann', '391.ann', '385.ann', '1177.ann', '178.ann', '150.ann', '622.ann', '144.ann', '193.ann', '187.ann', '018.ann', '27_11_12j.ann', '030.ann', '2046.ann', '568.ann', '540.ann', '226.ann', '232.ann', '554.ann', '583.ann', '1017.ann', '1003.ann', '597.ann', '09_01_13h.ann', '1015.ann', '581.ann', '595.ann', '1001.ann', 'last_07_new.ann', '1029.ann', '224.ann', '542.ann', '556.ann', '230.ann', '218.ann', '2044.ann', '2050.ann', '03_12_12h.ann', '026.ann', '032.ann', '191.ann', '185.ann', '152.ann', '146.ann', '620.ann', '21_11_12c.ann', '393.ann', '1161.ann', '1175.ann', '387.ann', '1149.ann', '350.ann', 'last_04.ann', '436.ann', 'last_10.ann', '422.ann', '344.ann', 'last_38.ann', '378.ann', '379.ann', 'last_39.ann', '423.ann', 'last_11.ann', '345.ann', '351.ann', '437.ann', 'last_05.ann', '1148.ann', '04_03_13a_sorokin.ann', '1174.ann', '386.ann', '392.ann', '1160.ann', '147.ann', '621.ann', '153.ann', '184.ann', '190.ann', '033.ann', '027.ann', '2045.ann', '219.ann', '557.ann', '231.ann', '225.ann', '543.ann', '1028.ann', '1000.ann', '594.ann', '1014.ann', '09_01_13i.ann', '1038.ann', '1010.ann', '590.ann', '1004.ann', '209.ann', '547.ann', '221.ann', '235.ann', '553.ann', 'chaves.ann', '2041.ann', '023.ann', '10_01_13i.ann', '037.ann', '194.ann', '180.ann', '619.ann', '157.ann', '631.ann', '625.ann', '143.ann', '1158.ann', '22_11_12h.ann', '1164.ann', '396.ann', '382.ann', '1170.ann', '369.ann', 'last_29.ann', 'last_01.ann', '433.ann', '355.ann', '341.ann', 'last_15.ann', '427.ann', '340.ann', '426.ann', 'last_14.ann', '432.ann', '354.ann', 'last_28.ann', '368.ann', '383.ann', '1171.ann', '1165.ann', '397.ann', '1159.ann', '29_11_12a.ann', '22_11_12i.ann', 'si_tzjanpin.ann', '624.ann', '142.ann', '156.ann', '630.ann', '618.ann', '181.ann', '195.ann', 'uchitel.ann', '036.ann', '022.ann', '2040.ann', '234.ann', '552.ann', '546.ann', '220.ann', '208.ann', '1005.ann', '591.ann', '585.ann', '1011.ann', '1039.ann', '593.ann', '1007.ann', '1013.ann', '587.ann', '584 (!).ann', '578.ann', '550.ann', '236.ann', '222.ann', '544.ann', '2042.ann', '04_02_13a_abdulatipov.ann', '008.ann', '034.ann', '020.ann', '183.ann', '197.ann', '168.ann', '140.ann', '626.ann', '632.ann', '154.ann', '1173.ann', '381.ann', '395.ann', 'maykl dzhekson.ann', '1167.ann', '418.ann', '1198.ann', 'last_16.ann', '424.ann', '342.ann', '356.ann', 'last_02.ann', '430.ann', '357.ann', '431.ann', 'last_03.ann', '425.ann', 'last_17.ann', '343.ann', '1199.ann', '419.ann', '394.ann', '1166.ann', '1172.ann', 'artjakov.ann', '380.ann', '29_11_12b.ann', '22_11_12j.ann', '633.ann', '155.ann', '141.ann', '627.ann', '169.ann', '196.ann', '182.ann', '021.ann', '035.ann', '009.ann', '2043.ann', 'last_30_new.ann', '223.ann', '545.ann', '551.ann', 'kamchatka.ann', '237.ann', '579.ann', '586.ann', '1012.ann', '1006.ann', '592.ann', '293.ann', '287.ann', '1049.ann', '536.ann', '250.ann', '244.ann', '522.ann', '278.ann', '091.ann', '085.ann', '2018.ann', '2030.ann', '23_11_12a.ann', '28_11_12i.ann', '2024.ann', '015 (!).ann', '052.ann', '046.ann', '126.ann', '132.ann', '481.ann', '1115.ann', '1101.ann', '495.ann', 'last_70.ann', '442.ann', '324.ann', '330.ann', 'last_64.ann', '318.ann', 'last_58.ann', 'last_59.ann', '26_11_12e.ann', '319.ann', '331.ann', '457.ann', 'last_65.ann', '443.ann', 'last_71.ann', '325.ann', '1128.ann', '494.ann', '1100.ann', '1114.ann', '480.ann', '133.ann', '127.ann', '047.ann', '053.ann', 'semenenko.ann', '2025.ann', '2031.ann', '28_11_12h.ann', '2019.ann', '084.ann', '090.ann', '279.ann', '245.ann', '523.ann', '537.ann', '251.ann', '1048.ann', '286.ann', '292.ann', '284.ann', '290.ann', '521.ann', '247.ann', '253.ann', '535.ann', '509.ann', '086.ann', '092.ann', '2027.ann', '23_11_12b.ann', '28_11_12j.ann', '045.ann', '051.ann', '079.ann', '131.ann', '125.ann', '119.ann', '1102.ann', '496.ann', '482.ann', '1116.ann', 'last_67.ann', '455.ann', '333.ann', '327.ann', 'last_73.ann', '441.ann', '469.ann', '26_11_12f.ann', '468.ann', '326.ann', '440.ann', 'last_72.ann', '454.ann', 'last_66.ann', '11_01_13b.ann', '332.ann', '1117.ann', '483.ann', '497.ann', '1103.ann', '118.ann', '124.ann', '130.ann', '078.ann', '050.ann', '044.ann', '23_11_12c.ann', '2032.ann', '2026.ann', '093.ann', '087.ann', '14_01_13g.ann', '508.ann', '252.ann', '534.ann', '520.ann', '246.ann', '291.ann', '285.ann', '281.ann', '295.ann', '20_11_12i.ann', '518.ann', '242.ann', '524.ann', '530.ann', '256.ann', '2022.ann', '2036.ann', '083.ann', '14_01_13c.ann', '097.ann', '068.ann', '040.ann', '054.ann', '19_11_12d.ann', '108.ann', '134.ann', '120.ann', '1107.ann', '493.ann', '487.ann', '1113.ann', '478.ann', '26_11_12b.ann', '336.ann', 'last_62.ann', '450.ann', '444.ann', '322.ann', '445.ann', '323.ann', '337.ann', '451.ann', 'last_63.ann', '479.ann', '26_11_12c.ann', '1112.ann', '486.ann', '492.ann', '1106.ann', '121.ann', '135.ann', '109.ann', '055.ann', '041.ann', '069.ann', '096.ann', '082.ann', '2037.ann', '23_11_12f.ann', '2023.ann', '531.ann', '257.ann', '243.ann', '525.ann', '519.ann', '294.ann', '280.ann', '296.ann', '282.ann', '269.ann', '255.ann', '527.ann', '241.ann', '23_11_12d.ann', '2035.ann', '2021.ann', '2009.ann', '094.ann', '080.ann', '057.ann', '043.ann', 'klinton.ann', '123.ann', '137.ann', '1138.ann', '484.ann', '1110.ann', '1104.ann', '490.ann', '555 (!).ann', 'last_49.ann', '309.ann', '321.ann', 'last_75.ann', '447.ann', '11_01_13e.ann', 'last_61.ann', '453.ann', '335.ann', '452.ann', 'last_60.ann', '334.ann', '320.ann', '446.ann', 'last_74.ann', '308.ann', 'last_48.ann', '491.ann', '1105.ann', '1111.ann', '485.ann', '1139.ann', '136.ann', '122.ann', 'mvd.ann', '042.ann', '056.ann', '081.ann', 'ryadovoy chelah.ann', '095.ann', '2008.ann', '2020.ann', '23_11_12e.ann', '2034.ann', '526.ann', '240.ann', '254.ann', '532.ann', '268.ann', '283.ann', 'abdulatipov.ann', '297.ann']\n"
     ]
    }
   ],
   "source": [
    "fileDir = r\"collection3\"\n",
    "fileExt = r\".ann\"\n",
    "documents_ann = [_ for _ in os.listdir(fileDir) if _.endswith(fileExt)]\n",
    "print(documents_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83697b23-1d48-4e02-b312-c8f968cc0bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>LOC 0 6</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 50 53</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>LOC 57 63</td>\n",
       "      <td>Грузию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 87 93</td>\n",
       "      <td>МОСКВА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>ORG 103 114</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 116 122</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>LOC 141 144</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 161 168</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 301 307</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T10</td>\n",
       "      <td>PER 308 324</td>\n",
       "      <td>Григорий Карасин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T11</td>\n",
       "      <td>LOC 383 386</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T12</td>\n",
       "      <td>PER 387 402</td>\n",
       "      <td>Дэниэлом Фридом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 505 517</td>\n",
       "      <td>Южной Осетии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>LOC 703 709</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 723 730</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T16</td>\n",
       "      <td>LOC 815 825</td>\n",
       "      <td>Вашингтона</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>ORG 838 841</td>\n",
       "      <td>МИД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 842 848</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1                 2\n",
       "0    T1      LOC 0 6            Россия\n",
       "1    T2    LOC 50 53               США\n",
       "2    T3    LOC 57 63            Грузию\n",
       "3    T4    LOC 87 93            МОСКВА\n",
       "4    T5  ORG 103 114       РИА Новости\n",
       "5    T6  LOC 116 122            Россия\n",
       "6    T7  LOC 141 144               США\n",
       "7    T8  LOC 161 168           Тбилиси\n",
       "8    T9  LOC 301 307            России\n",
       "9   T10  PER 308 324  Григорий Карасин\n",
       "10  T11  LOC 383 386               США\n",
       "11  T12  PER 387 402   Дэниэлом Фридом\n",
       "12  T13  LOC 505 517      Южной Осетии\n",
       "13  T14  LOC 703 709            Россия\n",
       "14  T15  LOC 723 730           Тбилиси\n",
       "15  T16  LOC 815 825        Вашингтона\n",
       "16  T17  ORG 838 841               МИД\n",
       "17  T18  LOC 842 848            России"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = pd.read_csv('collection3/001.ann', delimiter='\\t', header=None)\n",
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a776056-e9dd-4ff6-a3e5-436eaa380290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "docs = []\n",
    "for i in range(len(data_text)):\n",
    "    words = []\n",
    "    labels = []\n",
    "    text = data_text['text'][i]\n",
    "    \n",
    "    df = pd.read_csv('collection3/' + documents_ann[i], delimiter='\\t', header=None, quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "    df_ann = pd.DataFrame()\n",
    "    df_ann['Token'] = df.loc[:, 2]\n",
    "    split_1 = [loc.split() for loc in df.loc[:, 1].values]\n",
    "    df_ann['Entity'] = [loc[0] for loc in split_1]\n",
    "       \n",
    "    dic = {}\n",
    "    for j in range(len(df)):\n",
    "        token = df_ann['Token'][j].lower().split()\n",
    "        entity = df_ann['Entity'][j]\n",
    "        for tok in token:\n",
    "            dic[tok] = entity\n",
    "\n",
    "    for token in tokenize(text):\n",
    "        if (token.text.lower() in dic.keys()):\n",
    "            words.append(token.text)\n",
    "            labels.append(dic[token.text.lower()])\n",
    "        else:\n",
    "            words.append(token.text)\n",
    "            labels.append('OUT')\n",
    "    \n",
    "    docs.append([words, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d51ced4e-4daa-4a75-a8b1-cd757c827b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Жириновский', 'предлагает', 'обменять', 'с', 'США', 'Сноудена', 'на', 'Бута', 'Лидер', 'ЛДПР', 'Владимир', 'Жириновский', 'предложил', 'обменять', 'бывшего', 'сотрудника', 'ЦРУ', 'США', 'Эдварда', 'Сноудена', ',', 'который', 'прибыл', 'в', 'Москву', ',', 'на', 'осужденного', 'в', 'Америке', 'бизнесмена', 'Виктора', 'Бута', '.', '\"', 'Сноудена', 'ни', 'в', 'коем', 'случае', 'не', 'высылать', 'в', 'США', ',', 'а', 'обменять', 'на', 'Виктора', 'Бута', 'и', 'Константина', 'Ярошенко', '.', 'В', 'идеале', '—', 'добавить', 'генерала', 'Олега', 'Калугина', '\"', ',', '—', 'написал', 'он', 'в', 'своем', 'микроблоге', 'в', 'Twitter', '.', 'Сноуден', ',', 'работавший', 'на', 'компанию', 'Booz', 'Allen', 'Hamilton', '—', 'подрядчика', 'Центрального', 'разведывательного', 'управления', 'США', ',', 'в', 'начале', 'июня', 'распространил', 'секретный', 'ордер', 'суда', ',', 'по', 'которому', 'спецслужбы', 'получили', 'доступ', 'ко', 'всем', 'звонкам', 'крупнейшего', 'сотового', 'оператора', 'Verizon', ',', 'а', 'также', 'данные', 'о', 'сверхсекретной', 'программе', 'агентства', 'национальной', 'безопасности', 'PRISM', ',', 'позволяющей', 'отслеживать', 'электронные', 'коммуникации', 'на', 'крупнейших', 'сайтах', '.', 'В', 'воскресенье', 'стало', 'известно', ',', 'что', 'Сноуден', 'прибыл', 'из', 'Гонконга', 'в', 'Москву', 'и', 'запросил', 'убежища', 'в', 'Эквадоре', '.', 'Что', 'ждет', 'Эдварда', 'Сноудена', 'Эдвард', 'Сноуден', ',', 'наверное', ',', 'не', 'знал', 'только', 'одного', ':', 'что', 'отныне', 'от', 'него', 'ничего', 'уже', 'не', 'будет', 'зависеть', '.', 'Москва-Гавана-Каракас', '–', 'в', 'новой', 'траектории', 'жизни', '.', 'В', 'плотном', 'кольце', 'новых', 'друзей', ',', 'которым', 'нужно', 'быстро', 'вытащить', 'из', 'тебя', 'то', ',', 'что', 'еще', 'не', 'сказал', '.', 'А', 'может', ',', 'говорить', 'больше', 'и', 'нечего', '.', 'Когда', 'и', 'они', 'в', 'этом', 'убедятся', ',', 'как', 'раз', 'объявят', 'посадку', 'в', 'Каракасе', '.', 'Добро', 'пожаловать', 'в', 'третий', 'мир', '.', 'Потому', 'что', 'если', 'тебе', 'нет', 'место', 'в', 'первом', ',', 'не', 'станет', 'с', 'тобой', 'надолго', 'связываться', 'и', 'второй', '.', 'Подробнее', '>', '>']\n",
      "['OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(docs[0][0]), print(docs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6926406a-0dd0-4d31-bfee-4149e9741933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Жириновский\tOUT\n",
      "предлагает\tOUT\n",
      "обменять\tOUT\n",
      "с\tOUT\n",
      "США\tOUT\n",
      "Сноудена\tOUT\n",
      "на\tOUT\n",
      "Бута\tOUT\n",
      "Лидер\tOUT\n",
      "ЛДПР\tOUT\n",
      "Владимир\tOUT\n",
      "Жириновский\tOUT\n",
      "предложил\tOUT\n",
      "обменять\tOUT\n",
      "бывшего\tOUT\n",
      "сотрудника\tOUT\n",
      "ЦРУ\tOUT\n",
      "США\tOUT\n",
      "Эдварда\tOUT\n",
      "Сноудена\tOUT\n",
      ",\tOUT\n",
      "который\tOUT\n",
      "прибыл\tOUT\n",
      "в\tOUT\n",
      "Москву\tOUT\n",
      ",\tOUT\n",
      "на\tOUT\n",
      "осужденного\tOUT\n",
      "в\tOUT\n",
      "Америке\tOUT\n",
      "бизнесмена\tOUT\n",
      "Виктора\tOUT\n",
      "Бута\tOUT\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "Сноудена\tOUT\n",
      "ни\tOUT\n",
      "в\tOUT\n",
      "коем\tOUT\n",
      "случае\tOUT\n",
      "не\tOUT\n",
      "высылать\tOUT\n",
      "в\tOUT\n",
      "США\tOUT\n",
      ",\tOUT\n",
      "а\tOUT\n",
      "обменять\tOUT\n",
      "на\tOUT\n",
      "Виктора\tOUT\n",
      "Бута\tOUT\n",
      "и\tOUT\n",
      "Константина\tOUT\n",
      "Ярошенко\tOUT\n",
      ".\tOUT\n",
      "В\tOUT\n",
      "идеале\tOUT\n",
      "—\tOUT\n",
      "добавить\tOUT\n",
      "генерала\tOUT\n",
      "Олега\tOUT\n",
      "Калугина\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "—\tOUT\n",
      "написал\tOUT\n",
      "он\tOUT\n",
      "в\tOUT\n",
      "своем\tOUT\n",
      "микроблоге\tOUT\n",
      "в\tOUT\n",
      "Twitter\tOUT\n",
      ".\tOUT\n",
      "Сноуден\tOUT\n",
      ",\tOUT\n",
      "работавший\tOUT\n",
      "на\tOUT\n",
      "компанию\tOUT\n",
      "Booz\tOUT\n",
      "Allen\tOUT\n",
      "Hamilton\tOUT\n",
      "—\tOUT\n",
      "подрядчика\tOUT\n",
      "Центрального\tOUT\n",
      "разведывательного\tOUT\n",
      "управления\tOUT\n",
      "США\tOUT\n",
      ",\tOUT\n",
      "в\tOUT\n",
      "начале\tOUT\n",
      "июня\tOUT\n",
      "распространил\tOUT\n",
      "секретный\tOUT\n",
      "ордер\tOUT\n",
      "суда\tOUT\n",
      ",\tOUT\n",
      "по\tOUT\n",
      "которому\tOUT\n",
      "спецслужбы\tOUT\n",
      "получили\tOUT\n",
      "доступ\tOUT\n",
      "ко\tOUT\n",
      "всем\tOUT\n",
      "звонкам\tOUT\n",
      "крупнейшего\tOUT\n",
      "сотового\tOUT\n",
      "оператора\tOUT\n",
      "Verizon\tOUT\n",
      ",\tOUT\n",
      "а\tOUT\n",
      "также\tOUT\n",
      "данные\tOUT\n",
      "о\tOUT\n",
      "сверхсекретной\tOUT\n",
      "программе\tOUT\n",
      "агентства\tOUT\n",
      "национальной\tOUT\n",
      "безопасности\tOUT\n",
      "PRISM\tOUT\n",
      ",\tOUT\n",
      "позволяющей\tOUT\n",
      "отслеживать\tOUT\n",
      "электронные\tOUT\n",
      "коммуникации\tOUT\n",
      "на\tOUT\n",
      "крупнейших\tOUT\n",
      "сайтах\tOUT\n",
      ".\tOUT\n",
      "В\tOUT\n",
      "воскресенье\tOUT\n",
      "стало\tOUT\n",
      "известно\tOUT\n",
      ",\tOUT\n",
      "что\tOUT\n",
      "Сноуден\tOUT\n",
      "прибыл\tOUT\n",
      "из\tOUT\n",
      "Гонконга\tOUT\n",
      "в\tOUT\n",
      "Москву\tOUT\n",
      "и\tOUT\n",
      "запросил\tOUT\n",
      "убежища\tOUT\n",
      "в\tOUT\n",
      "Эквадоре\tOUT\n",
      ".\tOUT\n",
      "Что\tOUT\n",
      "ждет\tOUT\n",
      "Эдварда\tOUT\n",
      "Сноудена\tOUT\n",
      "Эдвард\tOUT\n",
      "Сноуден\tOUT\n",
      ",\tOUT\n",
      "наверное\tOUT\n",
      ",\tOUT\n",
      "не\tOUT\n",
      "знал\tOUT\n",
      "только\tOUT\n",
      "одного\tOUT\n",
      ":\tOUT\n",
      "что\tOUT\n",
      "отныне\tOUT\n",
      "от\tOUT\n",
      "него\tOUT\n",
      "ничего\tOUT\n",
      "уже\tOUT\n",
      "не\tOUT\n",
      "будет\tOUT\n",
      "зависеть\tOUT\n",
      ".\tOUT\n",
      "Москва-Гавана-Каракас\tOUT\n",
      "–\tOUT\n",
      "в\tOUT\n",
      "новой\tOUT\n",
      "траектории\tOUT\n",
      "жизни\tOUT\n",
      ".\tOUT\n",
      "В\tOUT\n",
      "плотном\tOUT\n",
      "кольце\tOUT\n",
      "новых\tOUT\n",
      "друзей\tOUT\n",
      ",\tOUT\n",
      "которым\tOUT\n",
      "нужно\tOUT\n",
      "быстро\tOUT\n",
      "вытащить\tOUT\n",
      "из\tOUT\n",
      "тебя\tOUT\n",
      "то\tOUT\n",
      ",\tOUT\n",
      "что\tOUT\n",
      "еще\tOUT\n",
      "не\tOUT\n",
      "сказал\tOUT\n",
      ".\tOUT\n",
      "А\tOUT\n",
      "может\tOUT\n",
      ",\tOUT\n",
      "говорить\tOUT\n",
      "больше\tOUT\n",
      "и\tOUT\n",
      "нечего\tOUT\n",
      ".\tOUT\n",
      "Когда\tOUT\n",
      "и\tOUT\n",
      "они\tOUT\n",
      "в\tOUT\n",
      "этом\tOUT\n",
      "убедятся\tOUT\n",
      ",\tOUT\n",
      "как\tOUT\n",
      "раз\tOUT\n",
      "объявят\tOUT\n",
      "посадку\tOUT\n",
      "в\tOUT\n",
      "Каракасе\tOUT\n",
      ".\tOUT\n",
      "Добро\tOUT\n",
      "пожаловать\tOUT\n",
      "в\tOUT\n",
      "третий\tOUT\n",
      "мир\tOUT\n",
      ".\tOUT\n",
      "Потому\tOUT\n",
      "что\tOUT\n",
      "если\tOUT\n",
      "тебе\tOUT\n",
      "нет\tOUT\n",
      "место\tOUT\n",
      "в\tOUT\n",
      "первом\tOUT\n",
      ",\tOUT\n",
      "не\tOUT\n",
      "станет\tOUT\n",
      "с\tOUT\n",
      "тобой\tOUT\n",
      "надолго\tOUT\n",
      "связываться\tOUT\n",
      "и\tOUT\n",
      "второй\tOUT\n",
      ".\tOUT\n",
      "Подробнее\tOUT\n",
      ">\tOUT\n",
      ">\tOUT\n"
     ]
    }
   ],
   "source": [
    "data, labels = list(zip(*docs))\n",
    "for w, e in zip(data[0], labels[0]):\n",
    "    print(f'{w}\\t{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8181bc73-46f7-4851-861b-62c99970c32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>data</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Жириновский</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>предлагает</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>обменять</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>с</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>США</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Сноудена</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>на</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Бута</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Лидер</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>ЛДПР</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Владимир</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Жириновский</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>предложил</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>обменять</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>бывшего</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>сотрудника</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>ЦРУ</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>США</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Эдварда</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Сноудена</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>который</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>прибыл</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>Москву</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>на</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>осужденного</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>Америке</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>бизнесмена</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>Виктора</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>Бута</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>\"</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>Сноудена</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>ни</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>коем</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>случае</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>не</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>высылать</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>США</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>а</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>обменять</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>на</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>Виктора</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>Бута</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id         data entities\n",
       "0         0  Жириновский      OUT\n",
       "1         0   предлагает      OUT\n",
       "2         0     обменять      OUT\n",
       "3         0            с      OUT\n",
       "4         0          США      OUT\n",
       "5         0     Сноудена      OUT\n",
       "6         0           на      OUT\n",
       "7         0         Бута      OUT\n",
       "8         0        Лидер      OUT\n",
       "9         0         ЛДПР      OUT\n",
       "10        0     Владимир      OUT\n",
       "11        0  Жириновский      OUT\n",
       "12        0    предложил      OUT\n",
       "13        0     обменять      OUT\n",
       "14        0      бывшего      OUT\n",
       "15        0   сотрудника      OUT\n",
       "16        0          ЦРУ      OUT\n",
       "17        0          США      OUT\n",
       "18        0      Эдварда      OUT\n",
       "19        0     Сноудена      OUT\n",
       "20        0            ,      OUT\n",
       "21        0      который      OUT\n",
       "22        0       прибыл      OUT\n",
       "23        0            в      OUT\n",
       "24        0       Москву      OUT\n",
       "25        0            ,      OUT\n",
       "26        0           на      OUT\n",
       "27        0  осужденного      OUT\n",
       "28        0            в      OUT\n",
       "29        0      Америке      OUT\n",
       "30        0   бизнесмена      OUT\n",
       "31        0      Виктора      OUT\n",
       "32        0         Бута      OUT\n",
       "33        0            .      OUT\n",
       "34        0            \"      OUT\n",
       "35        0     Сноудена      OUT\n",
       "36        0           ни      OUT\n",
       "37        0            в      OUT\n",
       "38        0         коем      OUT\n",
       "39        0       случае      OUT\n",
       "40        0           не      OUT\n",
       "41        0     высылать      OUT\n",
       "42        0            в      OUT\n",
       "43        0          США      OUT\n",
       "44        0            ,      OUT\n",
       "45        0            а      OUT\n",
       "46        0     обменять      OUT\n",
       "47        0           на      OUT\n",
       "48        0      Виктора      OUT\n",
       "49        0         Бута      OUT"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sent_id': [i for j in [[i] * len(s) for i, s in enumerate(data)] for i in j],\n",
    "                   'data': [i for j in data for i in j],\n",
    "                   'entities': [i for j in labels for i in j]})\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "890261e4-a140-488d-a453-ff760ba15d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s['data'].values.tolist(), \n",
    "                                                           s['entities'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('sent_id').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(df)\n",
    "\n",
    "sentences = getter.sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ad4f7dd-a859-4448-ae07-67fa8b3bd14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i + 1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76192aab-4115-43c0-91f7-5a799bd55460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8610816d-5b96-4457-9f28-5d223db55403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'в',\n",
       " 'word[-3:]': 'в',\n",
       " 'word[-2:]': 'в',\n",
       " 'word.isdigit()': False,\n",
       " '-1:word.lower()': 'работать',\n",
       " '+1:word.lower()': 'администрации'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92f43f4c-ac50-4bd9-abde-35d57df83917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4797b31-42eb-4d2b-aca2-4a54e297eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:700]\n",
    "X_test = X[700:]\n",
    "y_train = y[:700]\n",
    "y_test = y[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f17834a9-2575-4124-bc86-fc94318db0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 700/700 [00:04<00:00, 162.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 85907\n",
      "Seconds required: 0.964\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 1000\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.22  loss=65101.15 active=85833 feature_norm=1.00\n",
      "Iter 2   time=0.11  loss=11866.86 active=85408 feature_norm=2.09\n",
      "Iter 3   time=0.12  loss=11479.92 active=85618 feature_norm=2.15\n",
      "Iter 4   time=0.11  loss=10762.37 active=41710 feature_norm=2.36\n",
      "Iter 5   time=0.11  loss=10578.59 active=29199 feature_norm=2.47\n",
      "Iter 6   time=0.12  loss=10362.50 active=19895 feature_norm=2.60\n",
      "Iter 7   time=0.11  loss=9836.94  active=14718 feature_norm=2.78\n",
      "Iter 8   time=0.23  loss=8791.67  active=11988 feature_norm=3.95\n",
      "Iter 9   time=0.12  loss=8383.66  active=13726 feature_norm=4.18\n",
      "Iter 10  time=0.11  loss=8056.35  active=13147 feature_norm=5.19\n",
      "Iter 11  time=0.14  loss=7839.94  active=12830 feature_norm=5.36\n",
      "Iter 12  time=0.12  loss=7554.27  active=11725 feature_norm=6.31\n",
      "Iter 13  time=0.11  loss=7429.68  active=11962 feature_norm=6.55\n",
      "Iter 14  time=0.11  loss=7189.23  active=11735 feature_norm=7.47\n",
      "Iter 15  time=0.12  loss=6996.81  active=11432 feature_norm=8.75\n",
      "Iter 16  time=0.12  loss=6865.93  active=11547 feature_norm=9.00\n",
      "Iter 17  time=0.11  loss=6699.19  active=11082 feature_norm=9.70\n",
      "Iter 18  time=0.12  loss=6464.78  active=10049 feature_norm=11.43\n",
      "Iter 19  time=0.12  loss=6255.82  active=9289  feature_norm=13.40\n",
      "Iter 20  time=0.13  loss=6012.58  active=10130 feature_norm=15.01\n",
      "Iter 21  time=0.12  loss=5894.59  active=9574  feature_norm=18.31\n",
      "Iter 22  time=0.13  loss=5750.13  active=9822  feature_norm=18.59\n",
      "Iter 23  time=0.10  loss=5659.31  active=8961  feature_norm=19.56\n",
      "Iter 24  time=0.12  loss=5486.29  active=8673  feature_norm=25.28\n",
      "Iter 25  time=0.13  loss=5336.04  active=8801  feature_norm=24.73\n",
      "Iter 26  time=0.11  loss=5266.81  active=8738  feature_norm=25.56\n",
      "Iter 27  time=0.11  loss=5118.26  active=8526  feature_norm=31.55\n",
      "Iter 28  time=0.13  loss=4956.95  active=8713  feature_norm=32.36\n",
      "Iter 29  time=0.10  loss=4844.93  active=8505  feature_norm=34.44\n",
      "Iter 30  time=0.23  loss=4742.88  active=8213  feature_norm=35.16\n",
      "Iter 31  time=0.13  loss=4495.90  active=8224  feature_norm=44.57\n",
      "Iter 32  time=0.11  loss=4373.42  active=8236  feature_norm=48.34\n",
      "Iter 33  time=0.11  loss=4295.12  active=8180  feature_norm=50.99\n",
      "Iter 34  time=0.12  loss=4149.02  active=7846  feature_norm=59.32\n",
      "Iter 35  time=0.31  loss=4127.76  active=7770  feature_norm=60.62\n",
      "Iter 36  time=0.11  loss=4076.89  active=7735  feature_norm=61.97\n",
      "Iter 37  time=0.12  loss=4040.85  active=7659  feature_norm=64.56\n",
      "Iter 38  time=0.12  loss=4002.48  active=7507  feature_norm=66.80\n",
      "Iter 39  time=0.11  loss=3975.29  active=7266  feature_norm=69.35\n",
      "Iter 40  time=0.11  loss=3962.59  active=7226  feature_norm=70.05\n",
      "Iter 41  time=0.11  loss=3944.03  active=7076  feature_norm=71.27\n",
      "Iter 42  time=0.12  loss=3932.99  active=6827  feature_norm=71.89\n",
      "Iter 43  time=0.12  loss=3925.21  active=6648  feature_norm=72.68\n",
      "Iter 44  time=0.12  loss=3918.84  active=6575  feature_norm=72.94\n",
      "Iter 45  time=0.12  loss=3913.26  active=6481  feature_norm=73.29\n",
      "Iter 46  time=0.12  loss=3907.35  active=6377  feature_norm=73.39\n",
      "Iter 47  time=0.11  loss=3902.32  active=6171  feature_norm=73.71\n",
      "Iter 48  time=0.12  loss=3897.93  active=6115  feature_norm=73.72\n",
      "Iter 49  time=0.12  loss=3894.95  active=6040  feature_norm=73.93\n",
      "Iter 50  time=0.11  loss=3891.26  active=5641  feature_norm=74.09\n",
      "Iter 51  time=0.12  loss=3888.41  active=5566  feature_norm=74.40\n",
      "Iter 52  time=0.13  loss=3886.10  active=5527  feature_norm=74.43\n",
      "Iter 53  time=0.12  loss=3883.48  active=5502  feature_norm=74.61\n",
      "Iter 54  time=0.11  loss=3880.79  active=5431  feature_norm=74.69\n",
      "Iter 55  time=0.11  loss=3878.91  active=5417  feature_norm=74.85\n",
      "Iter 56  time=0.14  loss=3877.12  active=5406  feature_norm=74.89\n",
      "Iter 57  time=0.15  loss=3875.36  active=5383  feature_norm=75.08\n",
      "Iter 58  time=0.12  loss=3873.72  active=5380  feature_norm=75.11\n",
      "Iter 59  time=0.11  loss=3872.42  active=5367  feature_norm=75.24\n",
      "Iter 60  time=0.13  loss=3870.81  active=5348  feature_norm=75.32\n",
      "Iter 61  time=0.11  loss=3870.35  active=5319  feature_norm=75.49\n",
      "Iter 62  time=0.12  loss=3868.81  active=5322  feature_norm=75.47\n",
      "Iter 63  time=0.10  loss=3868.23  active=5312  feature_norm=75.54\n",
      "Iter 64  time=0.11  loss=3867.43  active=5304  feature_norm=75.56\n",
      "Iter 65  time=0.10  loss=3866.76  active=5265  feature_norm=75.67\n",
      "Iter 66  time=0.11  loss=3865.94  active=5268  feature_norm=75.66\n",
      "Iter 67  time=0.12  loss=3865.25  active=5256  feature_norm=75.76\n",
      "Iter 68  time=0.12  loss=3864.57  active=5246  feature_norm=75.76\n",
      "Iter 69  time=0.11  loss=3863.87  active=5222  feature_norm=75.85\n",
      "Iter 70  time=0.11  loss=3863.42  active=5208  feature_norm=75.85\n",
      "Iter 71  time=0.11  loss=3862.71  active=5195  feature_norm=75.98\n",
      "Iter 72  time=0.10  loss=3862.13  active=5187  feature_norm=75.96\n",
      "Iter 73  time=0.11  loss=3861.60  active=5179  feature_norm=76.02\n",
      "Iter 74  time=0.12  loss=3861.12  active=5180  feature_norm=76.03\n",
      "Iter 75  time=0.13  loss=3860.88  active=5169  feature_norm=76.10\n",
      "Iter 76  time=0.11  loss=3860.21  active=5184  feature_norm=76.08\n",
      "Iter 77  time=0.11  loss=3859.94  active=5177  feature_norm=76.15\n",
      "Iter 78  time=0.12  loss=3859.47  active=5178  feature_norm=76.14\n",
      "Iter 79  time=0.18  loss=3859.17  active=5176  feature_norm=76.19\n",
      "Iter 80  time=0.17  loss=3858.88  active=5173  feature_norm=76.19\n",
      "Iter 81  time=0.14  loss=3858.61  active=5165  feature_norm=76.25\n",
      "Iter 82  time=0.11  loss=3858.34  active=5164  feature_norm=76.24\n",
      "Iter 83  time=0.11  loss=3858.11  active=5156  feature_norm=76.29\n",
      "Iter 84  time=0.12  loss=3857.85  active=5157  feature_norm=76.29\n",
      "Iter 85  time=0.10  loss=3857.65  active=5154  feature_norm=76.33\n",
      "Iter 86  time=0.12  loss=3857.49  active=5152  feature_norm=76.33\n",
      "Iter 87  time=0.11  loss=3857.29  active=5149  feature_norm=76.38\n",
      "Iter 88  time=0.12  loss=3857.10  active=5146  feature_norm=76.37\n",
      "Iter 89  time=0.11  loss=3856.93  active=5140  feature_norm=76.40\n",
      "Iter 90  time=0.11  loss=3856.76  active=5141  feature_norm=76.40\n",
      "Iter 91  time=0.12  loss=3856.65  active=5137  feature_norm=76.45\n",
      "Iter 92  time=0.12  loss=3856.45  active=5135  feature_norm=76.44\n",
      "Iter 93  time=0.12  loss=3856.29  active=5132  feature_norm=76.47\n",
      "Iter 94  time=0.11  loss=3856.14  active=5132  feature_norm=76.47\n",
      "Iter 95  time=0.11  loss=3855.99  active=5129  feature_norm=76.50\n",
      "Iter 96  time=0.12  loss=3855.83  active=5129  feature_norm=76.50\n",
      "Iter 97  time=0.12  loss=3855.65  active=5128  feature_norm=76.53\n",
      "Iter 98  time=0.12  loss=3855.46  active=5123  feature_norm=76.52\n",
      "Iter 99  time=0.11  loss=3855.38  active=5120  feature_norm=76.56\n",
      "Iter 100 time=0.13  loss=3855.11  active=5117  feature_norm=76.55\n",
      "Iter 101 time=0.10  loss=3855.00  active=5113  feature_norm=76.58\n",
      "Iter 102 time=0.11  loss=3854.84  active=5113  feature_norm=76.58\n",
      "Iter 103 time=0.11  loss=3854.74  active=5115  feature_norm=76.60\n",
      "Iter 104 time=0.10  loss=3854.60  active=5115  feature_norm=76.60\n",
      "Iter 105 time=0.11  loss=3854.51  active=5112  feature_norm=76.62\n",
      "Iter 106 time=0.11  loss=3854.34  active=5111  feature_norm=76.61\n",
      "Iter 107 time=0.11  loss=3854.28  active=5110  feature_norm=76.64\n",
      "Iter 108 time=0.11  loss=3854.09  active=5111  feature_norm=76.63\n",
      "Iter 109 time=0.11  loss=3854.01  active=5109  feature_norm=76.66\n",
      "Iter 110 time=0.11  loss=3853.86  active=5109  feature_norm=76.65\n",
      "Iter 111 time=0.12  loss=3853.75  active=5111  feature_norm=76.67\n",
      "Iter 112 time=0.12  loss=3853.64  active=5112  feature_norm=76.66\n",
      "Iter 113 time=0.13  loss=3853.54  active=5111  feature_norm=76.68\n",
      "Iter 114 time=0.12  loss=3853.42  active=5112  feature_norm=76.67\n",
      "Iter 115 time=0.11  loss=3853.32  active=5109  feature_norm=76.69\n",
      "Iter 116 time=0.11  loss=3853.18  active=5110  feature_norm=76.67\n",
      "Iter 117 time=0.12  loss=3853.12  active=5108  feature_norm=76.69\n",
      "Iter 118 time=0.12  loss=3852.97  active=5110  feature_norm=76.68\n",
      "Iter 119 time=0.11  loss=3852.91  active=5108  feature_norm=76.69\n",
      "Iter 120 time=0.11  loss=3852.79  active=5106  feature_norm=76.67\n",
      "Iter 121 time=0.10  loss=3852.71  active=5105  feature_norm=76.69\n",
      "Iter 122 time=0.12  loss=3852.61  active=5105  feature_norm=76.67\n",
      "Iter 123 time=0.11  loss=3852.53  active=5101  feature_norm=76.69\n",
      "Iter 124 time=0.13  loss=3852.45  active=5094  feature_norm=76.67\n",
      "Iter 125 time=0.11  loss=3852.36  active=5091  feature_norm=76.68\n",
      "Iter 126 time=0.11  loss=3852.29  active=5092  feature_norm=76.67\n",
      "Iter 127 time=0.12  loss=3852.20  active=5091  feature_norm=76.68\n",
      "Iter 128 time=0.11  loss=3852.15  active=5091  feature_norm=76.67\n",
      "Iter 129 time=0.11  loss=3852.05  active=5086  feature_norm=76.68\n",
      "Iter 130 time=0.11  loss=3852.01  active=5086  feature_norm=76.67\n",
      "Iter 131 time=0.12  loss=3851.90  active=5085  feature_norm=76.68\n",
      "Iter 132 time=0.12  loss=3851.86  active=5086  feature_norm=76.67\n",
      "Iter 133 time=0.12  loss=3851.75  active=5086  feature_norm=76.68\n",
      "Iter 134 time=0.11  loss=3851.72  active=5087  feature_norm=76.67\n",
      "Iter 135 time=0.12  loss=3851.60  active=5088  feature_norm=76.68\n",
      "Iter 136 time=0.12  loss=3851.54  active=5089  feature_norm=76.66\n",
      "Iter 137 time=0.11  loss=3851.45  active=5090  feature_norm=76.67\n",
      "Iter 138 time=0.12  loss=3851.41  active=5089  feature_norm=76.66\n",
      "Iter 139 time=0.11  loss=3851.29  active=5087  feature_norm=76.67\n",
      "Iter 140 time=0.23  loss=3851.22  active=5088  feature_norm=76.66\n",
      "Iter 141 time=0.13  loss=3851.12  active=5087  feature_norm=76.66\n",
      "Iter 142 time=0.24  loss=3851.04  active=5086  feature_norm=76.64\n",
      "Iter 143 time=0.21  loss=3850.96  active=5083  feature_norm=76.64\n",
      "Iter 144 time=0.22  loss=3850.91  active=5084  feature_norm=76.63\n",
      "Iter 145 time=0.22  loss=3850.81  active=5085  feature_norm=76.64\n",
      "Iter 146 time=0.21  loss=3850.75  active=5086  feature_norm=76.62\n",
      "Iter 147 time=0.23  loss=3850.68  active=5084  feature_norm=76.63\n",
      "Iter 148 time=0.23  loss=3850.61  active=5086  feature_norm=76.61\n",
      "Iter 149 time=0.23  loss=3850.56  active=5084  feature_norm=76.62\n",
      "Iter 150 time=0.25  loss=3850.50  active=5080  feature_norm=76.60\n",
      "Iter 151 time=0.25  loss=3850.43  active=5079  feature_norm=76.60\n",
      "Iter 152 time=0.22  loss=3850.37  active=5076  feature_norm=76.59\n",
      "Iter 153 time=0.22  loss=3850.29  active=5076  feature_norm=76.59\n",
      "Iter 154 time=0.23  loss=3850.23  active=5078  feature_norm=76.57\n",
      "Iter 155 time=0.22  loss=3850.18  active=5078  feature_norm=76.58\n",
      "Iter 156 time=0.23  loss=3850.13  active=5080  feature_norm=76.56\n",
      "Iter 157 time=0.22  loss=3850.07  active=5081  feature_norm=76.57\n",
      "Iter 158 time=0.23  loss=3850.02  active=5083  feature_norm=76.56\n",
      "Iter 159 time=0.25  loss=3849.97  active=5084  feature_norm=76.56\n",
      "Iter 160 time=0.15  loss=3849.95  active=5082  feature_norm=76.53\n",
      "Iter 161 time=0.13  loss=3849.85  active=5081  feature_norm=76.54\n",
      "Iter 162 time=0.13  loss=3849.82  active=5084  feature_norm=76.52\n",
      "Iter 163 time=0.12  loss=3849.74  active=5081  feature_norm=76.52\n",
      "Iter 164 time=0.14  loss=3849.70  active=5085  feature_norm=76.51\n",
      "Iter 165 time=0.12  loss=3849.65  active=5083  feature_norm=76.51\n",
      "Iter 166 time=0.11  loss=3849.64  active=5080  feature_norm=76.49\n",
      "Iter 167 time=0.10  loss=3849.56  active=5079  feature_norm=76.50\n",
      "Iter 168 time=0.10  loss=3849.54  active=5080  feature_norm=76.48\n",
      "Iter 169 time=0.12  loss=3849.48  active=5080  feature_norm=76.49\n",
      "Iter 170 time=0.11  loss=3849.46  active=5083  feature_norm=76.47\n",
      "Iter 171 time=0.11  loss=3849.38  active=5080  feature_norm=76.48\n",
      "Iter 172 time=0.11  loss=3849.36  active=5079  feature_norm=76.47\n",
      "Iter 173 time=0.12  loss=3849.31  active=5078  feature_norm=76.47\n",
      "Iter 174 time=0.11  loss=3849.30  active=5079  feature_norm=76.45\n",
      "Iter 175 time=0.11  loss=3849.23  active=5080  feature_norm=76.46\n",
      "Iter 176 time=0.12  loss=3849.21  active=5077  feature_norm=76.45\n",
      "Iter 177 time=0.12  loss=3849.14  active=5076  feature_norm=76.45\n",
      "Iter 178 time=0.11  loss=3849.14  active=5074  feature_norm=76.44\n",
      "Iter 179 time=0.10  loss=3849.06  active=5073  feature_norm=76.44\n",
      "Iter 180 time=0.11  loss=3849.05  active=5073  feature_norm=76.43\n",
      "Iter 181 time=0.11  loss=3848.98  active=5071  feature_norm=76.44\n",
      "Iter 182 time=0.11  loss=3848.97  active=5069  feature_norm=76.42\n",
      "Iter 183 time=0.11  loss=3848.91  active=5070  feature_norm=76.43\n",
      "Iter 184 time=0.11  loss=3848.90  active=5071  feature_norm=76.42\n",
      "Iter 185 time=0.11  loss=3848.84  active=5071  feature_norm=76.42\n",
      "Iter 186 time=0.20  loss=3848.81  active=5073  feature_norm=76.42\n",
      "Iter 187 time=0.10  loss=3848.79  active=5073  feature_norm=76.42\n",
      "Iter 188 time=0.21  loss=3848.73  active=5074  feature_norm=76.41\n",
      "Iter 189 time=0.11  loss=3848.69  active=5074  feature_norm=76.41\n",
      "Iter 190 time=0.23  loss=3848.65  active=5075  feature_norm=76.40\n",
      "Iter 191 time=0.20  loss=3848.62  active=5075  feature_norm=76.40\n",
      "Iter 192 time=0.21  loss=3848.58  active=5077  feature_norm=76.39\n",
      "Iter 193 time=0.23  loss=3848.55  active=5076  feature_norm=76.39\n",
      "Iter 194 time=0.22  loss=3848.51  active=5079  feature_norm=76.38\n",
      "Iter 195 time=0.22  loss=3848.47  active=5079  feature_norm=76.38\n",
      "Iter 196 time=0.24  loss=3848.45  active=5079  feature_norm=76.38\n",
      "Iter 197 time=0.21  loss=3848.41  active=5075  feature_norm=76.38\n",
      "Iter 198 time=0.22  loss=3848.39  active=5078  feature_norm=76.37\n",
      "Iter 199 time=0.22  loss=3848.36  active=5077  feature_norm=76.37\n",
      "Iter 200 time=0.22  loss=3848.33  active=5079  feature_norm=76.36\n",
      "Iter 201 time=0.21  loss=3848.30  active=5079  feature_norm=76.37\n",
      "Iter 202 time=0.23  loss=3848.28  active=5081  feature_norm=76.36\n",
      "Iter 203 time=0.24  loss=3848.24  active=5081  feature_norm=76.36\n",
      "Iter 204 time=0.22  loss=3848.22  active=5080  feature_norm=76.35\n",
      "Iter 205 time=0.20  loss=3848.19  active=5080  feature_norm=76.36\n",
      "Iter 206 time=0.20  loss=3848.17  active=5080  feature_norm=76.35\n",
      "Iter 207 time=0.21  loss=3848.14  active=5083  feature_norm=76.35\n",
      "Iter 208 time=0.21  loss=3848.12  active=5085  feature_norm=76.34\n",
      "Iter 209 time=0.21  loss=3848.09  active=5082  feature_norm=76.35\n",
      "Iter 210 time=0.22  loss=3848.07  active=5083  feature_norm=76.34\n",
      "Iter 211 time=0.24  loss=3848.03  active=5080  feature_norm=76.34\n",
      "Iter 212 time=0.20  loss=3848.01  active=5083  feature_norm=76.34\n",
      "Iter 213 time=0.22  loss=3847.98  active=5083  feature_norm=76.34\n",
      "Iter 214 time=0.22  loss=3847.97  active=5082  feature_norm=76.33\n",
      "Iter 215 time=0.22  loss=3847.93  active=5081  feature_norm=76.34\n",
      "Iter 216 time=0.22  loss=3847.92  active=5081  feature_norm=76.33\n",
      "Iter 217 time=0.21  loss=3847.89  active=5080  feature_norm=76.33\n",
      "Iter 218 time=0.21  loss=3847.87  active=5079  feature_norm=76.32\n",
      "Iter 219 time=0.22  loss=3847.84  active=5078  feature_norm=76.33\n",
      "Iter 220 time=0.21  loss=3847.83  active=5080  feature_norm=76.32\n",
      "Iter 221 time=0.21  loss=3847.80  active=5079  feature_norm=76.33\n",
      "Iter 222 time=0.23  loss=3847.79  active=5079  feature_norm=76.32\n",
      "Iter 223 time=0.15  loss=3847.78  active=5077  feature_norm=76.32\n",
      "Iter 224 time=0.12  loss=3847.75  active=5079  feature_norm=76.31\n",
      "Iter 225 time=0.11  loss=3847.70  active=5078  feature_norm=76.32\n",
      "Iter 226 time=0.10  loss=3847.69  active=5083  feature_norm=76.30\n",
      "Iter 227 time=0.10  loss=3847.64  active=5079  feature_norm=76.31\n",
      "Iter 228 time=0.12  loss=3847.64  active=5080  feature_norm=76.30\n",
      "Iter 229 time=0.11  loss=3847.60  active=5080  feature_norm=76.31\n",
      "Iter 230 time=0.11  loss=3847.59  active=5080  feature_norm=76.30\n",
      "Iter 231 time=0.11  loss=3847.57  active=5080  feature_norm=76.31\n",
      "Iter 232 time=0.11  loss=3847.57  active=5079  feature_norm=76.30\n",
      "Iter 233 time=0.11  loss=3847.55  active=5080  feature_norm=76.31\n",
      "Iter 234 time=0.10  loss=3847.53  active=5082  feature_norm=76.30\n",
      "Iter 235 time=0.13  loss=3847.51  active=5081  feature_norm=76.31\n",
      "Iter 236 time=0.14  loss=3847.50  active=5082  feature_norm=76.30\n",
      "Iter 237 time=0.12  loss=3847.48  active=5081  feature_norm=76.30\n",
      "Iter 238 time=0.11  loss=3847.47  active=5080  feature_norm=76.30\n",
      "Iter 239 time=0.12  loss=3847.45  active=5080  feature_norm=76.30\n",
      "Iter 240 time=0.12  loss=3847.44  active=5079  feature_norm=76.30\n",
      "Iter 241 time=0.10  loss=3847.42  active=5077  feature_norm=76.30\n",
      "Iter 242 time=0.11  loss=3847.41  active=5078  feature_norm=76.30\n",
      "Iter 243 time=0.11  loss=3847.39  active=5076  feature_norm=76.30\n",
      "Iter 244 time=0.12  loss=3847.38  active=5077  feature_norm=76.29\n",
      "Iter 245 time=0.11  loss=3847.36  active=5076  feature_norm=76.30\n",
      "Iter 246 time=0.10  loss=3847.35  active=5076  feature_norm=76.29\n",
      "Iter 247 time=0.11  loss=3847.34  active=5076  feature_norm=76.30\n",
      "Iter 248 time=0.11  loss=3847.33  active=5078  feature_norm=76.29\n",
      "Iter 249 time=0.13  loss=3847.31  active=5078  feature_norm=76.29\n",
      "Iter 250 time=0.14  loss=3847.29  active=5078  feature_norm=76.29\n",
      "Iter 251 time=0.12  loss=3847.28  active=5077  feature_norm=76.29\n",
      "Iter 252 time=0.11  loss=3847.26  active=5075  feature_norm=76.29\n",
      "Iter 253 time=0.11  loss=3847.26  active=5076  feature_norm=76.29\n",
      "Iter 254 time=0.12  loss=3847.24  active=5078  feature_norm=76.28\n",
      "Iter 255 time=0.22  loss=3847.22  active=5077  feature_norm=76.28\n",
      "Iter 256 time=0.11  loss=3847.22  active=5076  feature_norm=76.28\n",
      "Iter 257 time=0.11  loss=3847.20  active=5077  feature_norm=76.28\n",
      "Iter 258 time=0.11  loss=3847.18  active=5077  feature_norm=76.28\n",
      "Iter 259 time=0.12  loss=3847.18  active=5077  feature_norm=76.28\n",
      "Iter 260 time=0.12  loss=3847.16  active=5076  feature_norm=76.28\n",
      "Iter 261 time=0.12  loss=3847.14  active=5076  feature_norm=76.28\n",
      "Iter 262 time=0.13  loss=3847.13  active=5072  feature_norm=76.27\n",
      "Iter 263 time=0.12  loss=3847.12  active=5071  feature_norm=76.28\n",
      "Iter 264 time=0.12  loss=3847.10  active=5070  feature_norm=76.27\n",
      "Iter 265 time=0.13  loss=3847.10  active=5070  feature_norm=76.27\n",
      "Iter 266 time=0.12  loss=3847.08  active=5072  feature_norm=76.27\n",
      "Iter 267 time=0.14  loss=3847.08  active=5073  feature_norm=76.27\n",
      "Iter 268 time=0.14  loss=3847.06  active=5074  feature_norm=76.27\n",
      "Iter 269 time=0.13  loss=3847.05  active=5075  feature_norm=76.27\n",
      "Iter 270 time=0.13  loss=3847.04  active=5075  feature_norm=76.26\n",
      "Iter 271 time=0.15  loss=3847.04  active=5075  feature_norm=76.27\n",
      "Iter 272 time=0.14  loss=3847.02  active=5075  feature_norm=76.26\n",
      "Iter 273 time=0.13  loss=3847.02  active=5074  feature_norm=76.26\n",
      "Iter 274 time=0.12  loss=3847.00  active=5074  feature_norm=76.26\n",
      "Iter 275 time=0.11  loss=3846.99  active=5074  feature_norm=76.26\n",
      "Iter 276 time=0.11  loss=3846.98  active=5073  feature_norm=76.26\n",
      "Iter 277 time=0.10  loss=3846.98  active=5072  feature_norm=76.26\n",
      "Iter 278 time=0.12  loss=3846.97  active=5072  feature_norm=76.26\n",
      "Iter 279 time=0.11  loss=3846.96  active=5072  feature_norm=76.26\n",
      "Iter 280 time=0.11  loss=3846.95  active=5073  feature_norm=76.25\n",
      "Iter 281 time=0.10  loss=3846.95  active=5073  feature_norm=76.26\n",
      "Iter 282 time=0.11  loss=3846.93  active=5073  feature_norm=76.25\n",
      "Iter 283 time=0.11  loss=3846.93  active=5073  feature_norm=76.25\n",
      "Iter 284 time=0.10  loss=3846.91  active=5073  feature_norm=76.25\n",
      "Iter 285 time=0.12  loss=3846.91  active=5072  feature_norm=76.25\n",
      "Iter 286 time=0.12  loss=3846.90  active=5072  feature_norm=76.25\n",
      "Iter 287 time=0.12  loss=3846.90  active=5071  feature_norm=76.25\n",
      "Iter 288 time=0.12  loss=3846.88  active=5070  feature_norm=76.25\n",
      "Iter 289 time=0.20  loss=3846.87  active=5069  feature_norm=76.25\n",
      "Iter 290 time=0.12  loss=3846.87  active=5068  feature_norm=76.24\n",
      "Iter 291 time=0.11  loss=3846.87  active=5069  feature_norm=76.25\n",
      "Iter 292 time=0.12  loss=3846.85  active=5067  feature_norm=76.24\n",
      "Iter 293 time=0.11  loss=3846.84  active=5064  feature_norm=76.24\n",
      "Iter 294 time=0.11  loss=3846.82  active=5065  feature_norm=76.24\n",
      "Iter 295 time=0.21  loss=3846.81  active=5065  feature_norm=76.24\n",
      "Iter 296 time=0.12  loss=3846.81  active=5063  feature_norm=76.24\n",
      "Iter 297 time=0.12  loss=3846.80  active=5064  feature_norm=76.24\n",
      "Iter 298 time=0.10  loss=3846.79  active=5064  feature_norm=76.24\n",
      "Iter 299 time=0.12  loss=3846.78  active=5063  feature_norm=76.24\n",
      "Iter 300 time=0.10  loss=3846.76  active=5062  feature_norm=76.23\n",
      "Iter 301 time=0.11  loss=3846.76  active=5061  feature_norm=76.24\n",
      "Iter 302 time=0.12  loss=3846.74  active=5062  feature_norm=76.23\n",
      "Iter 303 time=0.11  loss=3846.74  active=5063  feature_norm=76.24\n",
      "Iter 304 time=0.11  loss=3846.72  active=5063  feature_norm=76.23\n",
      "Iter 305 time=0.12  loss=3846.72  active=5063  feature_norm=76.23\n",
      "Iter 306 time=0.10  loss=3846.71  active=5063  feature_norm=76.23\n",
      "Iter 307 time=0.11  loss=3846.70  active=5063  feature_norm=76.23\n",
      "Iter 308 time=0.11  loss=3846.69  active=5062  feature_norm=76.23\n",
      "Iter 309 time=0.12  loss=3846.68  active=5062  feature_norm=76.23\n",
      "Iter 310 time=0.12  loss=3846.67  active=5061  feature_norm=76.23\n",
      "Iter 311 time=0.12  loss=3846.66  active=5060  feature_norm=76.23\n",
      "Iter 312 time=0.12  loss=3846.65  active=5061  feature_norm=76.23\n",
      "Iter 313 time=0.12  loss=3846.65  active=5060  feature_norm=76.23\n",
      "Iter 314 time=0.11  loss=3846.63  active=5061  feature_norm=76.22\n",
      "Iter 315 time=0.11  loss=3846.63  active=5060  feature_norm=76.23\n",
      "Iter 316 time=0.11  loss=3846.62  active=5058  feature_norm=76.22\n",
      "Iter 317 time=0.11  loss=3846.62  active=5059  feature_norm=76.22\n",
      "Iter 318 time=0.14  loss=3846.61  active=5061  feature_norm=76.22\n",
      "Iter 319 time=0.11  loss=3846.61  active=5060  feature_norm=76.22\n",
      "Iter 320 time=0.11  loss=3846.59  active=5060  feature_norm=76.22\n",
      "Iter 321 time=0.11  loss=3846.59  active=5060  feature_norm=76.22\n",
      "Iter 322 time=0.12  loss=3846.58  active=5060  feature_norm=76.22\n",
      "Iter 323 time=0.21  loss=3846.57  active=5060  feature_norm=76.22\n",
      "Iter 324 time=0.20  loss=3846.57  active=5059  feature_norm=76.22\n",
      "Iter 325 time=0.20  loss=3846.57  active=5058  feature_norm=76.22\n",
      "Iter 326 time=0.23  loss=3846.56  active=5059  feature_norm=76.22\n",
      "Iter 327 time=0.23  loss=3846.56  active=5059  feature_norm=76.22\n",
      "Iter 328 time=0.21  loss=3846.55  active=5059  feature_norm=76.22\n",
      "Iter 329 time=0.23  loss=3846.54  active=5059  feature_norm=76.22\n",
      "Iter 330 time=0.21  loss=3846.54  active=5058  feature_norm=76.22\n",
      "Iter 331 time=0.23  loss=3846.53  active=5058  feature_norm=76.22\n",
      "Iter 332 time=0.22  loss=3846.53  active=5059  feature_norm=76.22\n",
      "Iter 333 time=0.22  loss=3846.52  active=5059  feature_norm=76.22\n",
      "Iter 334 time=0.24  loss=3846.52  active=5060  feature_norm=76.22\n",
      "Iter 335 time=0.23  loss=3846.51  active=5060  feature_norm=76.22\n",
      "Iter 336 time=0.22  loss=3846.51  active=5061  feature_norm=76.22\n",
      "Iter 337 time=0.21  loss=3846.50  active=5061  feature_norm=76.22\n",
      "Iter 338 time=0.22  loss=3846.50  active=5061  feature_norm=76.22\n",
      "Iter 339 time=0.21  loss=3846.49  active=5060  feature_norm=76.22\n",
      "Iter 340 time=0.24  loss=3846.49  active=5061  feature_norm=76.22\n",
      "Iter 341 time=0.26  loss=3846.48  active=5061  feature_norm=76.22\n",
      "Iter 342 time=0.22  loss=3846.48  active=5061  feature_norm=76.22\n",
      "Iter 343 time=0.21  loss=3846.47  active=5061  feature_norm=76.22\n",
      "Iter 344 time=0.23  loss=3846.47  active=5060  feature_norm=76.22\n",
      "Iter 345 time=0.21  loss=3846.46  active=5060  feature_norm=76.22\n",
      "Iter 346 time=0.23  loss=3846.46  active=5060  feature_norm=76.22\n",
      "Iter 347 time=0.20  loss=3846.45  active=5060  feature_norm=76.23\n",
      "Iter 348 time=0.23  loss=3846.45  active=5061  feature_norm=76.22\n",
      "Iter 349 time=0.24  loss=3846.44  active=5063  feature_norm=76.23\n",
      "Iter 350 time=0.25  loss=3846.44  active=5063  feature_norm=76.23\n",
      "Iter 351 time=0.20  loss=3846.43  active=5063  feature_norm=76.23\n",
      "Iter 352 time=0.22  loss=3846.43  active=5062  feature_norm=76.23\n",
      "Iter 353 time=0.20  loss=3846.42  active=5062  feature_norm=76.23\n",
      "Iter 354 time=0.22  loss=3846.42  active=5062  feature_norm=76.23\n",
      "Iter 355 time=0.22  loss=3846.41  active=5059  feature_norm=76.23\n",
      "Iter 356 time=0.25  loss=3846.41  active=5058  feature_norm=76.23\n",
      "Iter 357 time=0.23  loss=3846.40  active=5059  feature_norm=76.23\n",
      "Iter 358 time=0.21  loss=3846.40  active=5058  feature_norm=76.23\n",
      "Iter 359 time=0.22  loss=3846.39  active=5058  feature_norm=76.23\n",
      "Iter 360 time=0.21  loss=3846.39  active=5057  feature_norm=76.23\n",
      "Iter 361 time=0.21  loss=3846.38  active=5057  feature_norm=76.23\n",
      "Iter 362 time=0.22  loss=3846.38  active=5057  feature_norm=76.23\n",
      "Iter 363 time=0.23  loss=3846.38  active=5055  feature_norm=76.23\n",
      "Iter 364 time=0.22  loss=3846.37  active=5055  feature_norm=76.23\n",
      "Iter 365 time=0.21  loss=3846.37  active=5054  feature_norm=76.23\n",
      "Iter 366 time=0.21  loss=3846.36  active=5054  feature_norm=76.23\n",
      "Iter 367 time=0.21  loss=3846.36  active=5053  feature_norm=76.24\n",
      "Iter 368 time=0.21  loss=3846.35  active=5053  feature_norm=76.23\n",
      "Iter 369 time=0.23  loss=3846.35  active=5053  feature_norm=76.24\n",
      "Iter 370 time=0.21  loss=3846.34  active=5052  feature_norm=76.23\n",
      "Iter 371 time=0.22  loss=3846.34  active=5052  feature_norm=76.24\n",
      "Iter 372 time=0.21  loss=3846.33  active=5052  feature_norm=76.23\n",
      "Iter 373 time=0.22  loss=3846.33  active=5051  feature_norm=76.24\n",
      "Iter 374 time=0.21  loss=3846.33  active=5051  feature_norm=76.23\n",
      "Iter 375 time=0.20  loss=3846.32  active=5050  feature_norm=76.24\n",
      "Iter 376 time=0.23  loss=3846.32  active=5050  feature_norm=76.23\n",
      "Iter 377 time=0.22  loss=3846.31  active=5050  feature_norm=76.24\n",
      "Iter 378 time=0.21  loss=3846.31  active=5050  feature_norm=76.23\n",
      "Iter 379 time=0.20  loss=3846.31  active=5048  feature_norm=76.24\n",
      "Iter 380 time=0.22  loss=3846.30  active=5048  feature_norm=76.23\n",
      "Iter 381 time=0.20  loss=3846.29  active=5047  feature_norm=76.24\n",
      "Iter 382 time=0.20  loss=3846.29  active=5048  feature_norm=76.24\n",
      "Iter 383 time=0.22  loss=3846.29  active=5046  feature_norm=76.24\n",
      "Iter 384 time=0.21  loss=3846.28  active=5046  feature_norm=76.24\n",
      "Iter 385 time=0.20  loss=3846.28  active=5046  feature_norm=76.24\n",
      "Iter 386 time=0.21  loss=3846.27  active=5047  feature_norm=76.24\n",
      "Iter 387 time=0.27  loss=3846.27  active=5046  feature_norm=76.24\n",
      "Iter 388 time=0.24  loss=3846.27  active=5046  feature_norm=76.24\n",
      "Iter 389 time=0.11  loss=3846.26  active=5046  feature_norm=76.24\n",
      "Iter 390 time=0.23  loss=3846.26  active=5048  feature_norm=76.24\n",
      "Iter 391 time=0.11  loss=3846.25  active=5048  feature_norm=76.24\n",
      "Iter 392 time=0.22  loss=3846.24  active=5047  feature_norm=76.24\n",
      "Iter 393 time=0.29  loss=3846.24  active=5047  feature_norm=76.24\n",
      "Iter 394 time=0.32  loss=3846.24  active=5047  feature_norm=76.24\n",
      "Iter 395 time=0.32  loss=3846.23  active=5047  feature_norm=76.24\n",
      "Iter 396 time=0.36  loss=3846.23  active=5047  feature_norm=76.24\n",
      "Iter 397 time=0.34  loss=3846.23  active=5047  feature_norm=76.24\n",
      "Iter 398 time=0.22  loss=3846.22  active=5047  feature_norm=76.24\n",
      "Iter 399 time=0.21  loss=3846.22  active=5047  feature_norm=76.24\n",
      "Iter 400 time=0.32  loss=3846.21  active=5047  feature_norm=76.24\n",
      "Iter 401 time=0.36  loss=3846.21  active=5047  feature_norm=76.24\n",
      "Iter 402 time=0.34  loss=3846.21  active=5047  feature_norm=76.24\n",
      "L-BFGS terminated with the stopping criteria\n",
      "Total seconds required for training: 62.099\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 5047 (85907)\n",
      "Number of active attributes: 3272 (83977)\n",
      "Number of active labels: 4 (4)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.063\n",
      "\n",
      "CPU times: user 1min 6s, sys: 1.41 s, total: 1min 7s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', #Градиентный спуск с использованием метода L-BFGS\n",
    "    c1=0.1, #Коэффициент для регуляризации L1\n",
    "    c2=0.1, #Коэффициент для регуляризации L2\n",
    "    max_iterations=1000, #Максимальное количество итераций\n",
    "    all_possible_transitions=True, #Генерация объектов (не встречающихся в обучающих данных)\n",
    "    verbose=True #Включение режима тренировки\n",
    ")\n",
    "\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17e60f5a-e6fc-4283-a350-279584861747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities = sorted(df.entities.unique().tolist())\n",
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07b4a92d-0cdc-4d0f-bdec-beb823e17670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840980299899303"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=all_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75b8c5a7-93f5-4d2d-8e1b-00acfcfccf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9288c77a-96c8-4ceb-954d-4c0d92609444",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1a3afe1-7573-4814-a9d4-f2e8342c120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'мвд',\n",
       " 'word[-3:]': 'МВД',\n",
       " 'word[-2:]': 'ВД',\n",
       " 'word.isdigit()': False}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c82761c-3088-4e23-8c17-9d8a832e6640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "44040bdb-2bbc-4cb9-aaed-b68147f639a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:700]\n",
    "X_test = X[700:]\n",
    "y_train = y[:700]\n",
    "y_test = y[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e02562aa-50f6-46b6-893d-4e0ba291b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 700/700 [00:02<00:00, 334.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 32191\n",
      "Seconds required: 0.461\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 1000\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.15  loss=65495.05 active=32188 feature_norm=1.00\n",
      "Iter 2   time=0.08  loss=11793.74 active=32135 feature_norm=2.11\n",
      "Iter 3   time=0.08  loss=11438.25 active=32123 feature_norm=2.17\n",
      "Iter 4   time=0.08  loss=10757.28 active=16357 feature_norm=2.38\n",
      "Iter 5   time=0.08  loss=10582.87 active=11707 feature_norm=2.48\n",
      "Iter 6   time=0.09  loss=10368.85 active=7816  feature_norm=2.61\n",
      "Iter 7   time=0.09  loss=9832.85  active=6076  feature_norm=2.80\n",
      "Iter 8   time=0.19  loss=8895.44  active=5101  feature_norm=3.83\n",
      "Iter 9   time=0.13  loss=8488.73  active=4865  feature_norm=4.12\n",
      "Iter 10  time=0.09  loss=8135.02  active=4547  feature_norm=5.27\n",
      "Iter 11  time=0.09  loss=7914.84  active=4388  feature_norm=5.37\n",
      "Iter 12  time=0.07  loss=7698.45  active=3922  feature_norm=6.07\n",
      "Iter 13  time=0.09  loss=7575.49  active=3862  feature_norm=6.29\n",
      "Iter 14  time=0.10  loss=7280.96  active=3709  feature_norm=7.50\n",
      "Iter 15  time=0.12  loss=7187.88  active=3595  feature_norm=9.17\n",
      "Iter 16  time=0.12  loss=6993.55  active=3600  feature_norm=9.79\n",
      "Iter 17  time=0.09  loss=6924.39  active=3598  feature_norm=9.96\n",
      "Iter 18  time=0.10  loss=6852.87  active=3606  feature_norm=10.32\n",
      "Iter 19  time=0.09  loss=6681.41  active=3531  feature_norm=12.26\n",
      "Iter 20  time=0.10  loss=6573.00  active=3393  feature_norm=12.92\n",
      "Iter 21  time=0.09  loss=6436.03  active=3254  feature_norm=13.76\n",
      "Iter 22  time=0.09  loss=6369.27  active=2849  feature_norm=16.13\n",
      "Iter 23  time=0.09  loss=6270.85  active=2909  feature_norm=15.96\n",
      "Iter 24  time=0.10  loss=6239.45  active=2872  feature_norm=16.23\n",
      "Iter 25  time=0.09  loss=6159.68  active=2814  feature_norm=17.69\n",
      "Iter 26  time=0.09  loss=6143.86  active=2756  feature_norm=18.76\n",
      "Iter 27  time=0.08  loss=6071.67  active=2762  feature_norm=18.78\n",
      "Iter 28  time=0.08  loss=6034.02  active=2746  feature_norm=19.32\n",
      "Iter 29  time=0.09  loss=5971.48  active=2697  feature_norm=21.26\n",
      "Iter 30  time=0.08  loss=5934.07  active=2673  feature_norm=21.43\n",
      "Iter 31  time=0.08  loss=5905.07  active=2597  feature_norm=21.90\n",
      "Iter 32  time=0.08  loss=5853.80  active=2375  feature_norm=23.29\n",
      "Iter 33  time=0.08  loss=5822.78  active=2370  feature_norm=23.67\n",
      "Iter 34  time=0.08  loss=5769.00  active=2310  feature_norm=25.17\n",
      "Iter 35  time=0.08  loss=5736.06  active=2271  feature_norm=26.16\n",
      "Iter 36  time=0.11  loss=5705.82  active=2152  feature_norm=26.82\n",
      "Iter 37  time=0.53  loss=5695.12  active=2066  feature_norm=28.42\n",
      "Iter 38  time=0.09  loss=5653.49  active=1987  feature_norm=29.15\n",
      "Iter 39  time=0.10  loss=5636.62  active=1975  feature_norm=29.66\n",
      "Iter 40  time=0.10  loss=5599.98  active=1862  feature_norm=31.68\n",
      "Iter 41  time=0.09  loss=5597.92  active=1848  feature_norm=32.94\n",
      "Iter 42  time=0.08  loss=5576.03  active=1852  feature_norm=33.06\n",
      "Iter 43  time=0.09  loss=5568.23  active=1847  feature_norm=33.25\n",
      "Iter 44  time=0.11  loss=5559.70  active=1832  feature_norm=33.71\n",
      "Iter 45  time=0.10  loss=5556.17  active=1812  feature_norm=34.66\n",
      "Iter 46  time=0.07  loss=5547.71  active=1812  feature_norm=34.58\n",
      "Iter 47  time=0.08  loss=5546.38  active=1805  feature_norm=34.63\n",
      "Iter 48  time=0.09  loss=5542.60  active=1741  feature_norm=34.87\n",
      "Iter 49  time=0.09  loss=5537.45  active=1727  feature_norm=35.20\n",
      "Iter 50  time=0.08  loss=5534.57  active=1720  feature_norm=35.37\n",
      "Iter 51  time=0.09  loss=5532.40  active=1715  feature_norm=35.43\n",
      "Iter 52  time=0.09  loss=5527.18  active=1684  feature_norm=35.59\n",
      "Iter 53  time=0.08  loss=5526.75  active=1585  feature_norm=35.81\n",
      "Iter 54  time=0.08  loss=5520.36  active=1567  feature_norm=35.90\n",
      "Iter 55  time=0.08  loss=5518.90  active=1545  feature_norm=35.96\n",
      "Iter 56  time=0.08  loss=5516.59  active=1516  feature_norm=36.05\n",
      "Iter 57  time=0.08  loss=5515.17  active=1468  feature_norm=36.14\n",
      "Iter 58  time=0.08  loss=5513.04  active=1363  feature_norm=36.23\n",
      "Iter 59  time=0.08  loss=5511.45  active=1348  feature_norm=36.31\n",
      "Iter 60  time=0.09  loss=5510.32  active=1333  feature_norm=36.42\n",
      "Iter 61  time=0.09  loss=5508.79  active=1306  feature_norm=36.49\n",
      "Iter 62  time=0.08  loss=5507.46  active=1277  feature_norm=36.60\n",
      "Iter 63  time=0.09  loss=5506.33  active=1224  feature_norm=36.65\n",
      "Iter 64  time=0.08  loss=5505.77  active=1217  feature_norm=36.80\n",
      "Iter 65  time=0.09  loss=5504.47  active=1216  feature_norm=36.84\n",
      "Iter 66  time=0.09  loss=5503.65  active=1215  feature_norm=36.97\n",
      "Iter 67  time=0.08  loss=5502.65  active=1210  feature_norm=37.00\n",
      "Iter 68  time=0.08  loss=5502.09  active=1206  feature_norm=37.09\n",
      "Iter 69  time=0.08  loss=5501.30  active=1188  feature_norm=37.11\n",
      "Iter 70  time=0.09  loss=5500.68  active=1183  feature_norm=37.19\n",
      "Iter 71  time=0.08  loss=5500.30  active=1183  feature_norm=37.22\n",
      "Iter 72  time=0.08  loss=5499.42  active=1181  feature_norm=37.30\n",
      "Iter 73  time=0.09  loss=5499.21  active=1181  feature_norm=37.33\n",
      "Iter 74  time=0.08  loss=5498.23  active=1179  feature_norm=37.40\n",
      "Iter 75  time=0.10  loss=5498.13  active=1176  feature_norm=37.43\n",
      "Iter 76  time=0.09  loss=5497.13  active=1176  feature_norm=37.51\n",
      "Iter 77  time=0.09  loss=5496.96  active=1175  feature_norm=37.54\n",
      "Iter 78  time=0.08  loss=5496.11  active=1171  feature_norm=37.62\n",
      "Iter 79  time=0.07  loss=5496.01  active=1169  feature_norm=37.64\n",
      "Iter 80  time=0.08  loss=5495.03  active=1166  feature_norm=37.72\n",
      "Iter 81  time=0.08  loss=5494.99  active=1163  feature_norm=37.74\n",
      "Iter 82  time=0.08  loss=5493.98  active=1159  feature_norm=37.82\n",
      "Iter 83  time=0.09  loss=5493.97  active=1158  feature_norm=37.84\n",
      "Iter 84  time=0.08  loss=5492.92  active=1155  feature_norm=37.91\n",
      "Iter 85  time=0.15  loss=5492.56  active=1156  feature_norm=37.92\n",
      "Iter 86  time=0.17  loss=5492.28  active=1157  feature_norm=37.95\n",
      "Iter 87  time=0.15  loss=5491.95  active=1154  feature_norm=37.97\n",
      "Iter 88  time=0.16  loss=5491.50  active=1154  feature_norm=38.01\n",
      "Iter 89  time=0.17  loss=5491.17  active=1155  feature_norm=38.03\n",
      "Iter 90  time=0.16  loss=5490.68  active=1154  feature_norm=38.08\n",
      "Iter 91  time=0.16  loss=5490.27  active=1147  feature_norm=38.10\n",
      "Iter 92  time=0.15  loss=5489.83  active=1146  feature_norm=38.14\n",
      "Iter 93  time=0.17  loss=5489.39  active=1142  feature_norm=38.17\n",
      "Iter 94  time=0.17  loss=5488.85  active=1142  feature_norm=38.21\n",
      "Iter 95  time=0.16  loss=5488.41  active=1138  feature_norm=38.24\n",
      "Iter 96  time=0.15  loss=5487.98  active=1138  feature_norm=38.28\n",
      "Iter 97  time=0.17  loss=5487.63  active=1132  feature_norm=38.29\n",
      "Iter 98  time=0.17  loss=5487.24  active=1131  feature_norm=38.33\n",
      "Iter 99  time=0.08  loss=5487.15  active=1125  feature_norm=38.37\n",
      "Iter 100 time=0.08  loss=5486.42  active=1125  feature_norm=38.46\n",
      "Iter 101 time=0.10  loss=5486.08  active=1124  feature_norm=38.47\n",
      "Iter 102 time=0.10  loss=5485.67  active=1124  feature_norm=38.51\n",
      "Iter 103 time=0.09  loss=5485.67  active=1123  feature_norm=38.54\n",
      "Iter 104 time=0.08  loss=5485.21  active=1121  feature_norm=38.62\n",
      "Iter 105 time=0.08  loss=5484.98  active=1119  feature_norm=38.63\n",
      "Iter 106 time=0.09  loss=5484.64  active=1121  feature_norm=38.69\n",
      "Iter 107 time=0.09  loss=5484.39  active=1122  feature_norm=38.70\n",
      "Iter 108 time=0.09  loss=5484.21  active=1122  feature_norm=38.75\n",
      "Iter 109 time=0.09  loss=5484.08  active=1120  feature_norm=38.75\n",
      "Iter 110 time=0.10  loss=5483.75  active=1120  feature_norm=38.79\n",
      "Iter 111 time=0.09  loss=5483.69  active=1122  feature_norm=38.79\n",
      "Iter 112 time=0.09  loss=5483.35  active=1119  feature_norm=38.83\n",
      "Iter 113 time=0.12  loss=5483.24  active=1118  feature_norm=38.82\n",
      "Iter 114 time=0.10  loss=5483.02  active=1117  feature_norm=38.86\n",
      "Iter 115 time=0.11  loss=5482.99  active=1116  feature_norm=38.85\n",
      "Iter 116 time=0.10  loss=5482.71  active=1116  feature_norm=38.88\n",
      "Iter 117 time=0.10  loss=5482.69  active=1118  feature_norm=38.88\n",
      "Iter 118 time=0.08  loss=5482.43  active=1118  feature_norm=38.90\n",
      "Iter 119 time=0.16  loss=5482.33  active=1118  feature_norm=38.90\n",
      "Iter 120 time=0.09  loss=5482.21  active=1116  feature_norm=38.91\n",
      "Iter 121 time=0.08  loss=5482.15  active=1115  feature_norm=38.91\n",
      "Iter 122 time=0.09  loss=5481.94  active=1115  feature_norm=38.94\n",
      "Iter 123 time=0.10  loss=5481.63  active=1113  feature_norm=38.92\n",
      "Iter 124 time=0.09  loss=5481.56  active=1110  feature_norm=38.95\n",
      "Iter 125 time=0.08  loss=5481.29  active=1108  feature_norm=38.94\n",
      "Iter 126 time=0.09  loss=5481.14  active=1108  feature_norm=38.96\n",
      "Iter 127 time=0.09  loss=5480.93  active=1108  feature_norm=38.95\n",
      "Iter 128 time=0.10  loss=5480.79  active=1108  feature_norm=38.97\n",
      "Iter 129 time=0.09  loss=5480.67  active=1108  feature_norm=38.96\n",
      "Iter 130 time=0.09  loss=5480.43  active=1108  feature_norm=38.99\n",
      "Iter 131 time=0.09  loss=5480.40  active=1106  feature_norm=38.98\n",
      "Iter 132 time=0.08  loss=5480.08  active=1104  feature_norm=39.00\n",
      "Iter 133 time=0.15  loss=5479.89  active=1105  feature_norm=39.00\n",
      "Iter 134 time=0.09  loss=5479.85  active=1105  feature_norm=39.00\n",
      "Iter 135 time=0.08  loss=5479.72  active=1100  feature_norm=38.99\n",
      "Iter 136 time=0.08  loss=5479.39  active=1100  feature_norm=39.01\n",
      "Iter 137 time=0.08  loss=5479.38  active=1099  feature_norm=39.00\n",
      "Iter 138 time=0.09  loss=5479.08  active=1097  feature_norm=39.02\n",
      "Iter 139 time=0.08  loss=5478.98  active=1093  feature_norm=39.01\n",
      "Iter 140 time=0.08  loss=5478.85  active=1092  feature_norm=39.02\n",
      "Iter 141 time=0.08  loss=5478.76  active=1093  feature_norm=39.01\n",
      "Iter 142 time=0.08  loss=5478.55  active=1091  feature_norm=39.03\n",
      "Iter 143 time=0.08  loss=5478.50  active=1091  feature_norm=39.01\n",
      "Iter 144 time=0.08  loss=5478.22  active=1090  feature_norm=39.03\n",
      "Iter 145 time=0.17  loss=5478.09  active=1089  feature_norm=39.02\n",
      "Iter 146 time=0.08  loss=5478.08  active=1089  feature_norm=39.03\n",
      "Iter 147 time=0.08  loss=5477.95  active=1088  feature_norm=39.01\n",
      "Iter 148 time=0.09  loss=5477.83  active=1086  feature_norm=39.03\n",
      "Iter 149 time=0.08  loss=5477.70  active=1085  feature_norm=39.01\n",
      "Iter 150 time=0.09  loss=5477.50  active=1084  feature_norm=39.03\n",
      "Iter 151 time=0.09  loss=5477.44  active=1086  feature_norm=39.01\n",
      "Iter 152 time=0.08  loss=5477.25  active=1085  feature_norm=39.02\n",
      "Iter 153 time=0.08  loss=5477.21  active=1085  feature_norm=39.01\n",
      "Iter 154 time=0.08  loss=5477.04  active=1085  feature_norm=39.02\n",
      "Iter 155 time=0.08  loss=5477.02  active=1085  feature_norm=39.00\n",
      "Iter 156 time=0.07  loss=5476.84  active=1085  feature_norm=39.02\n",
      "Iter 157 time=0.09  loss=5476.82  active=1086  feature_norm=39.00\n",
      "Iter 158 time=0.10  loss=5476.64  active=1086  feature_norm=39.01\n",
      "Iter 159 time=0.16  loss=5476.53  active=1087  feature_norm=39.01\n",
      "Iter 160 time=0.16  loss=5476.47  active=1087  feature_norm=39.01\n",
      "Iter 161 time=0.17  loss=5476.42  active=1086  feature_norm=39.00\n",
      "Iter 162 time=0.17  loss=5476.32  active=1086  feature_norm=39.00\n",
      "Iter 163 time=0.17  loss=5476.28  active=1086  feature_norm=38.99\n",
      "Iter 164 time=0.17  loss=5476.17  active=1086  feature_norm=38.99\n",
      "Iter 165 time=0.16  loss=5476.08  active=1087  feature_norm=38.98\n",
      "Iter 166 time=0.17  loss=5475.99  active=1087  feature_norm=38.98\n",
      "Iter 167 time=0.16  loss=5475.95  active=1087  feature_norm=38.97\n",
      "Iter 168 time=0.15  loss=5475.81  active=1087  feature_norm=38.97\n",
      "Iter 169 time=0.17  loss=5475.76  active=1090  feature_norm=38.95\n",
      "Iter 170 time=0.17  loss=5475.63  active=1090  feature_norm=38.96\n",
      "Iter 171 time=0.17  loss=5475.55  active=1089  feature_norm=38.94\n",
      "Iter 172 time=0.17  loss=5475.42  active=1087  feature_norm=38.95\n",
      "Iter 173 time=0.18  loss=5475.32  active=1088  feature_norm=38.93\n",
      "Iter 174 time=0.17  loss=5475.22  active=1088  feature_norm=38.93\n",
      "Iter 175 time=0.17  loss=5475.16  active=1087  feature_norm=38.91\n",
      "Iter 176 time=0.18  loss=5475.01  active=1089  feature_norm=38.92\n",
      "Iter 177 time=0.17  loss=5474.94  active=1089  feature_norm=38.90\n",
      "Iter 178 time=0.17  loss=5474.82  active=1089  feature_norm=38.91\n",
      "Iter 179 time=0.17  loss=5474.76  active=1091  feature_norm=38.89\n",
      "Iter 180 time=0.18  loss=5474.67  active=1091  feature_norm=38.90\n",
      "Iter 181 time=0.17  loss=5474.61  active=1092  feature_norm=38.88\n",
      "Iter 182 time=0.17  loss=5474.51  active=1090  feature_norm=38.88\n",
      "Iter 183 time=0.17  loss=5474.44  active=1089  feature_norm=38.86\n",
      "Iter 184 time=0.17  loss=5474.34  active=1090  feature_norm=38.87\n",
      "Iter 185 time=0.19  loss=5474.30  active=1092  feature_norm=38.85\n",
      "Iter 186 time=0.18  loss=5474.18  active=1092  feature_norm=38.85\n",
      "Iter 187 time=0.17  loss=5474.10  active=1091  feature_norm=38.83\n",
      "Iter 188 time=0.19  loss=5474.01  active=1091  feature_norm=38.82\n",
      "Iter 189 time=0.17  loss=5473.98  active=1092  feature_norm=38.80\n",
      "Iter 190 time=0.17  loss=5473.87  active=1091  feature_norm=38.80\n",
      "Iter 191 time=0.17  loss=5473.83  active=1091  feature_norm=38.78\n",
      "Iter 192 time=0.17  loss=5473.74  active=1091  feature_norm=38.79\n",
      "Iter 193 time=0.18  loss=5473.70  active=1091  feature_norm=38.77\n",
      "Iter 194 time=0.17  loss=5473.62  active=1091  feature_norm=38.78\n",
      "Iter 195 time=0.19  loss=5473.57  active=1090  feature_norm=38.76\n",
      "Iter 196 time=0.18  loss=5473.50  active=1089  feature_norm=38.76\n",
      "Iter 197 time=0.18  loss=5473.46  active=1088  feature_norm=38.74\n",
      "Iter 198 time=0.17  loss=5473.38  active=1088  feature_norm=38.75\n",
      "Iter 199 time=0.17  loss=5473.33  active=1089  feature_norm=38.73\n",
      "Iter 200 time=0.17  loss=5473.27  active=1087  feature_norm=38.73\n",
      "Iter 201 time=0.15  loss=5473.22  active=1087  feature_norm=38.72\n",
      "Iter 202 time=0.17  loss=5473.17  active=1087  feature_norm=38.72\n",
      "Iter 203 time=0.15  loss=5473.12  active=1087  feature_norm=38.70\n",
      "Iter 204 time=0.18  loss=5473.07  active=1087  feature_norm=38.71\n",
      "Iter 205 time=0.17  loss=5473.02  active=1087  feature_norm=38.69\n",
      "Iter 206 time=0.16  loss=5472.97  active=1086  feature_norm=38.70\n",
      "Iter 207 time=0.17  loss=5472.92  active=1088  feature_norm=38.68\n",
      "Iter 208 time=0.17  loss=5472.87  active=1088  feature_norm=38.69\n",
      "Iter 209 time=0.16  loss=5472.82  active=1090  feature_norm=38.68\n",
      "Iter 210 time=0.16  loss=5472.77  active=1090  feature_norm=38.68\n",
      "Iter 211 time=0.17  loss=5472.72  active=1089  feature_norm=38.67\n",
      "Iter 212 time=0.16  loss=5472.66  active=1090  feature_norm=38.67\n",
      "Iter 213 time=0.15  loss=5472.62  active=1092  feature_norm=38.66\n",
      "Iter 214 time=0.17  loss=5472.57  active=1092  feature_norm=38.66\n",
      "Iter 215 time=0.18  loss=5472.53  active=1092  feature_norm=38.65\n",
      "Iter 216 time=0.16  loss=5472.47  active=1091  feature_norm=38.65\n",
      "Iter 217 time=0.17  loss=5472.43  active=1090  feature_norm=38.63\n",
      "Iter 218 time=0.17  loss=5472.37  active=1090  feature_norm=38.64\n",
      "Iter 219 time=0.17  loss=5472.33  active=1089  feature_norm=38.62\n",
      "Iter 220 time=0.19  loss=5472.27  active=1089  feature_norm=38.62\n",
      "Iter 221 time=0.16  loss=5472.24  active=1090  feature_norm=38.60\n",
      "Iter 222 time=0.18  loss=5472.18  active=1090  feature_norm=38.60\n",
      "Iter 223 time=0.17  loss=5472.15  active=1090  feature_norm=38.59\n",
      "Iter 224 time=0.18  loss=5472.09  active=1089  feature_norm=38.59\n",
      "Iter 225 time=0.17  loss=5472.06  active=1090  feature_norm=38.57\n",
      "Iter 226 time=0.18  loss=5472.00  active=1091  feature_norm=38.58\n",
      "Iter 227 time=0.16  loss=5471.97  active=1090  feature_norm=38.56\n",
      "Iter 228 time=0.17  loss=5471.91  active=1090  feature_norm=38.56\n",
      "Iter 229 time=0.18  loss=5471.89  active=1089  feature_norm=38.54\n",
      "Iter 230 time=0.16  loss=5471.83  active=1089  feature_norm=38.54\n",
      "Iter 231 time=0.16  loss=5471.81  active=1090  feature_norm=38.53\n",
      "Iter 232 time=0.18  loss=5471.75  active=1090  feature_norm=38.53\n",
      "Iter 233 time=0.18  loss=5471.73  active=1090  feature_norm=38.52\n",
      "Iter 234 time=0.16  loss=5471.68  active=1090  feature_norm=38.52\n",
      "Iter 235 time=0.15  loss=5471.66  active=1090  feature_norm=38.51\n",
      "Iter 236 time=0.17  loss=5471.61  active=1090  feature_norm=38.52\n",
      "Iter 237 time=0.16  loss=5471.59  active=1089  feature_norm=38.50\n",
      "Iter 238 time=0.16  loss=5471.54  active=1088  feature_norm=38.52\n",
      "Iter 239 time=0.15  loss=5471.51  active=1085  feature_norm=38.50\n",
      "Iter 240 time=0.17  loss=5471.46  active=1085  feature_norm=38.51\n",
      "Iter 241 time=0.16  loss=5471.43  active=1084  feature_norm=38.49\n",
      "Iter 242 time=0.17  loss=5471.39  active=1084  feature_norm=38.50\n",
      "Iter 243 time=0.17  loss=5471.36  active=1084  feature_norm=38.49\n",
      "Iter 244 time=0.15  loss=5471.32  active=1084  feature_norm=38.50\n",
      "Iter 245 time=0.16  loss=5471.29  active=1085  feature_norm=38.48\n",
      "Iter 246 time=0.17  loss=5471.26  active=1085  feature_norm=38.49\n",
      "Iter 247 time=0.16  loss=5471.23  active=1087  feature_norm=38.48\n",
      "Iter 248 time=0.17  loss=5471.20  active=1087  feature_norm=38.48\n",
      "Iter 249 time=0.14  loss=5471.18  active=1088  feature_norm=38.47\n",
      "Iter 250 time=0.16  loss=5471.15  active=1089  feature_norm=38.48\n",
      "Iter 251 time=0.15  loss=5471.12  active=1090  feature_norm=38.47\n",
      "Iter 252 time=0.15  loss=5471.10  active=1089  feature_norm=38.48\n",
      "Iter 253 time=0.15  loss=5471.07  active=1089  feature_norm=38.47\n",
      "Iter 254 time=0.16  loss=5471.05  active=1089  feature_norm=38.48\n",
      "Iter 255 time=0.18  loss=5471.02  active=1089  feature_norm=38.47\n",
      "Iter 256 time=0.17  loss=5471.00  active=1089  feature_norm=38.48\n",
      "Iter 257 time=0.19  loss=5470.97  active=1088  feature_norm=38.46\n",
      "Iter 258 time=0.18  loss=5470.95  active=1089  feature_norm=38.47\n",
      "Iter 259 time=0.15  loss=5470.92  active=1088  feature_norm=38.46\n",
      "Iter 260 time=0.17  loss=5470.91  active=1087  feature_norm=38.47\n",
      "Iter 261 time=0.16  loss=5470.88  active=1088  feature_norm=38.46\n",
      "Iter 262 time=0.18  loss=5470.86  active=1088  feature_norm=38.47\n",
      "Iter 263 time=0.25  loss=5470.84  active=1092  feature_norm=38.46\n",
      "Iter 264 time=0.23  loss=5470.82  active=1092  feature_norm=38.47\n",
      "Iter 265 time=0.21  loss=5470.80  active=1092  feature_norm=38.46\n",
      "Iter 266 time=0.17  loss=5470.78  active=1090  feature_norm=38.47\n",
      "Iter 267 time=0.22  loss=5470.75  active=1091  feature_norm=38.46\n",
      "Iter 268 time=0.19  loss=5470.74  active=1092  feature_norm=38.47\n",
      "Iter 269 time=0.17  loss=5470.72  active=1092  feature_norm=38.46\n",
      "Iter 270 time=0.22  loss=5470.70  active=1091  feature_norm=38.47\n",
      "Iter 271 time=0.17  loss=5470.68  active=1092  feature_norm=38.46\n",
      "Iter 272 time=0.17  loss=5470.66  active=1092  feature_norm=38.47\n",
      "Iter 273 time=0.18  loss=5470.64  active=1092  feature_norm=38.46\n",
      "Iter 274 time=0.18  loss=5470.62  active=1091  feature_norm=38.47\n",
      "Iter 275 time=0.17  loss=5470.60  active=1091  feature_norm=38.46\n",
      "Iter 276 time=0.17  loss=5470.58  active=1092  feature_norm=38.47\n",
      "Iter 277 time=0.16  loss=5470.56  active=1092  feature_norm=38.46\n",
      "Iter 278 time=0.19  loss=5470.55  active=1092  feature_norm=38.47\n",
      "Iter 279 time=0.18  loss=5470.53  active=1092  feature_norm=38.46\n",
      "Iter 280 time=0.17  loss=5470.51  active=1092  feature_norm=38.47\n",
      "Iter 281 time=0.18  loss=5470.49  active=1092  feature_norm=38.46\n",
      "Iter 282 time=0.17  loss=5470.47  active=1092  feature_norm=38.47\n",
      "Iter 283 time=0.20  loss=5470.45  active=1093  feature_norm=38.46\n",
      "Iter 284 time=0.18  loss=5470.44  active=1094  feature_norm=38.47\n",
      "Iter 285 time=0.17  loss=5470.41  active=1092  feature_norm=38.46\n",
      "Iter 286 time=0.17  loss=5470.40  active=1092  feature_norm=38.47\n",
      "Iter 287 time=0.18  loss=5470.37  active=1092  feature_norm=38.46\n",
      "Iter 288 time=0.17  loss=5470.36  active=1092  feature_norm=38.47\n",
      "Iter 289 time=0.18  loss=5470.34  active=1092  feature_norm=38.46\n",
      "Iter 290 time=0.17  loss=5470.32  active=1092  feature_norm=38.47\n",
      "Iter 291 time=0.18  loss=5470.30  active=1091  feature_norm=38.46\n",
      "Iter 292 time=0.16  loss=5470.28  active=1092  feature_norm=38.47\n",
      "Iter 293 time=0.17  loss=5470.26  active=1091  feature_norm=38.46\n",
      "Iter 294 time=0.17  loss=5470.24  active=1090  feature_norm=38.46\n",
      "Iter 295 time=0.18  loss=5470.22  active=1090  feature_norm=38.46\n",
      "Iter 296 time=0.18  loss=5470.20  active=1089  feature_norm=38.46\n",
      "Iter 297 time=0.17  loss=5470.18  active=1089  feature_norm=38.46\n",
      "Iter 298 time=0.17  loss=5470.16  active=1089  feature_norm=38.46\n",
      "Iter 299 time=0.17  loss=5470.14  active=1088  feature_norm=38.45\n",
      "Iter 300 time=0.17  loss=5470.12  active=1088  feature_norm=38.46\n",
      "Iter 301 time=0.17  loss=5470.10  active=1088  feature_norm=38.45\n",
      "Iter 302 time=0.18  loss=5470.09  active=1088  feature_norm=38.46\n",
      "Iter 303 time=0.16  loss=5470.07  active=1088  feature_norm=38.45\n",
      "Iter 304 time=0.19  loss=5470.05  active=1088  feature_norm=38.46\n",
      "Iter 305 time=0.19  loss=5470.03  active=1088  feature_norm=38.45\n",
      "Iter 306 time=0.18  loss=5470.02  active=1088  feature_norm=38.45\n",
      "Iter 307 time=0.18  loss=5469.99  active=1090  feature_norm=38.45\n",
      "Iter 308 time=0.18  loss=5469.98  active=1090  feature_norm=38.45\n",
      "Iter 309 time=0.17  loss=5469.96  active=1090  feature_norm=38.44\n",
      "Iter 310 time=0.18  loss=5469.94  active=1089  feature_norm=38.45\n",
      "Iter 311 time=0.18  loss=5469.92  active=1089  feature_norm=38.44\n",
      "Iter 312 time=0.17  loss=5469.91  active=1087  feature_norm=38.45\n",
      "Iter 313 time=0.18  loss=5469.88  active=1088  feature_norm=38.44\n",
      "Iter 314 time=0.18  loss=5469.87  active=1087  feature_norm=38.44\n",
      "Iter 315 time=0.18  loss=5469.85  active=1087  feature_norm=38.43\n",
      "Iter 316 time=0.17  loss=5469.83  active=1088  feature_norm=38.44\n",
      "Iter 317 time=0.17  loss=5469.81  active=1089  feature_norm=38.43\n",
      "Iter 318 time=0.17  loss=5469.80  active=1089  feature_norm=38.44\n",
      "Iter 319 time=0.18  loss=5469.77  active=1089  feature_norm=38.43\n",
      "Iter 320 time=0.17  loss=5469.76  active=1089  feature_norm=38.43\n",
      "Iter 321 time=0.18  loss=5469.73  active=1089  feature_norm=38.42\n",
      "Iter 322 time=0.16  loss=5469.73  active=1089  feature_norm=38.43\n",
      "Iter 323 time=0.16  loss=5469.70  active=1089  feature_norm=38.42\n",
      "Iter 324 time=0.08  loss=5469.69  active=1089  feature_norm=38.42\n",
      "Iter 325 time=0.08  loss=5469.67  active=1089  feature_norm=38.40\n",
      "Iter 326 time=0.08  loss=5469.66  active=1089  feature_norm=38.42\n",
      "Iter 327 time=0.08  loss=5469.62  active=1092  feature_norm=38.40\n",
      "Iter 328 time=0.09  loss=5469.60  active=1094  feature_norm=38.41\n",
      "Iter 329 time=0.10  loss=5469.58  active=1095  feature_norm=38.40\n",
      "Iter 330 time=0.08  loss=5469.57  active=1095  feature_norm=38.41\n",
      "Iter 331 time=0.08  loss=5469.54  active=1095  feature_norm=38.40\n",
      "Iter 332 time=0.09  loss=5469.54  active=1094  feature_norm=38.41\n",
      "Iter 333 time=0.08  loss=5469.52  active=1097  feature_norm=38.40\n",
      "Iter 334 time=0.18  loss=5469.50  active=1097  feature_norm=38.40\n",
      "Iter 335 time=0.09  loss=5469.49  active=1095  feature_norm=38.40\n",
      "Iter 336 time=0.18  loss=5469.47  active=1095  feature_norm=38.41\n",
      "Iter 337 time=0.08  loss=5469.44  active=1094  feature_norm=38.41\n",
      "Iter 338 time=0.20  loss=5469.42  active=1094  feature_norm=38.41\n",
      "Iter 339 time=0.17  loss=5469.42  active=1093  feature_norm=38.41\n",
      "Iter 340 time=0.17  loss=5469.39  active=1093  feature_norm=38.41\n",
      "Iter 341 time=0.16  loss=5469.38  active=1092  feature_norm=38.41\n",
      "Iter 342 time=0.17  loss=5469.35  active=1092  feature_norm=38.41\n",
      "Iter 343 time=0.17  loss=5469.33  active=1092  feature_norm=38.41\n",
      "Iter 344 time=0.18  loss=5469.31  active=1091  feature_norm=38.42\n",
      "Iter 345 time=0.17  loss=5469.30  active=1091  feature_norm=38.41\n",
      "Iter 346 time=0.17  loss=5469.28  active=1091  feature_norm=38.42\n",
      "Iter 347 time=0.18  loss=5469.27  active=1090  feature_norm=38.42\n",
      "Iter 348 time=0.15  loss=5469.25  active=1090  feature_norm=38.43\n",
      "Iter 349 time=0.17  loss=5469.24  active=1090  feature_norm=38.42\n",
      "Iter 350 time=0.16  loss=5469.22  active=1090  feature_norm=38.43\n",
      "Iter 351 time=0.18  loss=5469.21  active=1089  feature_norm=38.43\n",
      "Iter 352 time=0.18  loss=5469.19  active=1088  feature_norm=38.44\n",
      "Iter 353 time=0.17  loss=5469.18  active=1089  feature_norm=38.43\n",
      "Iter 354 time=0.17  loss=5469.16  active=1089  feature_norm=38.44\n",
      "Iter 355 time=0.18  loss=5469.15  active=1088  feature_norm=38.44\n",
      "Iter 356 time=0.17  loss=5469.14  active=1086  feature_norm=38.44\n",
      "Iter 357 time=0.09  loss=5469.13  active=1086  feature_norm=38.44\n",
      "Iter 358 time=0.08  loss=5469.11  active=1085  feature_norm=38.45\n",
      "Iter 359 time=0.08  loss=5469.09  active=1086  feature_norm=38.45\n",
      "Iter 360 time=0.08  loss=5469.06  active=1087  feature_norm=38.46\n",
      "Iter 361 time=0.09  loss=5469.05  active=1087  feature_norm=38.45\n",
      "Iter 362 time=0.08  loss=5469.02  active=1087  feature_norm=38.46\n",
      "Iter 363 time=0.08  loss=5469.00  active=1087  feature_norm=38.46\n",
      "Iter 364 time=0.09  loss=5468.99  active=1086  feature_norm=38.47\n",
      "Iter 365 time=0.09  loss=5468.97  active=1086  feature_norm=38.47\n",
      "Iter 366 time=0.10  loss=5468.96  active=1086  feature_norm=38.48\n",
      "Iter 367 time=0.08  loss=5468.94  active=1086  feature_norm=38.47\n",
      "Iter 368 time=0.08  loss=5468.92  active=1087  feature_norm=38.48\n",
      "Iter 369 time=0.07  loss=5468.91  active=1086  feature_norm=38.48\n",
      "Iter 370 time=0.08  loss=5468.89  active=1086  feature_norm=38.49\n",
      "Iter 371 time=0.08  loss=5468.89  active=1087  feature_norm=38.49\n",
      "Iter 372 time=0.08  loss=5468.86  active=1087  feature_norm=38.49\n",
      "Iter 373 time=0.16  loss=5468.85  active=1087  feature_norm=38.49\n",
      "Iter 374 time=0.15  loss=5468.84  active=1087  feature_norm=38.50\n",
      "Iter 375 time=0.17  loss=5468.83  active=1087  feature_norm=38.50\n",
      "Iter 376 time=0.17  loss=5468.82  active=1087  feature_norm=38.50\n",
      "Iter 377 time=0.16  loss=5468.82  active=1088  feature_norm=38.50\n",
      "Iter 378 time=0.18  loss=5468.80  active=1088  feature_norm=38.50\n",
      "Iter 379 time=0.17  loss=5468.80  active=1088  feature_norm=38.50\n",
      "Iter 380 time=0.17  loss=5468.79  active=1088  feature_norm=38.51\n",
      "Iter 381 time=0.18  loss=5468.78  active=1088  feature_norm=38.51\n",
      "Iter 382 time=0.19  loss=5468.77  active=1087  feature_norm=38.51\n",
      "Iter 383 time=0.20  loss=5468.76  active=1087  feature_norm=38.51\n",
      "Iter 384 time=0.18  loss=5468.75  active=1087  feature_norm=38.52\n",
      "Iter 385 time=0.18  loss=5468.75  active=1086  feature_norm=38.52\n",
      "Iter 386 time=0.18  loss=5468.73  active=1085  feature_norm=38.52\n",
      "Iter 387 time=0.18  loss=5468.73  active=1086  feature_norm=38.52\n",
      "Iter 388 time=0.20  loss=5468.72  active=1086  feature_norm=38.52\n",
      "Iter 389 time=0.18  loss=5468.71  active=1085  feature_norm=38.52\n",
      "Iter 390 time=0.16  loss=5468.70  active=1085  feature_norm=38.53\n",
      "Iter 391 time=0.18  loss=5468.69  active=1086  feature_norm=38.52\n",
      "Iter 392 time=0.17  loss=5468.68  active=1086  feature_norm=38.53\n",
      "Iter 393 time=0.18  loss=5468.67  active=1086  feature_norm=38.53\n",
      "Iter 394 time=0.21  loss=5468.67  active=1086  feature_norm=38.53\n",
      "Iter 395 time=0.17  loss=5468.66  active=1086  feature_norm=38.53\n",
      "Iter 396 time=0.20  loss=5468.65  active=1086  feature_norm=38.53\n",
      "Iter 397 time=0.17  loss=5468.64  active=1087  feature_norm=38.53\n",
      "Iter 398 time=0.18  loss=5468.64  active=1087  feature_norm=38.54\n",
      "Iter 399 time=0.17  loss=5468.63  active=1086  feature_norm=38.53\n",
      "Iter 400 time=0.18  loss=5468.62  active=1087  feature_norm=38.54\n",
      "Iter 401 time=0.16  loss=5468.62  active=1088  feature_norm=38.53\n",
      "Iter 402 time=0.16  loss=5468.61  active=1088  feature_norm=38.54\n",
      "Iter 403 time=0.17  loss=5468.60  active=1086  feature_norm=38.54\n",
      "Iter 404 time=0.09  loss=5468.60  active=1086  feature_norm=38.54\n",
      "Iter 405 time=0.08  loss=5468.59  active=1085  feature_norm=38.53\n",
      "Iter 406 time=0.08  loss=5468.57  active=1085  feature_norm=38.54\n",
      "Iter 407 time=0.09  loss=5468.56  active=1085  feature_norm=38.54\n",
      "Iter 408 time=0.08  loss=5468.55  active=1083  feature_norm=38.54\n",
      "Iter 409 time=0.10  loss=5468.55  active=1081  feature_norm=38.54\n",
      "Iter 410 time=0.10  loss=5468.53  active=1082  feature_norm=38.54\n",
      "Iter 411 time=0.10  loss=5468.52  active=1082  feature_norm=38.54\n",
      "Iter 412 time=0.10  loss=5468.51  active=1081  feature_norm=38.54\n",
      "Iter 413 time=0.18  loss=5468.50  active=1081  feature_norm=38.54\n",
      "Iter 414 time=0.08  loss=5468.50  active=1081  feature_norm=38.54\n",
      "Iter 415 time=0.07  loss=5468.49  active=1082  feature_norm=38.54\n",
      "Iter 416 time=0.08  loss=5468.47  active=1082  feature_norm=38.54\n",
      "Iter 417 time=0.09  loss=5468.47  active=1083  feature_norm=38.54\n",
      "Iter 418 time=0.08  loss=5468.45  active=1082  feature_norm=38.55\n",
      "Iter 419 time=0.07  loss=5468.45  active=1082  feature_norm=38.54\n",
      "Iter 420 time=0.08  loss=5468.43  active=1083  feature_norm=38.55\n",
      "Iter 421 time=0.08  loss=5468.43  active=1083  feature_norm=38.54\n",
      "Iter 422 time=0.09  loss=5468.41  active=1083  feature_norm=38.55\n",
      "Iter 423 time=0.16  loss=5468.40  active=1083  feature_norm=38.55\n",
      "Iter 424 time=0.09  loss=5468.39  active=1083  feature_norm=38.55\n",
      "Iter 425 time=0.20  loss=5468.38  active=1083  feature_norm=38.55\n",
      "Iter 426 time=0.08  loss=5468.38  active=1083  feature_norm=38.56\n",
      "Iter 427 time=0.17  loss=5468.36  active=1082  feature_norm=38.55\n",
      "Iter 428 time=0.27  loss=5468.36  active=1083  feature_norm=38.56\n",
      "Iter 429 time=0.27  loss=5468.35  active=1084  feature_norm=38.56\n",
      "Iter 430 time=0.26  loss=5468.35  active=1084  feature_norm=38.56\n",
      "Iter 431 time=0.26  loss=5468.34  active=1084  feature_norm=38.56\n",
      "Iter 432 time=0.26  loss=5468.34  active=1084  feature_norm=38.56\n",
      "Iter 433 time=0.25  loss=5468.33  active=1082  feature_norm=38.56\n",
      "Iter 434 time=0.17  loss=5468.33  active=1082  feature_norm=38.56\n",
      "Iter 435 time=0.17  loss=5468.32  active=1081  feature_norm=38.56\n",
      "Iter 436 time=0.16  loss=5468.32  active=1081  feature_norm=38.56\n",
      "Iter 437 time=0.17  loss=5468.31  active=1081  feature_norm=38.56\n",
      "L-BFGS terminated with the stopping criteria\n",
      "Total seconds required for training: 60.137\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 1081 (32191)\n",
      "Number of active attributes: 622 (31693)\n",
      "Number of active labels: 4 (4)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.011\n",
      "\n",
      "CPU times: user 1min 1s, sys: 1.02 s, total: 1min 2s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=1000,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "28148ff3-b66b-4ce8-bb94-f5d559cfe239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities = sorted(df.entities.unique().tolist())\n",
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c976e793-96dd-4568-972d-edfb0a25145f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9843322190084342"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de4404-e4b0-46c4-8b25-3f9fb9bcf44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
