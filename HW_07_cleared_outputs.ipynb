{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –£—Ä–æ–∫ 7. –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ\n",
    "–ë–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ (–∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è)\n",
    "1. –£—á–∏–º conv —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "\n",
    "2. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 2-–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å–µ—Ç–æ—á–µ–∫\n",
    "\n",
    "2.1 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å tf.keras.layers.Embedding –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤–∑—è—Ç—å –∫ –ø—Ä–∏–º–µ—Ä—É —Å https://rusvectores.org/ru/\n",
    "\n",
    "2.2 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–π tf.keras.layers.Embedding –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–Ω—É —Ç–æ –µ—Å—Ç—å –≤–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞—Ç—å —Å –≤–µ—Å–∞–º–∏)\n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ –∏ –∫–æ–≥–¥–∞ tf.keras.layers.Embedding –æ–±—É—á–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É —Å–æ –≤—Å–µ–π —Å–µ—Ç–æ—á–∫–æ–π, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ª—É—á—à–µ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop_words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: stop_words\n",
      "  Building wheel for stop_words (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stop_words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=fb954ab3a844fd544862fb959a995a4412d691b92db126f00b7b62fb28e23976\n",
      "  Stored in directory: /Users/Olga/Library/Caches/pip/wheels/da/d8/66/395317506a23a9d1d7de433ad6a7d9e6e16aab48cf028a0f60\n",
      "Successfully built stop_words\n",
      "Installing collected packages: stop_words\n",
      "Successfully installed stop_words-2018.7.23\n"
     ]
    }
   ],
   "source": [
    "!pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Olga/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping  \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
       "5       5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
       "6       5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
       "7       5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
       "8       5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
       "9       5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    14586\n",
       "1     2276\n",
       "4     2138\n",
       "3      911\n",
       "2      748\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13841, 3), (6818, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>–ù–∞–∫–æ–Ω–µ—Ü-—Ç–æ –∏—Å–ø—Ä–∞–≤–∏–ª–∏ —ç—Ç—É —á—É—à—å —Å –Ω–µ–æ—Ä–≥–∏–Ω–∞–ª—å–Ω–æ–π ...</td>\n",
       "      <td>2017-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>–£–¥–æ–±–Ω–æ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏</td>\n",
       "      <td>2017-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>2017-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–ö–ª–∞—Å—Å</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–£–¥–æ–±–Ω–æ</td>\n",
       "      <td>2017-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>4</td>\n",
       "      <td>–í—Å–µ –Ω—Ä–∞–≤–∏—Ç—Å—è</td>\n",
       "      <td>2017-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —Å–º–µ—à–Ω–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ø—É–≥–∞–µ—Ç—Å—è —Ä—É—Ç–∞ :)</td>\n",
       "      <td>2017-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>1</td>\n",
       "      <td>–ù–µ –º–æ–≥—É —Å–∫–∞—á–∞—Ç—å –æ—à–∏–±–∫–∞ –Ω–æ–º–µ—Ä 24</td>\n",
       "      <td>2017-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>5</td>\n",
       "      <td>–°–±–µ—Ä–±–∞–Ω–∫ –≤—Å–µ–≥–¥–∞ —Ä—è–¥–æ–º</td>\n",
       "      <td>2017-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>5</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º –≤—Å–µ –æ—á–µ–Ω—å –æ—Ç–ª–∏—á–Ω–æ!)</td>\n",
       "      <td>2017-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13841 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content        Date\n",
       "0           5  –ù–∞–∫–æ–Ω–µ—Ü-—Ç–æ –∏—Å–ø—Ä–∞–≤–∏–ª–∏ —ç—Ç—É —á—É—à—å —Å –Ω–µ–æ—Ä–≥–∏–Ω–∞–ª—å–Ω–æ–π ...  2017-08-09\n",
       "1           5                             –£–¥–æ–±–Ω–æ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏  2017-07-27\n",
       "2           5                                            –û—Ç–ª–∏—á–Ω–æ  2017-08-08\n",
       "3           5                                              –ö–ª–∞—Å—Å  2017-07-25\n",
       "4           5                                             –£–¥–æ–±–Ω–æ  2017-07-08\n",
       "...       ...                                                ...         ...\n",
       "13836       4                                       –í—Å–µ –Ω—Ä–∞–≤–∏—Ç—Å—è  2017-07-29\n",
       "13837       5            –û—á–µ–Ω—å —Å–º–µ—à–Ω–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ø—É–≥–∞–µ—Ç—Å—è —Ä—É—Ç–∞ :)  2017-07-28\n",
       "13838       1                    –ù–µ –º–æ–≥—É —Å–∫–∞—á–∞—Ç—å –æ—à–∏–±–∫–∞ –Ω–æ–º–µ—Ä 24  2017-08-06\n",
       "13839       5                              –°–±–µ—Ä–±–∞–Ω–∫ –≤—Å–µ–≥–¥–∞ —Ä—è–¥–æ–º  2017-08-12\n",
       "13840       5                        –í —Ü–µ–ª–æ–º –≤—Å–µ –æ—á–µ–Ω—å –æ—Ç–ª–∏—á–Ω–æ!)  2017-07-21\n",
       "\n",
       "[13841 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
    "df_test['Content'] = df_test['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>–Ω–∞–∫–æ–Ω–µ—Ü—Ç—ã–π –∏—Å–ø—Ä–∞–≤–∏—Ç—å —á—É—à—å —Å–Ω–µ–æ—Ä–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ—à–∏...</td>\n",
       "      <td>2017-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ</td>\n",
       "      <td>2017-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>2017-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–∫–ª–∞—Å—Å</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ</td>\n",
       "      <td>2017-07-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5  –Ω–∞–∫–æ–Ω–µ—Ü—Ç—ã–π –∏—Å–ø—Ä–∞–≤–∏—Ç—å —á—É—à—å —Å–Ω–µ–æ—Ä–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ—à–∏...  2017-08-09\n",
       "1       5                               —É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ  2017-07-27\n",
       "2       5                                            –æ—Ç–ª–∏—á–Ω–æ  2017-08-08\n",
       "3       5                                              –∫–ª–∞—Å—Å  2017-07-25\n",
       "4       5                                             —É–¥–æ–±–Ω–æ  2017-07-08"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"Content\"])\n",
    "train_corpus = train_corpus.lower()\n",
    "train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(train_corpus)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ': 4123, '—É–¥–æ–±–Ω–æ': 2201, '—Ä–∞–±–æ—Ç–∞—Ç—å': 1288, '—É–¥–æ–±–Ω—ã–π': 1182, '–æ—Ç–ª–∏—á–Ω–æ': 860, '–Ω—Ä–∞–≤–∏—Ç—å—Å—è': 763, '—Ö–æ—Ä–æ—à–∏–π': 681, '–æ—Ç–ª–∏—á–Ω—ã–π': 677, '—Ç–µ–ª–µ—Ñ–æ–Ω': 627, '—Å—É–ø–µ—Ä': 540, ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "dist = FreqDist(tokens_filtered)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',\n",
       " '—É–¥–æ–±–Ω–æ',\n",
       " '—Ä–∞–±–æ—Ç–∞—Ç—å',\n",
       " '—É–¥–æ–±–Ω—ã–π',\n",
       " '–æ—Ç–ª–∏—á–Ω–æ',\n",
       " '–Ω—Ä–∞–≤–∏—Ç—å—Å—è',\n",
       " '—Ö–æ—Ä–æ—à–∏–π',\n",
       " '–æ—Ç–ª–∏—á–Ω—ã–π',\n",
       " '—Ç–µ–ª–µ—Ñ–æ–Ω',\n",
       " '—Å—É–ø–µ—Ä']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 200\n",
    "\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tdk777qGJtz4"
   },
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5OULZgvkJzpj"
   },
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pqHlf5nNJ2hl"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Content\"]], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1590650625870,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "lI4NUg_TJ6NK",
    "outputId": "5d29285d-6c2e-4c34-f307-c2e9c3c12631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   1,   2,  15],\n",
       "       [  0,   0,   0, ...,   0,   2, 181],\n",
       "       [  0,   0,   0, ...,   0,   0,   5],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 164,  27,  84],\n",
       "       [  0,   0,   0, ...,   0,   0,  20],\n",
       "       [  0,   0,   0, ...,   0, 113,   5]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(df_train['Rating']) \n",
    "test_enc_labels = le.transform(df_test['Rating'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 0, 4, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_enc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = tf.keras.utils.to_categorical(train_enc_labels, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(test_enc_labels, num_classes=num_classes)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len)) \n",
    "\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[get_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 75ms/step - loss: 1.1623 - get_f1: 0.7151\n",
      "\n",
      "\n",
      "Test loss: 1.1623296737670898\n",
      "Test f1_score: 0.7151089310646057\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test loss:', score[0])\n",
    "print('Test f1_score:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://vectors.nlpl.eu/repository/\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('./180/model.bin', binary=True)  \n",
    "len(word_vectors), len(word_vectors[1]), word_vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_matrix = [word_vectors[i][:128] for i in range(200)]\n",
    "word_vectors_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.Constant(word_vectors_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, embeddings_initializer =initializer, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[get_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:43:58.427545: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-07-23 17:43:58.428237: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-07-23 17:43:58.435250: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/25 [=>............................] - ETA: 5s - loss: 1.5561 - get_f1: 0.5274 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:44:00.721624: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-07-23 17:44:00.721828: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-07-23 17:44:00.996098: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-07-23 17:44:01.009287: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-07-23 17:44:01.032499: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/train/plugins/profile/2022_07_23_17_44_01\n",
      "\n",
      "2022-07-23 17:44:01.036190: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2022_07_23_17_44_01/MacBook-Air-Olga.local.trace.json.gz\n",
      "2022-07-23 17:44:01.069938: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/train/plugins/profile/2022_07_23_17_44_01\n",
      "\n",
      "2022-07-23 17:44:01.070542: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2022_07_23_17_44_01/MacBook-Air-Olga.local.memory_profile.json.gz\n",
      "2022-07-23 17:44:01.073490: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2022_07_23_17_44_01\n",
      "Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2022_07_23_17_44_01/MacBook-Air-Olga.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2022_07_23_17_44_01/MacBook-Air-Olga.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2022_07_23_17_44_01/MacBook-Air-Olga.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2022_07_23_17_44_01/MacBook-Air-Olga.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2022_07_23_17_44_01/MacBook-Air-Olga.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 7s 237ms/step - loss: 0.9939 - get_f1: 0.6956 - val_loss: 0.8325 - val_get_f1: 0.7205\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 64ms/step - loss: 0.8248 - get_f1: 0.7317\n",
      "\n",
      "\n",
      "Test loss: 0.8247653841972351\n",
      "Test f1_score: 0.7317059636116028\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test loss:', score[0])\n",
    "print('Test f1_score:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
